# PACT：基于剪枝和聚类的令牌缩减方法，助力视觉语言模型加速推理

作者：Mohamed Dhouib¹、Davide Buscaldi²、Sonia Vanier¹、Aymen Shabou³¹ 法国巴黎综合理工学院 LIX 实验室、巴黎萨克雷大学² 法国巴黎第十三大学 LIPN 实验室³ 法国农业信贷银行集团 DataLab摘要：视觉语言模型（VLMs）的推理过程需要大量计算资源，这源于表示视觉信息所需的额外输入令牌。然而，这些视觉令牌往往包含冗余且不重要的信息，导致令牌数量过多。为解决这一问题，本文提出 PACT 方法 —— 通过在语言模型的早期层剪枝无关令牌并合并视觉冗余令牌，减少推理时间和内存占用。该方法采用一种新的重要性指标来识别不重要令牌，无需依赖注意力分数，因此与 FlashAttention 兼容。本文还提出一种新颖的聚类算法，即距离有界密度峰值聚类（Distance Bounded Density Peak Clustering, DBDPC），能高效聚类视觉令牌，同时通过预定义阈值约束簇内元素间的距离。大量实验验证了 PACT 的有效性。

## 1 引言

近年来，将大型语言模型扩展到文本以外的模态（[12, 19, 20, 54, 55]）在多个领域取得了成功，尤其在视觉领域，LLaVA [31]、Qwen-VL [4] 等模型表现突出。最先进的视觉语言模型通常由三个核心组件构成：视觉编码器、连接器和语言模型。视觉编码器将输入图像转换为视觉令牌，经连接器处理后，与输入文本一同送入语言模型。尽管该架构在各类任务中表现出令人印象深刻的性能，但由于视觉令牌数量庞大，其计算成本居高不下。

本文提出两种互补方法来优化视觉语言模型，降低推理时间和内存需求：剪枝模块和聚类算法。这两种方法可单独使用或组合使用，形成效果更优的 PACT 方法。值得注意的是，本文的剪枝和聚类模块以及 PACT 方法均在推理时应用，无需额外训练。剪枝模块基于一种新颖的重要性指标识别不重要的视觉令牌，该指标无需依赖注意力分数即可评估每个令牌的相关性，因此与不支持注意力分数计算的 FlashAttention [13] 兼容。第二个模块引入了新颖的距离有界密度峰值聚类（DBDPC）算法，在聚类视觉令牌的同时，确保簇内元素间的距离受预定义阈值约束。

通过组合这两种方法，PACT 的工作流程如下：首先，剪枝模块剔除不重要令牌；然后，DBDPC 算法对剩余令牌进行聚类；接着，将初始被剪枝但与已构建聚类足够接近的令牌重新纳入，以回收有价值信息；最后，每个聚类内的令牌被合并为一个代表性令牌，减少总令牌数。

PACT 通过结合剪枝和聚类，有效减少视觉令牌数量，同时解决了令牌无关性和冗余性问题。将其应用于 LLaVA-OneVision-7B 时，PACT 能实现 50% 的视觉令牌缩减，且性能损失可忽略不计。此外，在更高缩减率下，PACT 的性能下降显著低于现有方法 —— 实现 71.3% 的视觉令牌缩减时，性能仅下降 1.4%，而现有最先进方法在相同缩减率下性能下降至少达 4.4%。

本文的贡献如下：

1. 提出一种不依赖注意力分数的新颖视觉令牌剪枝指标，确保与 FlashAttention 兼容，并通过实证验证其有效性。
2. 引入一种针对视觉冗余缩减的新聚类算法，证明其在视觉令牌缩减任务上优于其他聚类算法。
3. 验证剪枝与基于聚类的合并相结合的方法，在视觉令牌缩减方面优于单独使用任一技术。通过整合剪枝和聚类算法，提出新颖的 PACT 方法，其性能超过现有及同期工作 [3, 7, 10, 30, 43]。
    
    本文实验代码已开源：[https://github.com/orailix/PACT/tree/main](https://github.com/orailix/PACT/tree/main)。

## 2 相关工作

### 2.1 视觉语言模型

自 BLIP-2 [28] 提出以来，“视觉编码器 + 连接器 + 语言模型” 的架构已成为视觉语言模型（VLMs）的标准设计 [8, 18, 48]。近期模型 [11, 27, 47] 增强了 VLM 的高分辨率处理能力，这对于文档理解任务 [14, 24] 至关重要。LLaVA-OneVision [27] 将图像分割为 384×384 的切块，通过 SigLIP [53] 编码每个切块，并利用双线性插值将令牌数减少至最多 8748 个。InternVL2 [11] 将图像分割为 448×448 的瓦片，每个图像最多处理 40 个瓦片，采用 InternViT [11] 编码并通过像素重排减少视觉令牌数，最多生成 10240 个令牌。Qwen-VL2 [47] 采用二维旋转位置编码支持动态分辨率，并通过 MLP 层合并相邻令牌，但处理高分辨率图像仍需超过 10000 个令牌。这些模型通过合并相邻令牌来减少数量以保留结构，但未解决令牌的无关性和冗余性问题，限制了效率提升。

### 2.2 视觉令牌缩减

多年来，减少视觉 Transformer（ViT）中的视觉令牌数量一直是研究热点。EViT [29] 通过依赖类别令牌（[CLS]）与视觉令牌间的注意力分数，识别并合并无关令牌。ToME [7] 提出一种简单有效的方法，在 ViT 各层中迭代合并相似令牌。基于这些思路，近期研究将视觉令牌缩减技术扩展到 VLMs 中。LaVIT [22] 使用 Gumbel-Softmax [21] 训练掩码以选择保留令牌，并通过额外注意力层将丢弃的令牌合并到保留令牌中。LLaVA-PruMerge [43] 利用 ViT 编码器最后一层中 [CLS] 令牌与视觉令牌的注意力分数来决定保留哪些令牌，以加速 LLAVA 1.5 [31]；HiRED [3] 通过基于早期层注意力分配令牌预算来优化该方法。然而，这两种方法仅适用于添加了 [CLS] 令牌的 ViT 架构，与大多数不使用 [CLS] 令牌的最先进 VLMs 不兼容。此外，它们均在视觉编码器输出端为令牌分配分数，但近期 VLMs 在将视觉令牌送入语言模型前会合并相邻令牌，难以将合并前的分数对应到合并后的令牌，导致适用性受限。

LLaVA-PruMerge 通过将剪枝令牌合并到保留令牌中减少信息损失，但未合并相似的保留令牌，因此无法解决视觉冗余问题 —— 这是剪枝类方法的典型局限。TRIM [45] 基于与 CLIP [41] 的池化文本的相似度剪枝令牌，但由于依赖文本信息，在多轮对话中可能仅根据图像前向传播时的文本信息剪枝视觉令牌，导致丢失后续提示所需的关键信息，适用性较差。FastV [10] 通过平均注意力分数评估令牌重要性，与 FlashAttention 不兼容，给近期 VLMs 带来额外计算开销。VTW [30] 在深层剪枝令牌，虽效果可期，但由于仅在后期移除视觉令牌，计算成本降低有限。

现有方法仅解决了两个问题之一：要么处理不重要令牌，要么处理视觉冗余。本文提出的 PACT 方法通过同时剪枝无关令牌和合并视觉冗余令牌，实现了对这两个问题的协同解决。

## 3 方法

本节详细介绍 PACT 方法，其目标是在语言模型的早期层 L 通过剪枝不重要令牌和合并视觉冗余令牌，减少 VLMs 的推理时间和内存占用。PACT 包含三个步骤：首先识别不重要令牌；其次对剩余令牌进行聚类；最后合并每个聚类内的令牌以及初始丢弃但足够接近聚类的令牌。PACT 在语言模型的选定层 L 中运行，适用于视觉令牌被送入语言模型的各类场景，与视觉编码器或连接器的架构无关。

我们用\(H \in \mathbb{R}^{n ×d}\)表示层 L 的隐藏状态，其中 n 为视觉令牌数量，d 为隐藏状态维度；用\(K, Q \in \mathbb{R}^{n ×n_{h} ×d_{h}}\)表示层 L 视觉令牌的键（key）和查询（query）矩阵，其中\(n_{h}\)为注意力头数量，\(d_{h}\)为每个注意力头的维度。为简化表示，省略层索引；用下标表示令牌的位置索引，上标表示注意力头，例如\(k_{i}^{(j)}\)表示第 i 个视觉令牌在第 j 个注意力头的键向量。

### 3.1 不重要令牌识别

在语言模型的特定层 L 识别不重要令牌的直接方法，是将每个令牌的重要性定义为其从所有其他令牌获得的总注意力分数 [10]。但该方法存在三个主要缺陷：首先，当前 VLMs 采用的 FlashAttention [13] 不支持输出注意力分数；其次，注意力分数计算涉及掩码，会引入偏差 —— 序列末尾的令牌由于较少被其他令牌关注，平均注意力分数往往较低，仅基于关注它的令牌计算平均分数虽能缓解该问题，但会产生新偏差（序列末尾令牌可能因主要被邻近令牌关注而获得更高分数），导致令牌剪枝受位置影响（如图 1 所示），而剪枝应仅取决于视觉令牌包含的信息而非其位置；最后，仅依赖单个层的键和查询来定义重要性指标，可能无法充分捕捉视觉令牌在语言模型所有层中的重要性，因为每个自注意力层关注视觉令牌的不同方面。

为解决这些问题，本文提出一种重要性指标，整合了隐藏状态的累积信息和早期层 L 的键、查询的层特定信息，称为高效不重要令牌识别（Efficient Unimportant Tokens Identification, EUTI）。我们推测，隐藏状态的范数能反映每个视觉令牌的重要性，因为它体现了令牌在网络中传递的信息量。图 2 展示了 LLaVA-OneVision-7B 第四层视觉令牌的隐藏状态范数统计，显示出较大方差，这表明某些视觉令牌通过残差连接累积了更多信息，可能对后续计算更重要。

为同时利用隐藏状态范数和键、查询向量的信息，首先计算全局查询向量\(Q_{global }\)，即所有视觉令牌查询向量的平均值：\(Q_{global }=\frac{1}{n} \sum_{i=1}^{n} Q_{i} \quad (1)\)

该向量代表层 L 中所有注意力头下视觉令牌所需的整体查询信息。然后计算每个视觉令牌的重要性分数：在每个注意力头中，计算令牌键与全局查询的点积，在视觉令牌上应用 Softmax，跨注意力头取平均，最后用隐藏状态范数缩放结果：\(s_{i}=\frac{1}{n_{h}} \sum_{j=1}^{n_{h}} Softmax\left(k_{i}^{(j)} \cdot Q_{global }^{(j)}\right) \cdot\left\| h_{i}\right\| _{2} \quad (2)\)

随后，使用参数\(\lambda \in[0,1]\)控制不重要令牌的比例，将视觉令牌分为重要令牌和不重要令牌两组：\(S_{important }=\left\{i | s_{i} \geq Percentile (s, \lambda)\right\} \quad (3)\)\(S_{unimportant }=\left\{i | s_{i}< Percentile (s, \lambda)\right\} \quad (4)\)

不重要令牌可直接剪枝，或与聚类算法结合以进一步减少视觉令牌数量（下一节将详细介绍）。完整的 EUTI 算法如算法 1 所示。

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

**算法 1 EUTI（高效不重要令牌识别）**输入：隐藏状态\(H \in \mathbb{R}^{n×d}\)；键和查询矩阵\(K, Q \in \mathbb{R}^{n×n_h×d_h}\)；剪枝比例\(\lambda \in[0,1]\)输出：重要视觉令牌集和不重要视觉令牌集

1. 计算全局查询向量：\(Q_{global }=\frac{1}{n} \sum_{i=1}^{n} Q_{i}\)
2. 计算每个视觉令牌的重要性分数：
    
    对所有\(i = 1, ..., n\)：\(s_{i}=\frac{1}{n_{h}} \sum_{j=1}^{n_{h}} Softmax\left(k_{i}^{(j)} \cdot Q_{global }^{(j)}\right) \cdot\left\| h_{i}\right\| _{2}\)
3. 定义重要令牌集和不重要令牌集：\(S_{important }=\{i | s_{i} \geq Percentile(s, \lambda)\}\)\(S_{unimportant }=\{i | s_{i}< Percentile(s, \lambda)\}\)
4. 返回\(S_{important }\)和\(S_{unimportant }\)

### 3.2 基于聚类的视觉令牌合并

#### 距离有界密度峰值聚类（DBDPC）

仅依靠上述重要性分数剪枝不重要令牌，虽能显著减少视觉令牌数量并保留重要令牌，但保留的令牌中可能仍存在冗余信息。因此，本文提出通过聚类算法合并冗余视觉令牌。我们期望聚类算法具备以下特性：（a）计算时间短；（b）避免将特征相似度低（距离远）的点分配到同一聚类中。

特性（b）确保异常值不会被分配到遥远的聚类中心 —— 我们推测这些异常值包含重要信息，应仅与邻近异常值合并或单独构成聚类；同时保证每个聚类内的点相对接近，从而在将单个向量作为聚类代表时最小化信息损失。密度峰值聚类（DPC）[5] 在此场景中具有吸引力，因为它满足特性（a），不同于 k-means [2] 等迭代聚类算法。然而，DPC 不满足特性（b），可能形成边界点彼此距离较远的大型聚类；DBSCAN [15] 等其他算法也存在类似问题。因此，本文提出一种新的聚类算法 —— 距离有界密度峰值聚类（DBDPC）。

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

DBDPC 的输入为一组向量\(\{u_i \in \mathbb{R}^{d_1}\}_{i=1}^q\)（其中\(q, d_1 \in \mathbb{N}^+\)），输出为一组聚类。算法输出取决于两个参数（截断距离\(d_c \in \mathbb{R}^+\)和归一化因子\(d_n \in \mathbb{R}^+\)）以及距离函数\(d: \mathbb{R}^{d_1} ×\mathbb{R}^{d_1} \to \mathbb{R}^+\)。我们定义两个向量\(u_i\)和\(u_j\)之间的距离为：\(d_{i j}=d\left(u_{i}, u_{j}\right)=1-\frac{u_{i} \cdot u_{j}}{\left\| u_{i}\right\| _{2}\left\| u_{j}\right\| _{2}} \quad (5)\)

然后计算局部密度\(\rho_i\)：\(\rho_{i}=\sum_{j} e^{-d_{i j} / d_{n}} \quad (6)\)

按\(\rho_i\)从高到低对向量\(u_i\)排序，若某个向量与已选聚类中心的最小距离大于\(d_c\)，则将其指定为新的聚类中心。每个向量\(u_i\)随后被分配到距离最近的聚类中心。该算法保证每个向量到其聚类中心的距离小于\(d_c\)，从而满足上述特性（b）。完整的 DBDPC 算法如算法 2 所示。

DBDPC 中的聚类中心识别过程确保簇间距离上界为\(2d_c ×(2-d_c)\)，同时聚类中心间距离下界为\(d_c\)（附录 B 提供正式证明）。需说明的是，为清晰起见，算法中部分步骤以循环形式呈现，但除聚类中心选择部分外，所有计算均可在 GPU 上并行执行 —— 聚类中心选择部分采用递归算法高效识别初始中心集和丢弃向量，减少待处理向量数量（附录 D 详细说明）。DBDPC 与 DPC 的对比及与其他聚类算法的定性比较见附录 C。

#### 距离计算的向量选择

如前所述，DBDPC 算法基于一组向量计算距离，为实现有效聚类，这些向量的点积需能准确反映对应视觉令牌的相似度。幸运的是，Transformer 通过 QKV 自注意力机制解决了这一问题 —— 键向量 K 为每个令牌提供了适合点积相似度计算的有意义表示。因此，DBDPC 算法中使用键向量进行聚类，形式化表示为：\(C_{centers }, C_{elements }=DBDPC\left(K'\right) \quad (7)\)其中\(K'=\{u_{i} \in K | i \in S_{important }\}\)是重要令牌对应的键向量子集。

#### 聚类中心附近的不重要令牌处理

初始被判定为不重要但距离聚类中心足够近的令牌，很可能是误判的。为减少信息损失，我们将这些令牌添加到对应的聚类中。形式化地，基于系数\(\alpha\)定义阈值，若初始被排除的令牌\(u_i\)与最近的聚类中心\(s \in C_{centers }\)的距离满足\(d_{i s}<\alpha \cdot d_{c}\)，则将其添加到该聚类中心的聚类中。具体而言，更新后的聚类元素集\(C_{elements }^{(s)}\)为：\(S_{added }^{(s)}=\left\{i \in S_{unimportant } | s=argmin_{s' \in C_{centers }} d_{i s'} \text{ 且 } d_{i s}<\alpha \cdot d_{c}\right\} \quad (8)\)\(C_{elements }^{(s)} \leftarrow C_{elements }^{(s)} \cup S_{added }^{(s)} \quad (9)\)

#### 令牌合并与位置 ID 分配

最后，合并每个聚类内元素对应的隐藏状态，形式化表示为：\(H'=\left\{\frac{1}{\left|C_{elements }^{(j)}\right|} \sum_{i \in C_{elements }^{(j)}} h_{i} | C_{elements }^{(j)} \in C_{elements }\right\} \quad (10)\)

为新隐藏状态\(H'\)中的每个向量准确分配位置 ID 至关重要，尤其是对于使用旋转嵌入的模型 —— 位置 ID 决定输入图像的结构或输入视频的时间依赖关系。为使统计结果与常规推理保持低差异，将\(H'\)中每个向量的位置 ID 设为其对应聚类中心的位置 ID。完整的 PACT 流程如算法 3 所示。

需注意，DBDPC、EUTI 及 PACT 均不依赖文本令牌，因此视觉令牌缩减独立于文本上下文，使其非常适合多轮对话场景。

#### 比例注意力

令牌合并会降低其在注意力机制中的影响力，若大量重要令牌被合并，可能导致性能下降。为解决这一问题，本文使用比例注意力 [7]（附录 E 详细说明）。

#### 令牌缩减层 L 的选择

为最大化计算收益，需选择语言模型的早期层 L 进行视觉令牌缩减；同时，所选层的键向量需具备足够的差异性，以实现有效聚类和剪枝。因此，我们选择键向量最大距离足够大的最早层。图 3 显示，LLaVA-OneVision-7B 的初始层中，视觉令牌对应的键向量相似度较高，缺乏有效剪枝和聚类所需的独特特征。

**算法 2 DBDPC（距离有界密度峰值聚类）**输入：截断距离\(d_c \in \mathbb{R}^+\)；归一化因子\(d_n \in \mathbb{R}^+\)；向量集\(\{u_i \in \mathbb{R}^{d_1}\}_{i=1}^q\)输出：聚类中心索引\(C_{centers }\)；每个聚类的元素索引\(C_{elements }\)

1. 计算所有向量对之间的距离：
    
    对所有向量对\((u_i, u_j)\)：\(d_{i j}=1-\frac{u_i \cdot u_j}{\left\| u_i\right\| _2\left\| u_j\right\| _2}\)
2. 计算每个向量的局部密度：
    
    对所有向量\(u_i\)：\(\rho_{i}=\sum_{j} e^{-d_{i j} / d_{n}}\)
3. 按\(\rho_i\)降序排序向量，得到索引\([i_1, i_2, ..., i_q]\)
4. 初始化聚类中心和聚类元素集：\(C_{centers } = \{i_1\}\)，\(C_{elements } = \{i_1 : \emptyset\}\)
5. 选择聚类中心：
    
    对排序后的所有索引\(i_k\)：
    
    若\(\min_{s \in C_{centers }} d_{i_k s} > d_c\)：\(C_{centers } = C_{centers } \cup \{i_k\}\)\(C_{elements }[i_k] = \emptyset\)
6. 分配向量到聚类：
    
    对所有索引i：\(s_i = argmin_{s \in C_{centers }} d_{i s}\)\(C_{elements }[s_i] = C_{elements }[s_i] \cup \{i\}\)
7. 返回\(C_{centers }\)和\(C_{elements }\)

**算法 3 PACT**输入：隐藏状态\(H = [h_1, ..., h_n] \in \mathbb{R}^{n×d}\)；键和查询矩阵\(K, Q \in \mathbb{R}^{n×n_h×d_h}\)；位置 ID\(P = [p_1, ..., p_n]\)；剪枝比例\(\lambda \in[0,1]\)；截断距离\(d_c > 0\)；容忍系数\(\alpha > 0\)输出：合并后的隐藏状态\(H'\)；新位置 ID\(P'\)

1. 识别重要令牌和不重要令牌：\(S_{important }, S_{unimportant } \leftarrow EUTI(H, K, Q, \lambda)\)
2. 用 DBDPC 聚类重要令牌：\(K' \leftarrow \{k_i \in K | i \in S_{important }\}\)\(C_{centers }, C_{elements } \leftarrow DBDPC(K', d_c, d_n)\)
3. 将不重要令牌分配到足够近的聚类：
    
    对所有\(i \in S_{unimportant }\)：\(s_i \leftarrow argmin_{s} d_{i s}\)
    
    若\(d_{i s_i} < \alpha \cdot d_c\)：\(C_{elements }[s_i] = C_{elements }[s_i] \cup \{i\}\)
4. 合并隐藏状态并分配位置 ID：
    
    对所有\(s \in C_{centers }\)：\(h'_s \leftarrow \frac{1}{|C_{elements }[s]|} \sum_{i \in C_{elements }[s]} h_i\)\(p'_s \leftarrow p_s\)
5. 返回\(H' = [h'_s]_{s \in C_{centers }}\)和\(P' = [p'_s]_{s \in C_{centers }}\)

## 4 实验

### 4.1 评估数据集

本文使用多种基准数据集评估 PACT 的有效性，与 LLaVA-OneVision-7B 的评估数据集一致，涵盖单图像、多图像和视频任务：

- 文本丰富文档任务：AI2D [23]、TextVQA [44]、ChartQA [36]、DocVQA [37]、InfographicVQA [38]（评估令牌缩减时的性能保持能力）；
- 跨学科推理任务：MME [16]、MMBench [51]、MMVet [49]、MathVerse [56]、MathVista [33]、MMMU [52]、MMStar [9]、ScienceQA [32]；
- 真实场景与视觉聊天鲁棒性任务：Vibe-Eval [39]、MM-LiveBench [6]、LLaVA-BenchWilder [26]；
- 跨图像推理任务：LLaVA-Interleave Bench [26]、MuirBench [46]；
- 视频理解任务：ActivityNet-QA [50]、MLVU [57]、VideoMME [17]、EgoSchema [35]、PerceptionTest [40]；
- 视频对话任务：Video-ChatGPT [34]。

### 4.2 评估设置

对比方法包括与 PACT 类似的单层出缩减方法（如 FastV 和基于聚类的视觉令牌缩减），以及渐进式令牌缩减方法（如 ToME [7]）、视觉编码器后缩减方法（如 PruMerge、HiReD）和深层令牌移除方法（如 VTW）。对于单层出缩减方法，缩减率定义为 “1 - 缩减后视觉令牌数 / 缩减前视觉令牌数”；对于其他方法，调整参数以确保所有层的平均视觉令牌数与单层出缩减方法在相同缩减率下一致。

所有聚类算法评估均采用比例注意力（可显著提升高缩减率下的性能）；为保证统计一致性，需为缩减后的视觉令牌正确分配位置 ID（附录 F 详细说明分配策略）。实验均在单张 A100 GPU 上进行。

### 4.3 实验结果

本文在 LLaVA-OneVision-7B、InternVL2-8B、Qwen2-VL-7B-Instruct 和 LLaVA-1.6-Mistral-7B 四种模型上，将 PACT 与 FastV [10]、VTW [30]、ToME [7]、PruMerge [43] 和 HiRED [3]（仅适用于 LLaVA-1.6）进行对比，结果如下：

#### 性能对比

如图 4-7 所示，在相同缩减率和相同吞吐量下，PACT 在四种模型上均持续优于其他方法：

- VTW 在缩减率超过 40% 后性能显著下降，表明深层令牌移除的局限性；
- FastV 和 ToME 在高缩减率下表现不佳；
- PruMerge 和 HiRED 即使在低缩减率下也存在性能退化；
- PACT 在高缩减率下仍保持可接受性能。

表 2 显示，PACT 应用于 LLaVA-OneVision-7B 时，在大多数测试数据集上优于其他方法（其他模型的详细结果见附录 J）。

#### 效率对比

表 1 展示了在 LLaVA-OneVision-7B 上，当 “方法 - 参考指标比”（Approach-to-Reference Metric Ratio）为 98.6% 时（反映模型原始能力的保留程度），各方法的缩减率、吞吐量和 GPU 最大内存消耗：

- PACT 实现 71.3% 的缩减率，GPU 内存减少 31%，速度提升至 225%；
- FastV 由于注意力分数计算成本高，GPU 内存消耗相对较高。

#### 聚类算法对比

如图 8 所示，DBDPC 在视觉令牌缩减任务上持续优于层次聚类 [1]、k-means [2]、DPC [5] 和 DBSCAN [15]，在相同缩减率下性能退化更小，计算效率更高。

#### 剪枝指标对比

如图 4 所示，EUTI 在相同缩减率下优于 FastV，且无需计算注意力分数，无 GPU 内存开销。

表 1：LLaVA-OneVision-7B 上各方法的缩减率、吞吐量和 GPU 内存消耗（方法 - 参考指标比 = 98.6%）

|指标|无缩减|PACT（本文方法）|FastV|VTW|ToME|
|---|---|---|---|---|---|
|缩减率|0%|71.3%|50%|25%|40%|
|吞吐量占比|100%|225%|165%|160%|137%|
|GPU 最大内存消耗（GB）|27.4|19.05|30.4|19.2|21.4|

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

### 4.4 消融实验

#### PACT 组件有效性

如图 4 所示，PACT 在各种缩减率下均优于单独使用 DBDPC 或 EUTI，验证了剪枝与聚类结合的协同效应 —— 可同时解决视觉令牌的无关性和冗余性问题。

#### DBDPC 组件消融

如图 9 所示，DBDPC 的各组件（令牌合并、比例注意力、位置 ID 分配、键向量使用）均对性能有积极贡献：

- 正确分配位置 ID 至关重要（反映图像结构和视频时间顺序）；
- 比例注意力在高缩减率下效果显著；
- 令牌合并在缩减率超过 50% 后提升性能；
- 键向量更适合基于余弦相似度的距离计算（与注意力机制的点积特性匹配）。

#### EUTI 组件消融

如图 9 所示，结合全局查询分数和隐藏状态范数的重要性指标，性能优于单独使用任一指标，表明两者提供了视觉令牌重要性的互补信息。

#### PACT 其他组件消融

如图 10 所示：

- 重新纳入聚类中心附近的误判不重要令牌，可在所有缩减率下提升性能；
- 本文提出的缩减层选择方法有效（附录 K 提供更多数值结果）。

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27400%27%20height=%27256%27/%3e)![image](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjI1NiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==)

## 5 结论

本文提出 PACT 方法，同时解决视觉令牌的无关性和冗余性问题。PACT 是一种即插即用的解决方案，无需额外训练；不依赖文本令牌进行视觉令牌缩减，适合多轮对话场景；且独立于视觉编码器和连接器架构，可广泛应用于各类视觉语言模型。实验结果证实，视觉语言模型中的视觉令牌数量存在不必要的冗余，为有效令牌缩减提供了有价值的见解，也为未来设计更高效的 VLM 连接器和架构开辟了方向。

## 6 致谢

本研究得到法国农业信贷银行集团与巴黎综合理工学院合作的 “可信负责任人工智能” 研究 chair 资助，并获得法国国家计算中心（GENCI）分配的 IDRIS 高性能计算资源支持（编号：2024-AD011014793R1）。

（参考文献部分按原文保留，此处省略）

---

要不要我帮你整理一份**PACT 核心技术与实验结果提炼文档**？包含方法流程、关键参数、性能对比核心数据和消融实验结论，方便快速掌握核心价值。