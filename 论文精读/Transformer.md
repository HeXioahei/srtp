可以结合另一篇笔记来理解，看李宏毅老师的self-attention课程时做的笔记。



在transformer出来之前是有attention的，它一般放在encoder和decoder中间。但以前encoder和decoder是用卷积来完成的。而transformer去掉了所有的循环和卷积，只用attention，且主要是多头自注意力机制。

RNN是串行，难以并行；而self-attention可并行。

用Multi-Head来模拟CNN的多输出通道功能，提取多方面的信息。

**模型**：



![807c8c65-9a25-485d-9df2-2aeb39c96cec](file:///C:/Users/Lenovo/Pictures/Typedown/807c8c65-9a25-485d-9df2-2aeb39c96cec.png)



注意力机制可以直接看到全局的信息，不用从左到右。在encoder部分，我们允许它看到全部信息，这样方便我们对每个位置的特征做判断。但是，在decoder部分，我们不允许它看到全局的信息，因为decoder是要进行输出的，输出是要按顺序来的。所以我们需要Masked来遮掩当前时刻t后面的信息，只读取encoder结果的前t个时刻的输出。

Position Encoding的作用：因为embedding后进入attention中是没有顺序信息的，所以我们需要添加一个position来表示每个序列的顺序。

Norm用的是LM。

**LayerNorm和BatchNorm的区别**：



![f235c24c-3c63-49e3-a69b-f5bcbc893332](file:///C:/Users/Lenovo/Pictures/Typedown/f235c24c-3c63-49e3-a69b-f5bcbc893332.png)



**Scaled Dot-Product Attention:**



![e830f773-fb61-4d2d-921d-91fc214935cd](file:///C:/Users/Lenovo/Pictures/Typedown/e830f773-fb61-4d2d-921d-91fc214935cd.png)

![be9af6c7-aa5a-42ef-bc9d-de1b69a84f7a](file:///C:/Users/Lenovo/Pictures/Typedown/be9af6c7-aa5a-42ef-bc9d-de1b69a84f7a.png)



（为什么要scaled？——为了缩小softmax的输入，使得softmax的结果不会十分接近于0和1，这样才能使得梯度没那么快消失。）

mask具体怎么做呢？他就是将t时刻后面的K的值都设置为一个很大很大的负数，大概是-1e10，这样在softmax的结果就会是0了，就没有任何结果了。



自注意力机制与注意力机制的不同点在于，前者的q、k、v是由同一个输入复制三份得来的。



**不同模型的算法复杂度比较：**



![89b08a8b-7c3a-4477-b4b8-daf492c4387a](file:///C:/Users/Lenovo/Pictures/Typedown/89b08a8b-7c3a-4477-b4b8-daf492c4387a.png)



Transformer架构虽然比其他架构简单，计算起来更快，但是需要更多的数据和更大的模型才能训练出和其他模型一样的效果。



# transformer的反向传播是如何进行的？

Transformer在NLP任务中的学习过程基于监督学习，通过前向传播计算预测结果，再通过反向传播梯度更新模型参数。以下是其学习机制及梯度传播的详细步骤：

---

### **1. Transformer的基本结构**

- **编码器（Encoder）**：由多个编码器层堆叠，每层包含：
  - **多头自注意力机制**（Multi-Head Self-Attention）
  - **前馈神经网络**（Feed-Forward Network）
  - **残差连接**（Residual Connection）和**层归一化**（Layer Normalization）
- **解码器（Decoder）**：同样由多个解码器层堆叠，每层包含：
  - **掩码多头自注意力**（Masked Multi-Head Self-Attention）
  - **编码器-解码器注意力**（Encoder-Decoder Attention）
  - **前馈神经网络**、残差连接和层归一化
- **输入输出处理**：
  - **嵌入层**（Embedding Layer）将词转换为向量。
  - **位置编码**（Positional Encoding）注入序列位置信息。

---

### **2. 前向传播过程**

1. **输入处理**：
   - 输入序列通过嵌入层转换为向量，并添加位置编码。
2. **编码器层**：
   - **自注意力计算**：每个词向量生成Query（Q）、Key（K）、Value（V），计算注意力权重并加权融合。
   - **前馈网络**：对注意力输出进行非线性变换。
   - **残差连接与层归一化**：保留原始输入信息并稳定训练。
3. **解码器层**：
   - **掩码自注意力**：防止解码时看到未来信息。
   - **编码器-解码器注意力**：解码器关注编码器的输出。
   - 类似编码器的前馈网络和归一化。
4. **输出预测**：
   - 最终解码器输出通过线性层和softmax生成词的概率分布。

---

### **3. 反向传播与梯度计算**

反向传播通过链式法则从损失函数反向计算各参数的梯度，具体步骤如下：

#### **（1）损失函数**

- 常用**交叉熵损失**（Cross-Entropy Loss），衡量预测概率分布与真实标签的差异。
- 例如，在机器翻译中，损失函数为每个输出位置的预测词与目标词的交叉熵之和。

#### **（2）梯度传播路径**

梯度从输出层开始，逐层反向传播至输入层：

1. **输出层梯度**：
   
   - 计算softmax输出的梯度，反向传播至解码器的最后一层。

2. **解码器内部梯度**：
   
   - **线性变换层**：输出概率的梯度传播到解码器末端的线性层权重。
   - **解码器层**：
     - **前馈网络**：梯度通过激活函数（如ReLU）传播到其权重矩阵。
     - **编码器-解码器注意力**：梯度传播到Q、K、V矩阵及拼接后的线性层。
     - **掩码自注意力**：梯度传播到对应的Q、K、V矩阵。

3. **编码器内部梯度**：
   
   - **前馈网络**：类似解码器的梯度传播。
   - **自注意力机制**：梯度传播到Q、K、V矩阵。
   - **残差连接**：梯度分为两支（原始输入和变换后输出），缓解梯度消失。

4. **嵌入层与位置编码**：
   
   - 梯度传播到词嵌入矩阵。若位置编码为可学习参数，其梯度也会被更新。

#### **（3）关键组件梯度计算**

- **自注意力机制**：
  - 输入矩阵\( X \)经过线性变换生成Q、K、V（权重矩阵\( W^Q, W^K, W^V \)）。
  - 梯度通过注意力权重（Softmax输出）传播到Q、K、V，进而更新\( W^Q, W^K, W^V \)。
- **层归一化**：
  - 计算均值与方差，梯度通过归一化后的值传播到缩放（γ）和平移（β）参数。
- **残差连接**：
  - 梯度直接传递到上一层，避免深层网络中的梯度消失。

---

### **4. 梯度更新与优化**

- **优化器**：常用Adam优化器，根据梯度方向和大小更新参数。
- **学习率调整**：可能使用预热（Warm-up）策略，逐步增大学习率以稳定训练。
- **梯度裁剪**：防止梯度爆炸，限制梯度幅值。

---

### **5. 示例：机器翻译任务中的梯度流动**

假设输入为句子“Hello world”，目标输出为“你好 世界”：

1. **前向传播**：
   - 编码器将“Hello world”编码为上下文向量。
   - 解码器逐步生成“你”→“好”→“世”→“界”，每一步依赖前一步的输出。
2. **损失计算**：
   - 每个解码位置的输出与目标词（如“你”“好”）计算交叉熵损失。
3. **反向传播**：
   - 损失梯度从“界”反向传播到解码器的每一步，再通过编码器-解码器注意力传递到编码器。
   - 最终更新所有参数（嵌入、注意力权重、前馈网络等）。

---

### **6. 总结**

- **反向传播位置**：所有可训练参数均参与梯度计算，包括：
  - 嵌入层权重。
  - 自注意力中的Q、K、V矩阵。
  - 前馈神经网络权重。
  - 层归一化的γ和β参数。
- **核心机制**：通过链式法则计算梯度，优化器更新参数以最小化损失。
- **优势**：Transformer的并行计算能力和多头注意力机制使其在长序列任务中高效且稳定。



# transformer的预训练和训练有什么不一样吗？

Transformer的预训练（Pre-training）和下游任务训练（Fine-tuning）是模型开发流程中的两个不同阶段，目标、数据、方法均有显著区别。以下是两者的核心差异及技术细节：

---

### 一、目标差异

1. **预训练**  
   
   - **核心目标**：通过海量无标注数据（如Wikipedia、Common Crawl）学习语言的**通用表示**（例如词义、句法、语义关联）。  
   - **任务形式**：采用**自监督学习**（Self-supervised Learning），设计无需人工标注的预训练任务（如掩码语言建模、文本生成）。  
   - **典型模型**：BERT（双向语言模型）、GPT（自回归生成）、T5（文本到文本统一框架）。

2. **下游任务训练（微调）**  
   
   - **核心目标**：基于预训练模型，使用少量标注数据（如分类标签、问答对）**适配特定任务**（如情感分析、机器翻译）。  
   - **任务形式**：**有监督学习**，直接优化任务相关损失函数（如交叉熵、BLEU分数）。  
   - **典型任务**：文本分类、命名实体识别、摘要生成。

---

### 二、数据与资源需求对比

| **维度** | **预训练**         | **下游任务训练**    |
| ------ | --------------- | ------------- |
| 数据量    | 大规模（TB级文本）      | 小规模（千/万级标注样本） |
| 标注需求   | 无标注（自生成伪标签）     | 需人工标注         |
| 计算资源   | 极高（数千GPU小时）     | 较低（数GPU小时）    |
| 数据分布   | 通用领域（覆盖多样化语言现象） | 特定领域（如医疗、金融）  |

---

### 三、训练方法差异

1. **预训练的关键技术**  
   - **自监督任务设计**：  
- **BERT**：随机遮蔽15%的输入词，预测被遮蔽词（MLM）及句子关系（NSP）。  
- **GPT**：基于上文预测下一个词（自回归建模）。  
- **T5**：将文本重构任务统一为“输入-输出”格式（如填空、翻译）。  
  - **训练策略**：  
- 使用大批次（Batch Size ≥ 1024）和长序列（如512/1024 tokens）。  
- 优化器常采用AdamW，学习率预热（Learning Rate Warmup）。  
- 动态遮蔽（Dynamic Masking）增强鲁棒性。
2. **下游任务训练的关键技术**  
   - **模型适配**：  
- 添加任务特定层（如分类头、解码器）。  
- 调整输入格式（如添加[CLS]标记用于分类）。  
  - **训练策略**：  
- 小学习率（如预训练的1/10）避免覆盖预训练知识。  
- 部分参数冻结（如仅微调顶层Transformer块）。  
- 数据增强缓解小样本过拟合（如回译、随机删除）。  

---

### 四、参数更新模式

| **阶段** | **参数更新范围**               | **梯度传播方向**  |
| ------ | ------------------------ | ----------- |
| 预训练    | 更新全部参数（嵌入层+Transformer层） | 自监督任务损失反向传播 |
| 下游任务训练 | 通常仅更新顶层+任务头              | 任务损失反向传播    |

**示例**：BERT微调时，仅更新最后2层Transformer和分类头的参数，保留底层参数不变。

---

### 五、性能影响与挑战

1. **预训练的挑战**  
   
   - **计算成本**：训练175B参数的GPT-3需数千张V100 GPU。  
   - **数据偏见**：通用语料可能隐含性别、种族偏见，需去偏处理。  
   - **长尾现象**：低频词/语法可能未被充分学习。

2. **下游任务的挑战**  
   
   - **灾难性遗忘**：过度微调可能破坏预训练学到的通用知识。  
   - **领域迁移**：医疗领域微调需额外领域适配（如继续预训练）。  
   - **小样本学习**：标注数据不足时需Prompt Tuning等少样本技术。

---

### 六、典型流程示例

1. **预训练流程**  
   
   ```text
   输入：[CLS] The capital of France is [MASK]. [SEP]  
   自监督任务：预测[MASK]=Paris → 损失函数为MLM交叉熵  
   输出：更新所有Transformer层参数
   ```

2. **下游任务训练（分类）**  
   
   ```text
   输入：[CLS] This movie is fantastic! [SEP]  
   任务头：[CLS]向量→全连接层→情感标签（正面/负面）  
   损失函数：分类交叉熵 → 仅更新分类头+顶层参数
   ```

---

### 七、总结

| **核心区别** | **预训练**           | **下游任务训练**       |
| -------- | ----------------- | ---------------- |
| 目标       | 学习通用语言表示          | 适配具体任务           |
| 数据依赖     | 无标注大数据            | 有标注小数据           |
| 计算强度     | 极高                | 低至中等             |
| 可迁移性     | 跨任务通用（一次预训练，多次微调） | 任务专属（需为每个任务单独微调） |

**技术趋势**：  

- **参数高效微调**：LoRA（低秩适配）、Adapter Layers等技术减少微调参数量。  
- **统一预训练框架**：Prompt Tuning将下游任务转化为预训练任务形式，减少微调需求。  
- **多模态预训练**：CLIP、Flamingo等模型融合文本与图像预训练，扩展应用场景。



# GPT在预训练时的自回归预测

> 

GPT预训练的自回归预测是其核心训练机制，通过序列的逐步生成实现对语言规律的建模。以下从技术原理、实现细节、数学形式化及优化策略等多个角度展开分析：

---

### 一、自回归预测的数学本质

1. **概率分解原理**  
   自回归模型将序列的联合概率分解为**条件概率链式乘积**，即：  
   
   $$
   P(x_{1:T}) = \prod_{t=1}^T P(x_t | x_{<t})
   $$
   
   其中 $x_{<t} = x_1, x_2, ..., x_{t-1}$，模型通过最大化整个序列的对数似然进行训练。

2. **条件概率建模**  
   GPT使用Transformer解码器层（含掩码自注意力）对条件概率 $P(x_t | x_{<t})$ 进行建模。每个位置的预测仅依赖前序信息，无法访问后续token（通过掩码机制实现）。

---

### 二、具体实现流程

#### 1. **输入处理与序列生成**

- **Token化与嵌入**  
  输入文本被分割为子词（Subword）序列（如BPE算法），每个token转化为高维向量 $e_t = \text{Embedding}(x_t) + \text{PositionalEncoding}(t)$，嵌入层包含词义和位置信息。

- **掩码自注意力**  
  每一层Transformer解码器中，自注意力矩阵通过 **上三角掩码（Upper Triangular Mask）**  实现单向可见性：  
  
  $$
  \text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M\right)V
  $$
  
  其中掩码矩阵 $M$ 的上三角元素设为 $-\infty$，强制模型仅关注当前位置之前的token。

#### 2. **预测机制**

- **逐位置预测**  
  对于输入序列 $[x_1, x_2, ..., x_{t-1}]$，模型通过多层Transformer解码器处理后，在最后一层输出隐状态 $h_{t-1}$，再通过线性层+softmax计算下一个token的概率分布：  
  
  $$
  P(x_t | x_{<t}) = \text{softmax}(W_{\text{vocab}} \cdot h_{t-1} + b)
  $$
  
  其中 $W_{\text{vocab}}$ 是词表投影矩阵。

- **训练损失计算**  
  采用交叉熵损失函数，对每个位置的预测误差求和：  
  
  $$
  \mathcal{L} = -\sum_{t=1}^T \log P(x_t | x_{<t})
  $$
  
  通过反向传播优化所有Transformer层参数。

---

### 三、关键技术特征

#### 1. **单向上下文建模**

- **掩码机制限制**  
  与BERT的双向注意力不同，GPT的掩码自注意力强制模型仅使用左侧上下文，这使得其天然适合生成任务（如文本续写、对话生成）。
- **生成式能力**  
  自回归预测使GPT在推理时可实现**逐token生成**：每次预测新token后将其追加到输入序列，形成动态增长的上下文窗口。

#### 2. **大规模语料训练**

- **数据规模**  
  GPT-3使用的训练数据包含超3000亿token，覆盖网页、书籍、代码等多领域文本，确保模型学习到通用语言规律。
- **动态批处理**  
  训练时采用动态序列长度（如2048 tokens），通过梯度累积实现大批量训练（batch size达数百万token）。

---

### 四、优化策略与工程实现

#### 1. **模型架构优化**

- **解码器堆叠**  
  GPT-3包含96层Transformer解码器，每层含12288维隐状态，通过残差连接和层归一化（LayerNorm）稳定训练。
- **参数高效性**  
  使用 **稀疏注意力（Sparse Attention）**  减少计算量，例如在长序列中仅计算局部窗口内的注意力权重。

#### 2. **训练加速技术**

- **混合精度训练**  
  采用FP16/FP32混合精度计算，结合梯度缩放（Gradient Scaling）防止下溢出。
- **分布式并行**  
  模型参数分片到多个GPU，通过张量并行（Tensor Parallelism）和流水线并行（Pipeline Parallelism）实现超大规模训练。

---

### 五、与其他模型的对比

| **特性** | **GPT（自回归）** | **BERT（双向）**     |
| ------ | ------------ | ---------------- |
| 注意力机制  | 掩码自注意力（单向）   | 全连接自注意力（双向）      |
| 预训练任务  | 下一个词预测       | 掩码语言建模（MLM）+句子关系 |
| 生成能力   | 强（可动态生成序列）   | 弱（需额外解码器）        |
| 上下文理解  | 局部依赖建模       | 全局依赖建模           |
| 典型应用场景 | 文本生成、对话系统    | 文本分类、实体识别        |

---

### 六、实例演示

假设输入序列为 `["The", "quick", "brown"]`，GPT的自回归预测流程如下：

1. **Step 1**：输入 `["The"]` → 预测 `"quick"`（概率最高）
2. **Step 2**：输入 `["The", "quick"]` → 预测 `"brown"`
3. **Step 3**：输入 `["The", "quick", "brown"]` → 预测 `"fox"`

每一步的预测均基于累积的左侧上下文，最终生成完整句子 `"The quick brown fox"`。

---

### 七、局限性分析

1. **长程依赖挑战**  
   随着生成序列增长，早期token的影响可能被稀释（因注意力权重衰减）。
2. **误差累积**  
   自回归生成中单个token的预测错误会传播至后续步骤，导致语义偏移。
3. **计算复杂度**  
   生成N个token需进行N次前向计算，实时性受限。

---

### 八、前沿改进方向

1. **非自回归生成（NAR）**  
   如Google的 **NAT（Non-Autoregressive Transformer）**  通过并行预测多个token加速生成。
2. **检索增强生成**  
   结合外部知识库（如RETRO模型），减少对纯自回归建模的依赖。
3. **可控生成技术**  
   通过Prompt Engineering或Adapter Layers实现生成内容的方向性控制。

---

### 总结

GPT的自回归预训练通过单向上下文建模与逐步预测机制，实现了对语言生成规律的高效学习。其核心在于掩码自注意力架构与大规模语料训练的协同作用，虽在双向理解上存在局限，但在生成任务中展现出不可替代的优势。未来结合检索、可控生成等技术，可能进一步突破自回归模型的边界。
