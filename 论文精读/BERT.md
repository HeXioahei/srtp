GPT是单向的，用上文的信息来预测未来；BERT是双向的。ELMo的架构是RNN；BERT的架构是Transformer。



两个步骤：

1. pre-training(预训练)：先预训练得到初始权重

2. fine-tuning(微调)：再根据得到的初始权重对特定的数据进行训练并进行微调。


