# backbone等概念

[(8 封私信 / 6 条消息) 深度学习网络中backbone是什么意思? - 知乎](https://www.zhihu.com/question/399611596)



# 零样本分类和少样本分类

### **零样本图像分类（Zero-Shot Image Classification）**

#### **定义**

零样本分类（Zero-Shot Learning, ZSL）是指模型在训练阶段**从未见过某个类别的任何样本**，但在测试时仍能正确识别该类别的能力。其核心思想是通过**语义关联**（如文本描述、属性标签等）将已知类别（训练集）的知识迁移到未知类别（测试集）。

#### **核心原理**

1. **语义嵌入（Semantic Embedding）**：  
   - 将图像特征（如卷积神经网络提取的特征）和类别语义（如文本描述、属性向量）映射到同一语义空间。  
   - 例如，使用CLIP模型将图像和文本编码到同一空间，通过相似度匹配进行分类。  
2. **知识迁移**：  
   - 利用已知类别与未知类别之间的语义关系（如“斑马”和“马”共享“有蹄子”“黑白条纹”等属性），推断未知类别的特征。

#### **典型方法**

- **基于属性的模型**：为每个类别定义属性（如“有翅膀”“会游泳”），通过属性匹配分类。  
- **基于文本的模型**：利用自然语言描述（如“一种黑白条纹的非洲马”）与图像对齐，如CLIP、ALIGN。  

#### **应用场景**

- 识别训练数据中未出现的新类别（如新物种、罕见物体）。  
- 减少对标注数据的依赖，适应开放世界（Open-World）场景。  

#### **挑战**

- 语义鸿沟：图像特征与文本描述的匹配可能存在偏差。  
- 领域偏移：训练和测试的语义空间不一致时性能下降。  

---

### **少样本分类（Few-Shot Classification）**

#### **定义**

少样本分类（Few-Shot Learning, FSL）是指每个新类别仅有**极少量标注样本**（如1~5张图），模型通过少量示例快速适应新任务。核心目标是**从有限样本中泛化**，避免过拟合。

#### **核心原理**

1. **元学习（Meta-Learning）**：  
   - 训练模型掌握“如何学习新任务”的能力。  
   - 例如，在训练阶段模拟少样本场景（如5-way 1-shot任务），通过多次任务迭代优化模型。  
2. **度量学习（Metric Learning）**：  
   - 学习一个相似性度量函数（如欧氏距离、余弦相似度），将测试样本与支持集（少量样本）比对。  
   - 典型方法：原型网络（Prototypical Network）、关系网络（Relation Network）。  

#### **典型方法**

- **基于微调（Fine-tuning）**：预训练模型 + 少量数据微调最后一层（需谨慎防止过拟合）。  
- **基于记忆（Memory-Augmented）**：通过外部记忆模块存储和检索知识，如MANN。  

#### **应用场景**

- 数据标注成本高昂的领域（如医学图像）。  
- 快速适应新类别（如用户自定义标签）。  

#### **挑战**

- 过拟合：少量样本难以覆盖类内多样性。  
- 跨领域泛化：训练任务与测试任务的分布差异。  

---

### **对比总结**

| **维度**   | **零样本分类（ZSL）** | **少样本分类（FSL）**            |
| -------- | -------------- | ------------------------- |
| **训练数据** | 目标类别**无任何样本**  | 目标类别有**1~几十个样本**          |
| **依赖信息** | 类别语义（文本、属性）    | 少量标注样本                    |
| **核心方法** | 跨模态对齐（图像-文本）   | 元学习、度量学习                  |
| **典型模型** | CLIP、ALIGN     | Prototypical Network、MAML |
| **适用场景** | 完全未知的新类别       | 标注极少但需快速适应的新任务            |
| **主要挑战** | 语义鸿沟、领域偏移      | 过拟合、样本多样性不足               |

---

### **实例说明**

1. **零样本分类**：  
   
   - 训练时：模型学习“马”“老虎”的图片及其文本描述（如“有鬃毛”“有条纹”）。  
   - 测试时：输入一张斑马图片，模型通过文本关联（“黑白条纹的非洲马”）正确分类。  

2. **少样本分类**：  
   
   - 支持集：提供5张不同角度的“斑马”图片（1-shot）。  
   - 查询集：模型通过比对相似性，识别新的斑马图片。  

---

### **技术趋势**

- **零样本与少样本结合**：如广义零样本学习（GZSL），允许测试集包含已知和未知类别。  
- **多模态预训练**：CLIP等模型通过海量图文对学习通用表征，显著提升零样本和少样本性能。  
- **自监督学习**：利用无标注数据预训练，增强少样本场景下的泛化能力。  

通过结合语义推理和少量示例，这两种方法正在推动AI系统向更灵活、更高效的方向发展。



# SOTA

SOTA是**State-of-the-Art**的缩写，直译为“当前最先进技术”，在学术和工业界特指**在特定任务或基准测试中达到最佳性能的方法或模型**。

---

### **具体解释**

1. **含义**：  
   
   - 当说某个模型“建立SOTA性能”时，意味着它在公开的基准测试（如ImageNet分类、COCO目标检测等）中超越了此前所有已知方法，成为该任务上的性能最优解。
   - 例如，RemoteCLIP在图像分类、跨模态检索等任务中刷新了最高准确率，因此被称为“SOTA”。

2. **上下文中的意义**：  
   
   - 原文强调尽管RemoteCLIP设计简单，但通过**数据为中心的方法**（如高质量数据清洗、去重、多源数据融合），其性能仍能超越复杂模型，这说明数据质量对模型效果的影响可能比模型结构更大。  
   - 类似的例子如BioMedCLIP，它通过医学领域专业数据训练，成为医学影像分析中的SOTA模型，同样验证了“领域内数据”的重要性。

---

### **扩展知识**

- **SOTA的常见评判标准**：  
  
  - 在权威数据集（如GLUE、SuperGLUE）上的准确率、F1分数等指标。  
  - 实际应用中的推理速度、内存占用等工程指标（如“Pareto SOTA”）。  

- **SOTA的竞争性**：  
  
  - 学术界和产业界会持续发布新模型争夺SOTA地位（例如BERT → RoBERTa → DeBERTa → ChatGPT的演进）。  
  - 某些任务（如ImageNet分类）的SOTA提升已进入边际效益递减阶段，需结合创新突破（如Transformer取代CNN）。

---

### **示例说明**

假设目标任务是图像分类：

- 旧SOTA模型：ResNet-50在ImageNet上准确率76%。  
- 新模型RemoteCLIP：准确率提升至82%，则RemoteCLIP成为新SOTA。

---

### **与其他术语的对比**

| 术语           | 含义               | 与SOTA的关系           |
| ------------ | ---------------- | ------------------ |
| **Baseline** | 基准模型（通常为简单或经典方法） | SOTA需显著优于Baseline  |
| **SoTA**     | 同SOTA（拼写变体）      | 完全等价               |
| **Novelty**  | 创新性（不一定性能最优）     | SOTA模型通常需兼具Novelty |

---

总结来说，SOTA是技术进步的标志，而原文通过RemoteCLIP的例子说明：**即使模型设计简单，高质量数据也能推动性能达到SOTA**，这为构建基础模型提供了重要启示。



# distribution shift

**Distribution Shift（分布偏移）** 是指机器学习模型在训练阶段和实际应用阶段所面对的数据分布（data distribution）不一致的现象。这种不一致会导致模型在实际应用中的性能下降，因为模型在训练时学到的规律可能不再适用于新的数据环境。

---

### **常见的分布偏移类型**

1. **协变量偏移（Covariate Shift）**  
   
   - **特征分布变化**：输入特征（输入变量）的分布发生变化，但输入到输出的映射关系（如条件概率 \(P(y|x)\)）保持不变。  
   - **例子**：训练数据中的图片是白天的场景，但测试数据是夜间场景。

2. **标签偏移（Label Shift）**  
   
   - **标签分布变化**：输出标签（目标变量）的分布发生变化，但标签到特征的映射关系（如条件概率 \(P(x|y)\)）保持不变。  
   - **例子**：训练数据中猫狗图片各占50%，但测试数据中狗占90%、猫占10%。

3. **概念偏移（Concept Shift）**  
   
   - **输入到输出的映射关系变化**：特征和标签之间的关联关系本身发生了变化。  
   - **例子**：经济危机前，“高负债率”可能被模型认为是“高风险”，但经济危机后，由于政策变化，“高负债率”可能不再直接关联高风险。

---

### **为什么分布偏移是问题？**

- 模型在训练时假设训练数据和测试数据来自同一分布（独立同分布，i.i.d.），但实际应用中这一假设常被打破。
- **后果**：模型在新数据上的预测可能不准确，甚至完全失效。

---

### **典型场景举例**

1. **时间变化**：训练数据是历史数据，而测试数据来自未来（如金融预测、疫情趋势分析）。  
2. **领域变化**：训练数据来自实验室环境，测试数据来自真实世界（如自动驾驶）。  
3. **样本偏差**：训练数据未能覆盖所有可能的场景（如人脸识别系统未包含某些肤色的人群）。

---

### **应对分布偏移的方法**

1. **数据层面**  
   - 收集更具代表性的数据，覆盖更多潜在场景。  
   - 数据增强（Data Augmentation）或合成数据生成。  
2. **算法层面**  
   - **领域适应（Domain Adaptation）**：通过迁移学习调整模型，使其适应目标分布。  
   - **鲁棒性训练（Robust Training）**：使用对抗训练或正则化技术增强模型泛化能力。  
3. **监控与更新**  
   - 持续监控模型性能，定期用新数据重新训练模型（Online Learning）。  

---

### **总结**

分布偏移是机器学习实际部署中的核心挑战之一。理解其类型和成因，并采取针对性措施（如领域适应、持续监控），是提升模型鲁棒性和实用性的关键。



# Dense feature

密集特征（Dense Feature）是指在数据中大部分值为非零的浮点数型特征。这类特征通常以连续数值形式存在，例如温度、价格、图像像素值等，每个样本都会包含这些特征且其取值较为密集。与稀疏特征（如类别ID、文本词频等）不同，密集特征不需要通过独热编码（One-Hot Encoding）或嵌入（Embedding）等复杂处理，可以直接输入模型的全连接层（Dense Layer）进行学习。



# IoU

**IoU（Intersection over Union，交并比）**  是计算机视觉中用于衡量两个区域（如边界框、语义分割区域等）重叠程度的指标，广泛应用于目标检测、图像分割等任务中，用于评估预测结果与真实标注（Ground Truth）的匹配精度。

---

### **核心定义**

- **交集（Intersection）** ：预测区域与真实区域的重叠部分面积。

- **并集（Union）** ：预测区域与真实区域的合并总面积（交集 + 各自独立部分）。

- **IoU值**：交集面积与并集面积的比值，计算公式为：
  
  $$
  \text{IoU} = \frac{\text{Intersection}}{\text{Union}} = \frac{A_{\text{pred}} \cap A_{\text{true}}}{A_{\text{pred}} \cup A_{\text{true}}}
  $$
  
  **取值范围**：0（无重叠）到1（完全重合）。

---

### **图解示例**

- **目标检测**：预测框（Predicted BBox）与真实框（Ground Truth BBox）的交并比。  
  ![IoU示意图](https://miro.medium.com/v2/resize:fit:1400/1*5IQh16S2NWEt3g0xGdgTaA.png)  
  
  - 绿色框为真实框，红色框为预测框。
  - 黄色区域为交集，绿色+红色区域为并集。

- **图像分割**：预测掩码（Predicted Mask）与真实掩码（Ground Truth Mask）的像素级重叠率。

---

### **应用场景**

1. **目标检测评估**：
   
   - 判断预测框是否有效：通常设定阈值（如0.5），IoU ≥ 阈值则认为检测正确（True Positive）。
   - 用于非极大值抑制（NMS）：去除重叠率高的冗余预测框。

2. **语义分割评估**：
   
   - 计算每个类别的IoU，再取平均（mIoU）作为模型整体性能指标。

3. **模型训练**：
   
   - 作为损失函数的参考（如IoU Loss），但需结合可导的变体（如GIoU、DIoU）以支持梯度优化。

---

### **计算示例**

假设预测框和真实框的坐标分别为：

- **预测框**：左上角 (2,2)，右下角 (5,5)，面积 = 3×3=9。

- **真实框**：左上角 (3,3)，右下角 (6,6)，面积 = 3×3=9。
1. **计算交集**：
   
   - 交集左上角：(max(2,3), max(2,3)) = (3,3)
   - 交集右下角：(min(5,6), min(5,6)) = (5,5)
   - 交集面积 = 2×2=4

2. **计算并集**：
   
   - 并集面积 = 9 + 9 - 4 = 14

3. **IoU值**：
   
   $$
   \text{IoU} = \frac{4}{14} \approx 0.286
   $$

---

### **优缺点分析**

| **优点**       | **缺点**                         |
| ------------ | ------------------------------ |
| 直观反映重叠程度     | 对非重叠区域敏感（即使预测框靠近真实框但无重叠，IoU=0） |
| 与任务目标直接相关    | 作为损失函数不可导（需使用近似方法如GIoU）        |
| 广泛适用于不同形状的区域 | 对小目标检测误差敏感（像素级误差显著降低IoU）       |

---

### **改进版本**

为解决IoU的局限性，衍生出多种变体：

1. **GIoU（Generalized IoU）**：  
   - 引入最小闭包区域（包围两个框的最小矩形），解决无重叠时的梯度问题。
   - 公式：$$
     \text{GIoU} = \text{IoU} - \frac{\text{闭包区域面积 - 并集面积}}{\text{闭包区域面积}}
     $$

2. **DIoU（Distance IoU）**：  
   - 考虑中心点距离，加速收敛。
   - 公式：$$
     \text{DIoU} = \text{IoU} - \frac{\rho^2}{c^2}
     $$

其中 $ \rho $ 是中心点距离，$ c $ 是闭包区域对角线长度。

3. **CIoU（Complete IoU）**：  
   - 同时考虑重叠率、中心点距离和长宽比。

---

### **总结**

IoU是衡量目标检测或分割结果与真实标注匹配度的核心指标，直观且易于计算。尽管存在对零重叠敏感、不可导等缺点，但其改进版本（GIoU、DIoU等）已广泛应用于模型训练和评估，成为计算机视觉任务中不可或缺的评价工具。

# train from scrath
from scrath 在英文中的意思就是“从零开始、从头开始、白手起家”，引申过来就是不使用预训练文件而直接进行训练.

# Depthwise卷积与Pointwise卷积
[Depthwise卷积与Pointwise卷积 - 知乎](https://zhuanlan.zhihu.com/p/80041030)

# 种子指令
**种子指令（Seed Instructions）** 是指在人工智能（AI）模型训练或生成任务中，用于启动或引导模型行为的一组初始输入或提示。它们通常是简短、明确的指令或示例，帮助模型理解任务要求并生成符合预期的输出。

# 端到端的训练方式
**端到端（End-to-End）训练方式**是一种模型训练方法，整个过程从输入到输出由单一模型完成，无需分阶段或手动设计中间步骤。用这种方式训练复杂的大模型成本会很高。

# 随机掩膜和互补掩膜
* **随机掩膜（Random Mask）**
	- **定义**：通过在图像中随机生成形状、位置或面积不固定的遮挡区域，实现对原图特定区域的动态遮蔽。这种掩膜的生成具有概率性和不确定性，常用于数据增强或模拟现实遮挡场景。
	- **核心特征**：
	    - 动态性：每次生成的遮挡区域参数（如位置、面积、形状）均随机变化（如中的`LandmarksRandomMask`模块）
	    - 多样性：支持矩形、不规则图形等多种遮挡形态，甚至可结合随机噪声（如中的`MaskOut`方法将随机模板注入遮挡区域）

* **互补掩膜（Complementary Mask）**
	- **定义**：通过布尔逻辑运算（如AND、OR、NOT）组合两个或多个掩膜，形成覆盖全图且互斥的掩膜对。其中一个掩膜覆盖目标区域，另一个则覆盖其补集区域。
	- **核心特征**：
	    - 逻辑互斥性：两个掩膜的覆盖区域完全互补，满足MA∪MB=IMA​∪MB​=I且MA∩MB=∅MA​∩MB​=∅（如中通过"not"操作生成的细胞质掩膜）
	    - 全域覆盖性：互补掩膜组合后能完整覆盖整幅图像，避免处理盲区

# dpt

DPT（Dense Prediction Transformer）是一种基于**Transformer架构**的深度学习模型，专为**密集预测任务**（Dense Prediction Tasks）设计，例如图像分割、深度估计、语义分割等。它结合了Transformer的全局上下文建模能力和卷积网络（CNN）的局部特征提取优势，在像素级预测任务中表现优异。

---

### **DPT的核心原理**

1. **Transformer骨干网络**：
   
   - 输入图像被分割为多个图像块（patches），每个块通过线性嵌入转换为序列，输入到Transformer编码器中。
   - Transformer通过**自注意力机制**（Self-Attention）捕捉图像全局的上下文信息，弥补传统CNN局部感受野的不足。

2. **多尺度特征融合**：
   
   - DPT通过不同层级的Transformer特征（浅层细节+深层语义）进行融合，生成高分辨率的密集预测结果。
   - 使用**特征金字塔**（Feature Pyramid）或**解码器模块**逐步上采样，恢复空间细节。

3. **轻量化设计**：
   
   - 通过减少Transformer层数或使用混合结构（如CNN+Transformer），平衡计算效率和性能。

---

### **DPT的典型结构**

以图像分割任务为例，DPT的流程如下：

1. **图像分块**：将图像分割为固定大小（如16×16）的块，展开为序列。
2. **Transformer编码器**：通过多层Transformer提取全局特征。
3. **多级特征提取**：从不同Transformer层获取多尺度特征图。
4. **解码器融合**：通过跳跃连接（Skip Connection）和上采样逐步融合多尺度特征，生成像素级预测结果。

---

### **DPT的优势**

1. **全局上下文建模**：自注意力机制能有效捕捉长距离依赖，适合需要全局信息的任务（如场景分割）。
2. **多尺度适应性**：通过特征融合保留细节和语义，提升密集预测的精度。
3. **灵活性**：可适配多种任务（深度估计、语义分割、图像修复等）。

---

### **应用场景**

- **深度估计**：从单张图像预测每个像素的深度值（如DPT在[MiDaS](https://github.com/isl-org/MiDaS)中的应用）。
- **语义分割**：对图像中的每个像素分类（如医学图像分析）。
- **图像增强**：超分辨率、去噪等需要密集输出的任务。

---

### **与CNN的对比**

| **特性** | **DPT**         | **传统CNN** |
| ------ | --------------- | --------- |
| 感受野    | 全局（自注意力）        | 局部（卷积核）   |
| 计算效率   | 较高内存需求（随序列长度增加） | 较低内存需求    |
| 任务适应性  | 适合长距离依赖任务       | 适合局部模式提取  |

---

### **代码示例（PyTorch）**

```python
import torch
from transformers import DPTForDepthEstimation, DPTImageProcessor

# 加载预训练模型和处理器
processor = DPTImageProcessor.from_pretrained("Intel/dpt-large")
model = DPTForDepthEstimation.from_pretrained("Intel/dpt-large")

# 处理输入图像
image = torch.randn(1, 3, 384, 384)  # 假设输入为RGB图像
inputs = processor(images=image, return_tensors="pt")

# 推理
with torch.no_grad():
    outputs = model(**inputs)
    predicted_depth = outputs.predicted_depth  # 输出的深度图
```

---

### **总结**

DPT通过Transformer的全局建模能力与多尺度特征融合，显著提升了密集预测任务的性能。尽管计算成本较高，但在需要精确像素级预测的场景（如自动驾驶、医学影像）中，DPT已成为重要的技术选择。

# proposal

proposal指的是二阶段方法中RPN的输出框，也就是对anchor第一次做回归得到的结果，一种中间结果。可以理解为embedding性质的单词，一般都不翻译，就叫proposal。
proposal：候选框，用RPN生成候选框，然后分类和回归，region proposal指的是候选区域。



# RPN

[深度学习之 RPN（RegionProposal Network）- 区域候选网络-CSDN博客](https://blog.csdn.net/fenglepeng/article/details/117898968)



# RoIAlign

[（三十六）通俗易懂理解——ROI Align的基本原理及rpn与rcnn head锚框标签制作 - 知乎](https://zhuanlan.zhihu.com/p/73113289)




