# backbone等概念

[(8 封私信 / 6 条消息) 深度学习网络中backbone是什么意思? - 知乎](https://www.zhihu.com/question/399611596)



# 零样本分类和少样本分类

### **零样本图像分类（Zero-Shot Image Classification）**

#### **定义**

零样本分类（Zero-Shot Learning, ZSL）是指模型在训练阶段**从未见过某个类别的任何样本**，但在测试时仍能正确识别该类别的能力。其核心思想是通过**语义关联**（如文本描述、属性标签等）将已知类别（训练集）的知识迁移到未知类别（测试集）。

#### **核心原理**

1. **语义嵌入（Semantic Embedding）**：  
   - 将图像特征（如卷积神经网络提取的特征）和类别语义（如文本描述、属性向量）映射到同一语义空间。  
   - 例如，使用CLIP模型将图像和文本编码到同一空间，通过相似度匹配进行分类。  
2. **知识迁移**：  
   - 利用已知类别与未知类别之间的语义关系（如“斑马”和“马”共享“有蹄子”“黑白条纹”等属性），推断未知类别的特征。

#### **典型方法**

- **基于属性的模型**：为每个类别定义属性（如“有翅膀”“会游泳”），通过属性匹配分类。  
- **基于文本的模型**：利用自然语言描述（如“一种黑白条纹的非洲马”）与图像对齐，如CLIP、ALIGN。  

#### **应用场景**

- 识别训练数据中未出现的新类别（如新物种、罕见物体）。  
- 减少对标注数据的依赖，适应开放世界（Open-World）场景。  

#### **挑战**

- 语义鸿沟：图像特征与文本描述的匹配可能存在偏差。  
- 领域偏移：训练和测试的语义空间不一致时性能下降。  

---

### **少样本分类（Few-Shot Classification）**

#### **定义**

少样本分类（Few-Shot Learning, FSL）是指每个新类别仅有**极少量标注样本**（如1~5张图），模型通过少量示例快速适应新任务。核心目标是**从有限样本中泛化**，避免过拟合。

#### **核心原理**

1. **元学习（Meta-Learning）**：  
   - 训练模型掌握“如何学习新任务”的能力。  
   - 例如，在训练阶段模拟少样本场景（如5-way 1-shot任务），通过多次任务迭代优化模型。  
2. **度量学习（Metric Learning）**：  
   - 学习一个相似性度量函数（如欧氏距离、余弦相似度），将测试样本与支持集（少量样本）比对。  
   - 典型方法：原型网络（Prototypical Network）、关系网络（Relation Network）。  

#### **典型方法**

- **基于微调（Fine-tuning）**：预训练模型 + 少量数据微调最后一层（需谨慎防止过拟合）。  
- **基于记忆（Memory-Augmented）**：通过外部记忆模块存储和检索知识，如MANN。  

#### **应用场景**

- 数据标注成本高昂的领域（如医学图像）。  
- 快速适应新类别（如用户自定义标签）。  

#### **挑战**

- 过拟合：少量样本难以覆盖类内多样性。  
- 跨领域泛化：训练任务与测试任务的分布差异。  

---

### **对比总结**

| **维度**   | **零样本分类（ZSL）** | **少样本分类（FSL）**            |
| -------- | -------------- | ------------------------- |
| **训练数据** | 目标类别**无任何样本**  | 目标类别有**1~几十个样本**          |
| **依赖信息** | 类别语义（文本、属性）    | 少量标注样本                    |
| **核心方法** | 跨模态对齐（图像-文本）   | 元学习、度量学习                  |
| **典型模型** | CLIP、ALIGN     | Prototypical Network、MAML |
| **适用场景** | 完全未知的新类别       | 标注极少但需快速适应的新任务            |
| **主要挑战** | 语义鸿沟、领域偏移      | 过拟合、样本多样性不足               |

---

### **实例说明**

1. **零样本分类**：  
   
   - 训练时：模型学习“马”“老虎”的图片及其文本描述（如“有鬃毛”“有条纹”）。  
   - 测试时：输入一张斑马图片，模型通过文本关联（“黑白条纹的非洲马”）正确分类。  

2. **少样本分类**：  
   
   - 支持集：提供5张不同角度的“斑马”图片（1-shot）。  
   - 查询集：模型通过比对相似性，识别新的斑马图片。  

---

### **技术趋势**

- **零样本与少样本结合**：如广义零样本学习（GZSL），允许测试集包含已知和未知类别。  
- **多模态预训练**：CLIP等模型通过海量图文对学习通用表征，显著提升零样本和少样本性能。  
- **自监督学习**：利用无标注数据预训练，增强少样本场景下的泛化能力。  

通过结合语义推理和少量示例，这两种方法正在推动AI系统向更灵活、更高效的方向发展。



# SOTA

SOTA是**State-of-the-Art**的缩写，直译为“当前最先进技术”，在学术和工业界特指**在特定任务或基准测试中达到最佳性能的方法或模型**。

---

### **具体解释**

1. **含义**：  
   
   - 当说某个模型“建立SOTA性能”时，意味着它在公开的基准测试（如ImageNet分类、COCO目标检测等）中超越了此前所有已知方法，成为该任务上的性能最优解。
   - 例如，RemoteCLIP在图像分类、跨模态检索等任务中刷新了最高准确率，因此被称为“SOTA”。

2. **上下文中的意义**：  
   
   - 原文强调尽管RemoteCLIP设计简单，但通过**数据为中心的方法**（如高质量数据清洗、去重、多源数据融合），其性能仍能超越复杂模型，这说明数据质量对模型效果的影响可能比模型结构更大。  
   - 类似的例子如BioMedCLIP，它通过医学领域专业数据训练，成为医学影像分析中的SOTA模型，同样验证了“领域内数据”的重要性。

---

### **扩展知识**

- **SOTA的常见评判标准**：  
  
  - 在权威数据集（如GLUE、SuperGLUE）上的准确率、F1分数等指标。  
  - 实际应用中的推理速度、内存占用等工程指标（如“Pareto SOTA”）。  

- **SOTA的竞争性**：  
  
  - 学术界和产业界会持续发布新模型争夺SOTA地位（例如BERT → RoBERTa → DeBERTa → ChatGPT的演进）。  
  - 某些任务（如ImageNet分类）的SOTA提升已进入边际效益递减阶段，需结合创新突破（如Transformer取代CNN）。

---

### **示例说明**

假设目标任务是图像分类：

- 旧SOTA模型：ResNet-50在ImageNet上准确率76%。  
- 新模型RemoteCLIP：准确率提升至82%，则RemoteCLIP成为新SOTA。

---

### **与其他术语的对比**

| 术语           | 含义               | 与SOTA的关系           |
| ------------ | ---------------- | ------------------ |
| **Baseline** | 基准模型（通常为简单或经典方法） | SOTA需显著优于Baseline  |
| **SoTA**     | 同SOTA（拼写变体）      | 完全等价               |
| **Novelty**  | 创新性（不一定性能最优）     | SOTA模型通常需兼具Novelty |

---

总结来说，SOTA是技术进步的标志，而原文通过RemoteCLIP的例子说明：**即使模型设计简单，高质量数据也能推动性能达到SOTA**，这为构建基础模型提供了重要启示。



# distribution shift

**Distribution Shift（分布偏移）** 是指机器学习模型在训练阶段和实际应用阶段所面对的数据分布（data distribution）不一致的现象。这种不一致会导致模型在实际应用中的性能下降，因为模型在训练时学到的规律可能不再适用于新的数据环境。

---

### **常见的分布偏移类型**

1. **协变量偏移（Covariate Shift）**  
   
   - **特征分布变化**：输入特征（输入变量）的分布发生变化，但输入到输出的映射关系（如条件概率 \(P(y|x)\)）保持不变。  
   - **例子**：训练数据中的图片是白天的场景，但测试数据是夜间场景。

2. **标签偏移（Label Shift）**  
   
   - **标签分布变化**：输出标签（目标变量）的分布发生变化，但标签到特征的映射关系（如条件概率 \(P(x|y)\)）保持不变。  
   - **例子**：训练数据中猫狗图片各占50%，但测试数据中狗占90%、猫占10%。

3. **概念偏移（Concept Shift）**  
   
   - **输入到输出的映射关系变化**：特征和标签之间的关联关系本身发生了变化。  
   - **例子**：经济危机前，“高负债率”可能被模型认为是“高风险”，但经济危机后，由于政策变化，“高负债率”可能不再直接关联高风险。

---

### **为什么分布偏移是问题？**

- 模型在训练时假设训练数据和测试数据来自同一分布（独立同分布，i.i.d.），但实际应用中这一假设常被打破。
- **后果**：模型在新数据上的预测可能不准确，甚至完全失效。

---

### **典型场景举例**

1. **时间变化**：训练数据是历史数据，而测试数据来自未来（如金融预测、疫情趋势分析）。  
2. **领域变化**：训练数据来自实验室环境，测试数据来自真实世界（如自动驾驶）。  
3. **样本偏差**：训练数据未能覆盖所有可能的场景（如人脸识别系统未包含某些肤色的人群）。

---

### **应对分布偏移的方法**

1. **数据层面**  
   - 收集更具代表性的数据，覆盖更多潜在场景。  
   - 数据增强（Data Augmentation）或合成数据生成。  
2. **算法层面**  
   - **领域适应（Domain Adaptation）**：通过迁移学习调整模型，使其适应目标分布。  
   - **鲁棒性训练（Robust Training）**：使用对抗训练或正则化技术增强模型泛化能力。  
3. **监控与更新**  
   - 持续监控模型性能，定期用新数据重新训练模型（Online Learning）。  

---

### **总结**

分布偏移是机器学习实际部署中的核心挑战之一。理解其类型和成因，并采取针对性措施（如领域适应、持续监控），是提升模型鲁棒性和实用性的关键。



# Dense feature

密集特征（Dense Feature）是指在数据中大部分值为非零的浮点数型特征。这类特征通常以连续数值形式存在，例如温度、价格、图像像素值等，每个样本都会包含这些特征且其取值较为密集。与稀疏特征（如类别ID、文本词频等）不同，密集特征不需要通过独热编码（One-Hot Encoding）或嵌入（Embedding）等复杂处理，可以直接输入模型的全连接层（Dense Layer）进行学习。



# IoU

**IoU（Intersection over Union，交并比）**  是计算机视觉中用于衡量两个区域（如边界框、语义分割区域等）重叠程度的指标，广泛应用于目标检测、图像分割等任务中，用于评估预测结果与真实标注（Ground Truth）的匹配精度。

---

### **核心定义**

- **交集（Intersection）** ：预测区域与真实区域的重叠部分面积。

- **并集（Union）** ：预测区域与真实区域的合并总面积（交集 + 各自独立部分）。

- **IoU值**：交集面积与并集面积的比值，计算公式为：
  
  $$
  \text{IoU} = \frac{\text{Intersection}}{\text{Union}} = \frac{A_{\text{pred}} \cap A_{\text{true}}}{A_{\text{pred}} \cup A_{\text{true}}}
  $$
  
  **取值范围**：0（无重叠）到1（完全重合）。

---

### **图解示例**

- **目标检测**：预测框（Predicted BBox）与真实框（Ground Truth BBox）的交并比。  
  ![IoU示意图](https://miro.medium.com/v2/resize:fit:1400/1*5IQh16S2NWEt3g0xGdgTaA.png)  
  
  - 绿色框为真实框，红色框为预测框。
  - 黄色区域为交集，绿色+红色区域为并集。

- **图像分割**：预测掩码（Predicted Mask）与真实掩码（Ground Truth Mask）的像素级重叠率。

---

### **应用场景**

1. **目标检测评估**：
   
   - 判断预测框是否有效：通常设定阈值（如0.5），IoU ≥ 阈值则认为检测正确（True Positive）。
   - 用于非极大值抑制（NMS）：去除重叠率高的冗余预测框。

2. **语义分割评估**：
   
   - 计算每个类别的IoU，再取平均（mIoU）作为模型整体性能指标。

3. **模型训练**：
   
   - 作为损失函数的参考（如IoU Loss），但需结合可导的变体（如GIoU、DIoU）以支持梯度优化。

---

### **计算示例**

假设预测框和真实框的坐标分别为：

- **预测框**：左上角 (2,2)，右下角 (5,5)，面积 = 3×3=9。

- **真实框**：左上角 (3,3)，右下角 (6,6)，面积 = 3×3=9。
1. **计算交集**：
   
   - 交集左上角：(max(2,3), max(2,3)) = (3,3)
   - 交集右下角：(min(5,6), min(5,6)) = (5,5)
   - 交集面积 = 2×2=4

2. **计算并集**：
   
   - 并集面积 = 9 + 9 - 4 = 14

3. **IoU值**：
   
   $$
   \text{IoU} = \frac{4}{14} \approx 0.286
   $$

---

### **优缺点分析**

| **优点**       | **缺点**                         |
| ------------ | ------------------------------ |
| 直观反映重叠程度     | 对非重叠区域敏感（即使预测框靠近真实框但无重叠，IoU=0） |
| 与任务目标直接相关    | 作为损失函数不可导（需使用近似方法如GIoU）        |
| 广泛适用于不同形状的区域 | 对小目标检测误差敏感（像素级误差显著降低IoU）       |

---

### **改进版本**

为解决IoU的局限性，衍生出多种变体：

1. **GIoU（Generalized IoU）**：  
   - 引入最小闭包区域（包围两个框的最小矩形），解决无重叠时的梯度问题。
   - 公式：$$
     \text{GIoU} = \text{IoU} - \frac{\text{闭包区域面积 - 并集面积}}{\text{闭包区域面积}}
     $$

2. **DIoU（Distance IoU）**：  
   - 考虑中心点距离，加速收敛。
   - 公式：$$
     \text{DIoU} = \text{IoU} - \frac{\rho^2}{c^2}
     $$

其中 $ \rho $ 是中心点距离，$ c $ 是闭包区域对角线长度。

3. **CIoU（Complete IoU）**：  
   - 同时考虑重叠率、中心点距离和长宽比。

---

### **总结**

IoU是衡量目标检测或分割结果与真实标注匹配度的核心指标，直观且易于计算。尽管存在对零重叠敏感、不可导等缺点，但其改进版本（GIoU、DIoU等）已广泛应用于模型训练和评估，成为计算机视觉任务中不可或缺的评价工具。

# train from scrath
from scrath 在英文中的意思就是“从零开始、从头开始、白手起家”，引申过来就是不使用预训练文件而直接进行训练.

# Depthwise卷积与Pointwise卷积
[Depthwise卷积与Pointwise卷积 - 知乎](https://zhuanlan.zhihu.com/p/80041030)

# 种子指令
**种子指令（Seed Instructions）** 是指在人工智能（AI）模型训练或生成任务中，用于启动或引导模型行为的一组初始输入或提示。它们通常是简短、明确的指令或示例，帮助模型理解任务要求并生成符合预期的输出。