**PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models**

> 代码：https://github.com/orailix/PACT/tree/main

# 思维导图
![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511070922622.png)

# 摘要

视觉语言模型由于需要额外的输入标记来表示视觉信息，因此推理需要大量的计算资源。然而，这些视觉标记通常包含冗余和不重要的信息，导致标记数量不必要地增多。为了解决这个问题，==我们引入了PACT，这是一种通过在语言模型的早期层修剪无关标记并合并视觉上冗余的标记来减少推理时间和内存使用的方法==。我们的方法使用一种==新颖的重要性度量==来识别不重要的标记，而==不依赖于注意力分数==，这使其与FlashAttention兼容。我们还提出了一种名为==距离有界密度峰值聚类==的新颖聚类算法，该算法在通过预定义阈值限制簇内元素之间的距离的同时，有效地对视觉标记进行聚类。我们通过大量实验证明了PACT的有效性。

# 1.背景

视觉语言模型（VLMs）因需要大量视觉令牌来表示视觉信息，导致推理时计算资源消耗大，且这些视觉令牌常包含冗余和不重要信息，存在令牌数量过多的问题。

# 2.创新

在本文中，我们介绍了两种**互补**的方法来减少推理时间和内存需求来优化视觉语言模型：一种**剪枝模块**和一种**聚类算法**。这些方法可以独立使用，也可以结合使用，从而形成更有效的PACT方法。值得注意的是，我们的剪枝和聚类模块以及PACT都应用于推理阶段，因此==无需额外训练==。剪枝模块基于一种新的重要性度量来识别不重要的视觉标记，该度量在评估每个标记的相关性时不依赖于注意力分数。这使得它与FlashAttention兼容，因为FlashAttention不支持注意力分数的计算。第二个模块引入了一种新的聚类算法——距离有界密度峰值聚类（DBDPC），该算法在对视觉标记进行聚类的同时，确保簇内元素之间的距离受预定义阈值的限制。通过结合这两种方法，我们开发出了PACT。==首先，剪枝模块去除不重要的标记，然后DBDPC算法对剩余标记进行聚类。==最初被剪掉但与构建的簇足够接近的标记会被重新纳入，以确保从剪掉的标记中恢复有价值的信息。最后，每个簇内的标记被合并为单个代表性标记，从而减少标记总数。 

通过结合剪枝和聚类，PACT实现了有效的视觉标记缩减，同时解决了无关和冗余标记的问题。我们的贡献如下：

- 我们提出了一种新颖的视觉标记剪枝指标，该指标能够不依赖注意力分数，确保与FlashAttention兼容，并通过实证验证其有效性。
    
- 我们引入一种新的聚类算法，旨在减少视觉冗余，并展示其在视觉标记缩减方面优于其他聚类算法。
    
- 我们表明，将剪枝与基于聚类的合并相结合，在视觉标记缩减方面优于单独使用任何一种技术。通过整合我们的剪枝和聚类算法，我们提出了一种新颖的方法PACT，并证明它优于先前和同期的研究成果。

# 3.方法

![94420231c0c70f17529124a5c42ee96a.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511070938755.png)
图1. PACT的简化示意图。该图展示了PACT的三步流程：(1) 首先，使用EUTI修剪被认为不重要的视觉标记；(2) 然后，应用DBDPC对剩余标记进行聚类，确保每个标记与其相应聚类中心之间的距离小于截止距离；(3) 最后，重新整合靠近聚类中心的最初修剪的标记，并合并每个聚类中的元素，以形成简化的视觉标记集。

在本节中，我们提出了PACT，这是一种旨在通过在语言模型的==早期层==L修剪不重要的标记并合并视觉上冗余的标记，来减少视觉语言模型（VLMs）推理时间和内存使用的方法。PACT由三个步骤组成：==首先，识别不重要的标记。接下来，对剩余的标记进行聚类。最后，合并每个簇中的标记以及最初被丢弃但距离足够近的标记。==PACT在语言模型的选定层L内运行，并且适用于视觉标记被输入到语言模型的场景，无论视觉编码器或连接器的架构如何。图0展示了PACT的三步过程。我们用 $H ∈ {R}^{n×d}$ 表示层L的隐藏状态，其中n是视觉标记的数量，d是隐藏状态的维度。我们用 $K,Q ∈ {R}^{n×n_{h}×d_{h}}$ 表示层L视觉标记的键矩阵和查询矩阵，其中 $n_{h}$ 表示注意力头的数量，$d_{h}$ 是每个注意力头的维度。为了简化，我们在符号中省略了层索引。我们用下标表示标记的位置索引，而注意力头用上标表示。例如，$k_{i}^{(j)}$ 表示与第 i 个视觉标记和第 j 个注意力头对应的键向量。

### 3.1. 不重要的标记识别

![bab54b329dc1e041bb060a255cdadb0f.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511071540614.png)
图2. 使用视觉标记上的平均注意力分数作为剪枝指标所引发偏差的示意图。在（a）中，对所有标记的注意力进行平均会偏向早期标记，导致更频繁地剪枝后期标记。在（b）中，仅对有注意力的标记进行平均会逆转这种偏差，导致早期标记更常被剪枝。

在语言模型的特定层 L 识别不重要令牌的直接方法，是将每个令牌的重要性定义为其从所有其他令牌获得的总注意力分数 [10]。但该方法存在**三个主要缺陷**：
- ==首先，当前 VLMs 采用的 FlashAttention [13] 不支持输出注意力分数；==
- ==其次，注意力分数计算涉及掩码，会引入偏差 —— 序列末尾的令牌由于较少被其他令牌关注，平均注意力分数往往较低，仅基于关注它的令牌计算平均分数虽能缓解该问题，但会产生新偏差（序列末尾令牌可能因主要被邻近令牌关注而获得更高分数），导致令牌剪枝受位置影响（如图 2 所示），而剪枝应仅取决于视觉令牌包含的信息而非其位置；==
- ==最后，仅依赖单个层的键和查询来定义重要性指标，可能无法充分捕捉视觉令牌在语言模型所有层中的重要性，因为每个自注意力层关注视觉令牌的不同方面。==[^1]

![f9fb2df729cf38d5dbb1c771c9d3d45d.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511072347025.png)
图3. LLaVA-OneVision-7B第四层视觉标记范数统计示意图

为解决这些问题，本文提出一种重要性指标，==整合了隐藏状态的累积信息和早期层 L 的键、查询的层特定信息==，称为==**高效不重要令牌识别**==（Efficient Unimportant Tokens Identification, ==**EUTI**==）。我们推测，隐藏状态的范数能反映每个视觉令牌的重要性，因为它体现了令牌在网络中传递的信息量。图 3 展示了 LLaVA-OneVision-7B 第四层视觉令牌的隐藏状态范数统计，显示出较大方差，这表明某些视觉令牌通过残差连接累积了更多信息，可能对后续计算更重要。[^2]

为同时利用隐藏状态范数和键、查询向量的信息，首先计算全局查询向量 $Q_{global }$ ，即所有视觉令牌查询向量的平均值：$$Q_{global }=\frac{1}{n} \sum_{i=1}^{n} Q_{i} \quad (1)$$该向量代表层 L 中所有注意力头下视觉令牌所需的整体查询信息。然后计算每个视觉令牌的重要性分数：在每个注意力头中，计算令牌键与全局查询的点积，在视觉令牌上应用 Softmax，跨注意力头取平均，最后用隐藏状态范数缩放结果：$$s_{i}=\frac{1}{n_{h}} \sum_{j=1}^{n_{h}} Softmax\left(k_{i}^{(j)} \cdot Q_{global }^{(j)}\right) \cdot\left\| h_{i}\right\| _{2} \quad (2)$$随后，使用参数$\lambda \in[0,1]$控制不重要令牌的比例，将视觉令牌分为重要令牌和不重要令牌两组：$$S_{important }=\left\{i | s_{i} \geq Percentile (s, \lambda)\right\} \quad (3)$$$$
S_{unimportant }=\left\{i | s_{i}< Percentile (s, \lambda)\right\} \quad (4)$$不重要令牌可直接剪枝，或与聚类算法结合以进一步减少视觉令牌数量（下一节将详细介绍）。完整的 ==EUTI 算法==如算法 1 所示。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511101608136.png)

### 3.2. 基于聚类的视觉标记合并

##### 距离有界密度峰值聚类（DBDPC）

仅依靠上述重要性分数剪枝不重要令牌，虽能显著减少视觉令牌数量并保留重要令牌，但保留的令牌中可能仍存在冗余信息。因此，本文提出通过聚类算法合并冗余视觉令牌。我们期望聚类算法具备以下特性：
* （a）计算时间短；
* （b）避免将特征相似度低（距离远）的点分配到同一聚类中。

==特性（b）确保异常值不会被分配到遥远的聚类中心 —— 我们推测这些异常值包含重要信息，应仅与邻近异常值合并或单独构成聚类；同时保证每个聚类内的点相对接近，从而在将单个向量作为聚类代表时最小化信息损失==。[^3]密度峰值聚类（DPC）[5] 在此场景中具有吸引力，因为它满足特性（a），不同于 k-means [2] 等迭代聚类算法。然而，DPC 不满足特性（b），可能形成边界点彼此距离较远的大型聚类；DBSCAN [15] 等其他算法也存在类似问题。因此，本文提出一种新的聚类算法 —— **==距离有界密度峰值聚类（DBDPC）==**。

DBDPC 的输入为一组向量 $\{u_i \in \mathbb{R}^{d_1}\}_{i=1}^q$（其中 $q, d_1 \in \mathbb{N}^+$ ），输出为一组聚类。算法输出取决于两个参数（截断距离 $d_c \in \mathbb{R}^+$ 和归一化因子 $d_n \in \mathbb{R}^+$ ）以及距离函数 $d: \mathbb{R}^{d_1} ×\mathbb{R}^{d_1} \to \mathbb{R}^+$ 。我们定义两个向量 $u_i$ 和 $u_j$ 之间的距离为：$$d_{i j}=d\left(u_{i}, u_{j}\right)=1-\frac{u_{i} \cdot u_{j}}{\left\| u_{i}\right\| _{2}\left\| u_{j}\right\| _{2}} \quad (5)$$然后计算局部密度 $\rho_i$：$$\rho_{i}=\sum_{j} e^{-d_{i j} / d_{n}} \quad (6)$$按 $\rho_i$ 从高到低对向量 $u_i$ 排序，若某个向量与已选聚类中心的最小距离大于 $d_c$ ，则将其指定为新的聚类中心。每个向量 $u_i$ 随后被分配到距离最近的聚类中心。该算法保证每个向量到其聚类中心的距离小于 $d_c$ ，从而满足上述特性（b）。完整的 DBDPC 算法如算法 2 所示。

![3e858de39df28324418207be6707f90d.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511101638855.png)

==DBDPC 中的聚类中心识别过程确保簇间距离上界为 $2d_c ×(2-d_c)$ ，同时聚类中心间距离下界为 $d_c$（附录 B 提供正式证明）==。需说明的是，为清晰起见，算法中部分步骤以循环形式呈现，但除聚类中心选择部分外，所有计算均可在 GPU 上并行执行 —— 聚类中心选择部分采用递归算法高效识别初始中心集和丢弃向量，减少待处理向量数量（附录 D 详细说明）。DBDPC 与 DPC 的对比及与其他聚类算法的定性比较见附录 C。

##### 距离计算的向量选择

如前所述，DBDPC 算法基于一组向量计算距离，为实现有效聚类，这些向量的点积需能准确反映对应视觉令牌的相似度。幸运的是，Transformer 通过 QKV 自注意力机制解决了这一问题 —— ==键向量 K 为每个令牌提供了适合点积相似度计算的有意义表示==。因此，==DBDPC 算法中使用键向量进行聚类==，形式化表示为：$$C_{centers }, C_{elements }=DBDPC\left(K'\right) \quad (7)$$其中 $K'=\{u_{i} \in K | i \in S_{important }\}$ 是重要令牌对应的键向量子集。

##### 聚类中心附近的不重要令牌处理

初始被判定为不重要但距离聚类中心足够近的令牌，很可能是误判的。为减少信息损失，我们将这些令牌添加到对应的聚类中。形式化地，基于系数 $\alpha$ 定义阈值，若初始被排除的令牌 $u_i$ 与最近的聚类中心 $s \in C_{centers }$ 的距离满足 $d_{i s}<\alpha \cdot d_{c}$ ，则将其添加到该聚类中心的聚类中。具体而言，更新后的聚类元素集 $C_{elements }^{(s)}$ 为：$$S_{added }^{(s)}=\left\{i \in S_{unimportant } | s=argmin_{s' \in C_{centers }} d_{i s'} \text{ 且 } d_{i s}<\alpha \cdot d_{c}\right\} \quad (8)$$$$
C_{elements }^{(s)} \leftarrow C_{elements }^{(s)} \cup S_{added }^{(s)} \quad (9)$$

##### 令牌合并与位置 ID 分配

最后，合并每个聚类内元素对应的隐藏状态，形式化表示为：$$H'=\left\{\frac{1}{\left|C_{elements }^{(j)}\right|} \sum_{i \in C_{elements }^{(j)}} h_{i} | C_{elements }^{(j)} \in C_{elements }\right\} \quad (10)$$为新隐藏状态 $H'$ 中的每个向量准确分配位置 ID 至关重要，尤其是对于使用旋转嵌入的模型 —— 位置 ID 决定输入图像的结构或输入视频的时间依赖关系。为使统计结果与常规推理保持低差异，==将 $H'$ 中每个向量的位置 ID 设为其对应聚类中心的位置 ID==。完整的 PACT 流程如算法 3 所示。

![70798bdf18cf8fba0ec62937f0ab4c33.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511101700045.png)

==需注意，DBDPC、EUTI 及 PACT 均不依赖文本令牌==，因此视觉令牌缩减独立于文本上下文，使其非常适合多轮对话场景。

##### 比例注意力

==令牌合并会降低其在注意力机制中的影响力==，若大量重要令牌被合并，可能导致性能下降。为解决这一问题，本文使用==比例注意力== [7]。

设K、Q、V分别表示层 $L'（L' ≥L）$ 的键、查询和值矩阵。对于每个注意力头 j，注意力分数计算如下：$$A^{(j)}=softmax\left(\frac{Q^{(j)} K^{(j) \top}}{\sqrt{d_{h}}}+log W+B\right) (11)$$其中 $d_{h}$ 为每个注意力头的查询维度，W为表示每个令牌权重的矩阵，B为注意力掩码。具体而言，对于视觉令牌，任意 $i_0$ 对应的 $w_{i_0, i_1}$ 表示令牌 $i_1$ 对应簇的大小；对于位置 t 的文本令牌，$w_{i_0, t}=1$（文本令牌不合并，权重保持为 1）。通过基于W缩放注意力分数，模型能有效将每个视觉令牌视为代表多个令牌。需注意，使用比例注意力时，我们采用 PyTorch 的缩放点积注意力，其结果与官方 FlashAttention 实现相似，且支持自定义掩码。

#### 令牌缩减层 L 的选择

为最大化计算收益，需选择语言模型的早期层 L 进行视觉令牌缩减；同时，所选层的键向量需具备足够的差异性，以实现有效聚类和剪枝。因此，==我们选择键向量最大距离足够大的最早层==。图 4 显示，LLaVA-OneVision-7B 的初始层中，视觉令牌对应的键向量相似度较高，缺乏有效剪枝和聚类所需的独特特征。

![768eb9def98476b961e36e8a9bb3ef3e.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202511101706549.png)
图4. 在应用旋转嵌入之前，LLaVAOneVision-7B前10层视觉标记键之间最大距离的示意图。



# 脚注
[^1]: 这段话的核心是：**否定 “用‘某层接收的总注意力分数’判断词元（视觉令牌）重要性” 这种直观方法**，理由是它存在三个无法回避的硬伤 —— 而且每个硬伤都和你之前纠结的 “位置偏差、掩码、模型特性” 直接相关，咱们结合你的疑问拆得明明白白：
	
	### 先给这段话定个总基调：
	
	它想表达的是 “看似合理的方法，实际用不了、用不好”——“看谁收到的总注意力多，就认为谁重要”，逻辑上说得通，但在 VLMs（视觉语言模型）里，因为技术限制、偏差干扰和信息片面，根本没法作为剪枝的依据。
	
	### 逐点拆解三个缺点（结合你的过往疑问）：
	
	#### 1. 第一个缺点：FlashAttention 不支持输出注意力分数（技术上 “用不了”）
	
	- 核心问题：这种方法的前提是 “能拿到每个词元收到的注意力分数”，但现在主流 VLMs 都用 FlashAttention（一种高效计算注意力的技术）—— 它为了省内存、提速度，会 “跳过存储中间的注意力分数”，只输出最终的特征结果。
	- 通俗类比：就像你想知道 “谁给你投了票、投了多少”，但计票系统只告诉你 “最终结果”，不告诉你具体的投票明细 —— 没有明细，你根本没法算 “每个词元收到的总注意力”。
	- 和你的关联：你之前问过 “令牌是不是同时进入模型”，FlashAttention 就是 “同时并行计算” 的核心技术，而它的副作用就是 “拿不到注意力分数”，直接堵死了这种方法的可行性。
	
	#### 2. 第二个缺点：掩码引入双重偏差（逻辑上 “用不好”，也是你最纠结的点）
	
	- 先回顾掩码的作用：之前跟你说过，掩码是 “筛选器”，决定 “词元能关注谁、不能关注谁”（比如序列末尾的词元，后面没有其他词元，掩码会让它们 “看不到后面的词元”，自然也没人关注它们）。
	- 第一种偏差：序列末尾词元 “平均分数低”
	    - 原因：掩码让序列末尾的词元（后期令牌）“被关注的对象更少”（前面的词元能被后面所有词元关注，后面的词元只能被前面的词元关注），所以它们收到的 “总注意力分数” 天然更低 —— 平均下来分数就低，模型会误判它们 “不重要”，导致后期令牌被剪枝更多（对应你之前看的图 1a）。
	- 第二种偏差：缓解第一种偏差后，反而 “反转偏差”
	    - 原因：有人想解决上面的问题，提出 “不算所有词元，只算‘真正关注它的词元’的平均”（比如末尾词元只算前面关注它的 3 个词元的平均，而不是所有 100 个词元的平均）。
	    - 结果：末尾词元的 “关注者少但集中”（比如只有邻近的 2 个词元关注它，权重总和虽少，但除以 2 后，平均分数反而高），早期词元的 “关注者多但分散”（比如被 20 个词元关注，权重总和多，但除以 20 后，平均分数被拉低）—— 模型又会误判末尾词元 “重要”，导致早期令牌被剪枝更多（对应图 1b）。
	- 关键结论：这两种偏差都是 “位置导致的”，和词元本身包含的视觉信息无关 —— 剪枝本该看 “这个词元有没有用”，结果变成了 “这个词元在序列的前面还是后面”，这就是要避免的 “位置偏差”。
	
	#### 3. 第三个缺点：单一层的键和查询，信息太片面（结果 “不准确”）
	
	- 核心问题：每个自注意力层的作用不一样 —— 有的层关注 “局部相邻的词元”（比如判断 “这个像素和旁边的是不是同一物体”），有的层关注 “全局关联的词元”（比如判断 “天空和云朵是不是同一场景”）。
	- 通俗类比：就像评价一个人，只看他 “工作能力”（某一层的表现），不看他 “沟通能力、学习能力”（其他层的表现）—— 结论肯定片面。
	- 具体影响：某个词元在 “局部层” 收到的注意力少（看似不重要），但在 “全局层” 收到的注意力多（实际很重要），如果只看单一层的分数，就会误把它当成 “不重要的词元” 剪枝掉，导致模型性能下降。
	
	### 最后总结这段话的核心诉求：
	
	它不是在抬杠，而是在铺垫 ——“既然这种直观方法不行，那我们就需要一种新方法”（也就是后面提出的 EUTI），新方法必须满足三个条件：
	
	1. 不依赖注意力分数（适配 FlashAttention）；
	2. 避免位置偏差（剪枝只看词元信息，不看序列位置）；
	3. 能捕捉更全面的信息（不局限于单一层）。

[^2]: 这段话的核心是：**EUTI 是专门解决前面提到的三个问题（依赖注意力分数、位置偏差、单一层信息片面）的 “替代方案”** —— 它不用注意力分数、能避免位置偏差、还能捕捉更全面的信息，核心思路是 “把两种有用的信息结合起来判断令牌重要性”，咱们拆得通俗又透彻：
	
	### 一、先明确 EUTI 的核心目标：对症下药解决三个老问题
	
	之前的方法之所以不行，是因为 “依赖注意力分数（被 FlashAttention 卡脖子）、有位置偏差、单一层信息片面”。EUTI 的设计初衷就是：
	
	1. 不碰注意力分数（适配 FlashAttention）；
	2. 只看令牌 “自身携带的信息”，不看它在序列的位置（避免位置偏差）；
	3. 不止用单一层的信息，还结合 “累积信息”（更全面）。
	
	### 二、EUTI 的核心逻辑：整合两种关键信息，判断令牌重要性
	
	EUTI 的重要性指标不是瞎编的，是 “两种有价值的信息” 的结合体，咱们分别说清楚：
	
	#### 1. 第一种信息：早期层 L 的键（K）和查询（Q）—— 层特定的 “局部信息”
	
	- 作用：捕捉这一层对令牌的 “即时判断”。每个层的 K 和 Q 是用来计算 “令牌间关联” 的核心，哪怕不用注意力分数，K 和 Q 本身也能反映 “这个令牌在当前层的作用”（比如 K 能体现令牌的特征，Q 能体现令牌想关注什么）。
	- 关键选择：用 “早期层 L” 而不是深层 —— 早期层的令牌特征还没被过度加工，能保留更多原始视觉信息（比如物体的边缘、颜色），不容易受后续层的偏差影响。
	
	#### 2. 第二种信息：隐藏状态的累积信息 —— 全链路的 “全局信息”
	
	这是 EUTI 的核心创新，也是解决 “单一层信息片面” 的关键，重点理解两个点：
	
	- 什么是 “隐藏状态（Hidden State）”？每个令牌经过每一层时，都会产生一个 “特征向量”（就是隐藏状态），它记录了这个令牌在当前层的所有信息（包括从前面层传递过来的信息）。可以理解为：令牌的 “个人档案”，每经过一层就更新一次，记录自己的 “经历”（信息）。
	    
	- 什么是 “隐藏状态的范数（Norm）”？范数是一个简单的数值（比如 L2 范数，就是向量各元素平方和的平方根），核心作用是 “衡量令牌携带信息的总量”—— 范数越大，说明这个令牌的 “个人档案” 越丰富，携带的信息量越多；范数越小，信息量越少。
	    
	- 为什么能反映重要性？模型里有 “残差连接（Residual Connection）”—— 简单说就是 “令牌的信息不会被中间层弄丢，会一直累积传递”。比如一个令牌对应图像的核心物体（比如人脸），它的信息会在每一层被强化，隐藏状态的范数就会越来越大；而对应背景的令牌，信息没什么累积，范数就小。
	    
	
	### 三、图 2 的作用：用数据证明 “范数能区分重要性”
	
	作者不是凭空说 “范数能反映重要性”，而是用实验数据支撑：
	
	- 图 2 展示了 LLaVA-OneVision-7B 模型第四层所有视觉令牌的范数分布；
	- 关键现象是 “范数方差很大”—— 有的令牌范数特别大，有的特别小；
	- 结论：这说明令牌之间的 “信息量差异很明显”，用范数作为 “重要性的衡量维度” 是可行的（如果所有令牌范数都差不多，那这个指标就没用了）。
	
	### 四、EUTI 的核心优势（呼应前面的三个问题）
	
	|之前的问题|EUTI 的解决方式|
	|---|---|
	|依赖注意力分数（FlashAttention 不支持）|不用注意力分数，改用 K、Q 和隐藏状态范数|
	|位置偏差（剪枝看位置不看信息）|范数反映的是令牌自身的信息量，和序列位置无关|
	|单一层信息片面|整合 “单一层的 K/Q（局部信息）”+“隐藏状态累积信息（全局信息）”，更全面|
	
	### 最后总结 EUTI 的核心逻辑（一句话看懂）：
	
	判断一个令牌重要不重要，不看它 “收到多少注意力”（因为拿不到且有偏差），也不看它 “在序列前面还是后面”（位置没用），而是看两个硬指标：① 它在早期层的 K/Q 特征（当前层的作用）；② 它的隐藏状态范数（从前面层累积的信息量）—— 两者结合，就能精准识别出 “没什么信息量、可以剪枝的令牌”。
	
	这样是不是就清楚 EUTI 为什么能解决之前的问题了？如果想再深入了解它的具体计算过程（比如 K/Q 怎么和范数结合出最终分数），咱们可以再拆公式。

[^3]: 这段话的核心是：**聚类算法的特性（b）（避免远距点同簇），本质是“在合并冗余令牌的同时，守住两个关键底线——不丢重要信息（保护异常值）、不混无用信息（减少合并损失）”**，咱们结合视觉令牌的实际场景，拆得明明白白： ### 先明确特性（b）的核心约束：簇内点必须“特征相近” 特性（b）的字面意思是“不让特征相似度低（距离远）的令牌分到同一个聚类”，背后是聚类的核心目标——**合并“冗余的相似令牌”，但不破坏“重要的独特令牌”**。 比如图像里“大片蓝天”的令牌是冗余的（特征相近），可以聚成一簇；但“蓝天里的小鸟”令牌和蓝天令牌差异大（距离远），就不能强行凑到同一簇。 ### 第一部分：为什么要保护异常值？（异常值=重要信息） #### 1. 先搞懂：视觉令牌里的“异常值”是什么？ “异常值”就是和周围大多数令牌特征差异大的令牌——比如： - 图像背景是大片草地（多数令牌是“草地特征”），草地上的一朵红花（“红花特征”令牌）就是异常值； - 文档图片里的文字区域（多数令牌是“空白背景”），文字对应的令牌就是异常值。 这些异常值之所以“异常”，是因为它们包含**关键视觉信息**（红花、文字），而不是冗余信息——模型推理（比如回答“图里有什么”“文字写了什么”）全靠这些信息。 #### 2. 特性（b）怎么保护异常值？ 如果没有特性（b），聚类算法可能会把“红花令牌”（异常值）分到“草地聚类”（距离远但簇大），导致红花的信息被草地的信息“淹没”。 特性（b）通过“不让远距点同簇”，强制异常值只能： - 要么和“邻近的异常值”合并（比如两朵相邻的红花令牌聚成一簇）； - 要么单独构成一个聚类（比如只有一朵红花，就单独保留这个令牌，不合并）。 这样就能守住异常值里的重要信息，不会因为聚类而丢失。 ### 第二部分：为什么簇内点接近能最小化信息损失？（合并≠丢信息） 聚类的最终目的是“用一个‘代表向量’代替一簇令牌”（比如用一个“蓝天代表向量”代替所有蓝天令牌），从而减少令牌数量。 信息损失的大小，取决于“簇内令牌的相似度”： - 如果簇内点距离近（特征像）：比如所有蓝天令牌聚成一簇，代表向量就能准确反映“蓝天”的特征，合并后几乎没损失； - 如果簇内点距离远（特征杂）：比如把“蓝天”“红花”“小鸟”令牌凑到同一簇，代表向量既不像蓝天，也不像红花/小鸟，相当于这三个令牌的信息全被破坏了——损失极大。 特性（b）强制簇内点“相对接近”，就是让“代表向量”能精准概括簇里所有令牌的信息，让“合并冗余”和“保留有效信息”不冲突。 ### 最后总结特性（b）的核心作用（呼应PACT的整体目标） PACT的聚类是为了“合并视觉冗余令牌”，但不能为了减少令牌数而“乱合并”： - 保护异常值：确保关键信息（比如红花、文字）不被冗余背景“稀释”； - 控制簇内距离：确保合并后的代表向量不“失真”，信息损失最小。 这两点结合，才能让聚类既达到“减令牌、提速度”的目的，又不影响模型的推理性能——毕竟PACT的核心是“高效不低效”，不是“减令牌而减令牌”。 如果结合之前的3x3令牌例子（比如“右中”的文字令牌是异常值），就能更直观：特性（b）会让文字令牌要么单独成簇，要么和邻近的文字令牌合并，绝不会被分到背景聚类里，这就是它保护重要信息的实际作用~
