> 论文题目：ROS-SAM: High-Quality Interactive Segmentation for Remote Sensing Moving Object
> 
> 论文地址：https://arxiv.org/pdf/2503.12006
> 
> 论文代码：https://github.com/ShanZard/ROS-SAM
> 
> 发表时间：2025.3.15


# 摘要

遥感视频数据目标尺寸小、特征模糊以及泛化能力有限，本文提出ROS-SAM

1. 基于[[LoRA]]微调SAM
    
2. [^1]增强深度网络层，以提高提取特征的**可区分性**，从而减少误分类。
    
3. [^2]在Mask Decoder中**整合全局上下文与局部边界细节**，以生成高质量的分割掩码。
    
4. 此外，本文设计了数据管道（[[data pipeline]]），以确保模型在训练期间能够更好地处理不同尺度的目标，同时在推理时专注于高质量预测。
    

在遥感视频数据集上的实验表明，重新设计的数据管道使交并比（IoU）提高了6%，而ROS-SAM则使IoU提高了13%。

[^1]: 深层网络是提取特征的关键部分，深层网络的设计将影响特征提取的效果。

[^2]: 也是提到了整合全局和局部信息，这在很多论文中都有提及，只是整合的地点可能不太一样。

# 背景
- **遥感视频目标特性与标注难题**：遥感视频中的运动目标尺寸小、特征模糊且密度高，逐帧标注成本高昂，导致高质量像素级标注稀缺，限制了相关算法的训练和性能提升。
    
- **通用视觉模型的遥感适应性不足**：通用视觉模型（如SAM）在遥感任务中面临显著挑战：无法准确处理遥感目标的方向和特征（如区分船只与海浪），且生成的掩码边界粗糙、易碎片化，难以满足高质量分割需求。
    
- **遥感图像处理的技术瓶颈**：遥感图像尺寸大但目标小，而现有模型（如SAM）要求固定分辨率输入，导致下采样时目标丢失。此外，现有训练和推理流程无法有效处理[多尺度目标](遥感领域的多尺度目标)，难以适应遥感图像的特殊性。

# 方法

## 模型总览
![[Pasted image 20250518100156.png]]