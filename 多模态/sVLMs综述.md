# 1 前言
# 2 小型视觉语言模型的演变
## 2.1 历史概述
### 2.1.1 [[CLIP]]

* **原理**：用自然语言作为监督信号，通过**对比学习**在共享嵌入空间中最小化不匹配项，来对齐图像和文本
* **优势**：实现了显著的**零样本**性能。
* **局限**：其零样本性能仍然低于最先进的模型。计算要求极高。数据要求极大。在细粒度分类、抽象推理和分布外泛化方面存在困难。
* **模型架构**：![25aaa0d0-21c8-4d07-8e83-b6960e6d7cfa](file:///C:/Users/Lenovo/Pictures/Typedown/25aaa0d0-21c8-4d07-8e83-b6960e6d7cfa.png)

### 2.1.2 [[ViLT]]

* **原理**：采用仅transformer的架构，将图像划分为32×32的块，进行线性投影，并与文本嵌入融合以实现跨模态交互。该方法消除了CNNs和区域特定监督，简化了视觉处理。
* **优势**：架构**简单**轻量。
* **局限**：缺乏细粒度。扩展到更大模型需要大量的计算资源和数据。对块投影的依赖限制了详细的语义理解，影响了深度视觉推理。
* **模型架构**：![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504250912685.png)

### 2.1.3 VirTex

* **原理**：使用语义丰富的caption学习视觉表示
* **优势**：为依赖于大型 Token 数据集的传统监督和无监督方法提供了一种数据高效的选择。
* **局限**：依赖于高质量的标题标注。对于下游任务还需要微调。在更大的视觉 Backbone 上也表现出优化挑战。
* **模型架构**：![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504251000923.png)


	其架构由一个 **ResNet-50 视觉 Backbone** 和一个基于**双向 Transformer 的文本 Head** 组成，共同在 COCO Captions 数据集中的图像-标题对上进行训练以生成标题。预训练后，文本 Head 被丢弃，视觉 Backbone 被迁移到下游任务，如图像分类、目标检测和实例分割。

### 2.1.4 FLAVA

* **原理**：是一种**视觉和语言对齐**模型，旨在统一Transformer架构中处理视觉、语言和多模态任务。
* **优势**：联合训练单模态和多模态任务。
* **局限**：预训练数据集小。泛化能力差。可扩展性差。存在优化挑战。
* **模型架构**：![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504251012284.png)
	它包括基于ViT-B/16架构的**图像编码器**，用于处理视觉输入，相同设计的**文本编码器**用于文本表示，以及一个**多模态编码器**，用于对齐和融合来自两种模态的信息。
### 2.1.5 SimVLM

* **原理**：通过采用单个**前缀语言建模（PrefixLM）** 目标，引入了一种简化的视觉-语言预训练方法，该目标统一了双向上下文表示和自回归文本生成。进行端到端训练。
* **优势**：有较强的泛化和迁移能力，能够进行包括开放式视觉问题回答等zero-shot任务。
* **局限**：在精细任务上的性能较差。高计算需求。与全监督模型相比，在复杂推理任务中仍有所不足。对弱监督的依赖限制了模型学习详细视觉-语言关联的能力。
* **模型架构**：![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504251026178.png)
	其架构基于Transformer编码器-解码器框架，原始图像块通过受ResNet启发的卷积阶段进行处理，文本输入使用位置编码进行 Token 化。
### 2.1.6 [[BLIP系列]]

* **原理**：兼顾视觉-语言**理解和生成**，在**三个VLP**上做预训练。采用**boostrapping**进行数据集降噪。
* **优势**：基于图像的文本生成和图像-文本对比学习，使得在噪声网络数据上能够进行稳健的预训练。在包括图像描述、视觉问答和跨模态检索在内的多种任务上展现了最先进的性能。
* **局限**：当数据和模型的规模增大时，boostrapping caption 的效果就没那么好了。严重依赖于噪声网络数据，无法准确描述图像的视觉内容。基于编码器的方法难以直接应用于文本生成任务，如图像描述，而编码器-解码器模型在理解型任务，如图像-文本检索方面面临挑战。
* **模型架构**：![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504242049115.png)![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504242143382.png)
### 2.1.7 Flamingo

* **原理**：将预训练的仅视觉模型和仅语言模型连接起来，以处理交织的视觉和文本数据序列，从而在多模态任务上实现最先进的少样本学习。使用了新颖的多目标损失函数。
* **优势**：跨模态集成高效，同时保留了预训练语言模型的能力。旨在解决更广泛的开放性任务。
* **局限**：有时会出现幻觉。泛化时表现不佳。分类性能低于最先进的对比模型。
* **模型架构**：![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202504251049552.png)
	其架构集成了冻结的NFNet-F6视觉编码器与Perceiver Resampler，将可变长度的视觉特征转换为固定 Token ，这些 Token 随后由一个冻结的大语言模型处理，该模型增加了新的GATED XATTN-DENSE层。

## 2.2 小型视觉-语言模型（sVLMs）的 Backbone 架构分类

### 2.2.1 基于Transformer的模型代表

#### 2.2.1.1 TinyGPT-V

* **高效架构**：集成紧凑的 Phi-2 语言模型和预训练视觉编码器
* **新型训练方法**：专注于小型预训练骨干网络
* **资源高效训练和推理**：克服大型 MLLMs 的封闭性
* **关键技术**：LoRA (Low-Rank Adaptation)、Layer Normalization

#### 2.2.1.2 MiniGPT-4

* **架构特点** 
	- **创新方法**：通过冻结视觉编码器与先进 LLM 对齐
	- **技术挑战**：复制 GPT-4 的多模态能力，同时保持透明度
	- **架构组成**：预训练 ViT 和 Q-Former，线性投影层，Vicuna LLM
	- **两阶段训练**：大规模图像-文本对预训练 + 精细调整
- **性能评估**
	- **优势**：详细图像描述生成、网站创建、梗图解读、创意任务
	- **局限性**：图像描述幻觉、空间信息理解困难

#### 2.2.1.3 TinyViT

* **架构特点**：
	* **轻量化视觉 Transformer (ViT)**：为计算能力有限的设备设计
	* **知识蒸馏 (Knowledge Distillation)**：从大型模型学习，提升性能
	* **分层结构**：逐步下采样和局部注意力，平衡效率与精度
* **应用场景**：
	- 图像分类
	- 目标检测
	- 语义分割
* **局限性**：大型模型尺寸和计算成本，实时性不足

#### 2.2.1.4 FastViT

* **架构**
	* **混合视觉 Transformer**：兼顾速度和精度
	* **RepMixer 块**：结构化重参数化，消除跳跃连接，提高效率
	* **训练时过参数化**：增强精度，但增加计算开销
* **优势**
	- 优于 CMT, EfficientNet, ConvNeXt 等模型
	- 图像分类、目标检测、语义分割
* **局限性**
	- 训练时间增加
	- 硬件特定优化限制适应性

#### 2.2.1.5 LLaVA-Mini

* **架构**：
	* 视觉编码器
	* 模态预融合模块：视觉信息压缩，减少 FLOPs
	* 查询压缩：进一步压缩视觉标记数量
	* LLM：降低计算成本，保持视觉理解能力
* **优势**：高分辨率图像和视频任务，优于先前模型
* **局限性**：视觉细节丢失，依赖查询压缩和模态预融合

#### 2.2.1.6 Moondream2

* **架构**：
	* 模态预融合
	* 视觉标记压缩
	* 查询压缩
* **优势**
	- 高效处理图像和视频任务
	- 边缘设备适用
- **局限性**
	- 生成不准确陈述
	- 难以理解细微指令
	- 潜在偏见
	- 依赖大规模预训练
