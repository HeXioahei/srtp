# 博客推荐：
* [A Survey on Multimodal Large Language Models-全文解读 - 知乎](https://zhuanlan.zhihu.com/p/641866192)
* [【综述论文阅读】A Survey on Multimodal Large Language Models 上_prompt-based ensemble expert language models with -CSDN博客](https://blog.csdn.net/weixin_46231495/article/details/145903655?ops_request_misc=&request_id=&biz_id=102&utm_term=a%20survey%20on%20multimodal%20large%20l&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-145903655.142^v102^pc_search_result_base9&spm=1018.2226.3001.4187)
* [【综述论文阅读】A Survey on Multimodal Large Language Models下-CSDN博客](https://blog.csdn.net/weixin_46231495/article/details/146048896?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167492ef860aee0e47ba555a2472ad22%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=167492ef860aee0e47ba555a2472ad22&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-10-146048896-null-null.142^v102^pc_search_result_base9&utm_term=a%20survey%20on%20multimodal%20large%20l&spm=1018.2226.3001.4187)

# 架构

典型架构抽象为三个模块，即预训练的**多模态编码器、预训练的大语言模型**以及连接它们的**多模态接口**。

## 编码器

选择编码器时，需要考虑**分辨率、参数量**和**预训练语料库**等因素。分辨率的重要性最大。

**扩展输入分辨率的方法：**
* 直接缩放：**将更高分辨率的图像输入到编码器中**，通常需要进一步调整编码器或替换为更高分辨率的预训练编码器。
* 分块：**高分辨率图像切割成小块，并重用低分辨率编码器**。

## 预训练LLM

**常用公开可用LLM**：
* **FlanT5 系列**：是较早的 LLM，被用于类似 BLIP-2 和 InstructBLIP 的工作中。
* **LLaMA 系列 和 Vicuna 家族**：是具有代表性的开源 LLM，吸引了大量学术界的关注。由于这两类 LLM 主要基于英文语料库进行预训练，因此在多语言支持方面存在局限性，例如对中文的支持较为有限。
* **Qwen**： 是一款双语 LLM，能够很好地支持中文和英文。

扩大 LLM 的参数规模能带来额外的收益，类似于提高输入分辨率的情况。也有一些研究专注于使用较小的 LLM，以方便在移动设备上部署。关于 LLM 的专家混合（MoE, Mixture of Experts）架构的研究逐渐受到关注，与密集模型相比，稀疏架构通过选择性激活参数，能够在不增加计算成本的情况下扩展总参数规模。

## 模态接口

**两种实现模态接口的方法：**
* 在预训练的视觉编码器和LLM之间引入一个**可学习的连接器**。
* 通过**专家模型将图像翻译成语言**，然后将语言发送给LLM。

### 可学习连接器

该模块**将信息投影到LLM能够高效理解的空间中**。

实现这种接口的方法大致有两种：
* **token级融合** ：编码器输出的特征被转换为token，并在发送到LLM之前与文本token连接。
	* **利用一组可学习的查询token以基于查询的方式提取信息**：如BLIP-2。
	* 仅使用**基于MLP的接口**来弥合模态差距：如LLaVA系列。
* **特征级融合**：**通过插入额外的模块**来实现文本特征与视觉特征之间的深度交互和融合。例如：
	* Flamingo 在冻结的 LLM Transformer 层之间插入了额外的**交叉注意力层**，从而利用外部视觉线索增强语言特征。
	* CogVLM 在每个 Transformer 层中插入了一个**视觉专家模块**，以实现视觉特征与语言特征之间的双向交互和融合。为了获得更好的性能，所引入模块的 QKV 权重矩阵初始化自预训练的 LLM。
	* LLaMA-Adapter 在 Transformer 层中引入了**可学习的提示（prompt）**。这些提示首先嵌入了视觉知识，然后作为前缀与文本特征连接。

对于token级融合，模态适配器的类型远不如**视觉token的数量**和**输入分辨率**重要。

### 专家模型

**将多模态输入转换为语言表示，而无需额外训练**。LLM可以通过转换后的语言来理解多模态信息。例如，VideoChat-Text 使用预训练的视觉模型提取动作等视觉信息，并通过语音识别模型丰富描述内容。尽管使用专家模型的方法较为直接，但它可能不如采用可学习接口那样灵活。将其他模态的信息转换为文本会导致信息丢失。

# 训练策略与数据

一个完整的多模态大型语言模型（MLLM）需要经历三个训练阶段，即**预训练**、**指令微调**和**对齐优化**。每个训练阶段都需要不同类型的训练数据，并实现不同的目标。

## 预训练

目标是**对齐不同模态**并**学习多模态世界知识**，通常需要**大规模**的文本配对数据。
### 训练细节

给定一张图像，模型被训练以**自回归**的方式预测该图像的描述（caption），采用标准的交叉熵损失函数进行优化。一种常见的预训练方法是**冻结预训练模块**（例如视觉编码器和 LLM），然后训练一个**可学习的接口**，其核心思想是在不丢失预训练知识的情况下对齐不同模态。 一些方法还会**解冻更多模块**（例如视觉编码器），以增加可用于对齐的可训练参数。

训练方案与**数据质量**密切相关。对于**短且噪声较大**的描述数据，可以采用**较低分辨率**（例如 224）来加速训练过程；而对于**较长且较为干净**的数据，则更适合使用**更高分辨率**（例如 448 或更高）以减少幻觉现象的发生。

### 数据

类型：
* 粗粒度数据：
	* 样本通常来源于互联网爬取。
	* **数据量大**
	* **短且噪声较大
* 细粒度数据生成：
	* 通过**提示强大的 MLLM**（如 GPT-4V）生成高质量的细粒度数据。
	* 包含更长且更准确的图像描述，从而实现图像与文本模态之间更精细的对齐。
	* 需要调用商业用途的 MLLM，成本较高，数据量相对较小。
	* *ShareGPT4V [83] 通过一种折中方法实现了高效的数据生成：首先使用 GPT-4V 生成的 10 万条数据训练一个描述生成模型，然后利用该预训练模型扩展数据量至 120 万条。*
## 指令微调

**指令（Instruction）** 是指任务的描述。指令微调的目标是**教会模型更好地理解用户的指令并完成所要求的任务**。

* **监督微调（Supervised Fine-tuning）**：通常**需要大量的任务特定数据**来训练一个**任务特定**的模型。
* **提示（Prompting）**：减少了对大规模数据的依赖，并可以通过提示工程完成**特定任务**。在这种情况下，尽管**少样本性能有所提高**，但零样本性能仍然较为普通。
* **指令微调（Instruction Tuning）**：不同于上述两种方法，指令微调专注于学习如何**泛化到未见过的任务**，而不是像前两者那样适应特定任务。此外，指令微调与多任务提示（multi-task prompting）密切相关。

### 训练细节

形式上，一个多模态指令样本可以用三元组的形式表示，即 ((I, M, R))，其中 (I)、(M)、(R) 分别代表**指令**、**多模态输入**和**真实响应**。多模态大型语言模型（MLLM）根据指令和多模态输入预测答案：

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202503131859242.png)

这里，(A) 表示预测的答案，(θ) 是模型的参数。训练目标通常是用于训练大型语言模型（LLM）的原始自回归目标，在此基础上，MLLM 被鼓励预测响应中的下一个标记。该目标可以表示为：

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202503131900722.png)

其中，(N) 是真实响应的长度。

### 数据收集

有三种典型的规模化获取指令数据的方法：
* **数据适配**：利用现有的高质量的特定任务数据集来构建指令格式化的数据集。
* **自我指令生成**：利用 LLM 根据少量人工标注的样本生成文本指令数据。
* **数据混合**：多模态指令数据和仅语言数据的混合，包括混合指令微调（将两种类型的数据组合并随机打乱）和顺序指令微调（先用文本数据再用多模态数据）。

### 数据质量

提升数据质量的两个重要方面：
* **提示多样性**：多样化的提示有助于提升模型性能和泛化能力。
* **任务覆盖范围**：关于训练数据中涉及的任务类型，Du 等人进行了一项实证研究，发现视觉推理任务对于提升模型性能的效果优于图像描述和问答任务。此外，该研究建议，增强指令的复杂性可能比增加任务多样性或引入细粒度的空间注释更有益。

## 对齐微调

对齐微调更常用于**让模型与特定人类偏好对齐**的场景，例如减少幻觉的回答。目前，**基于人类反馈的强化学习（RLHF）** 和**直接偏好优化（DPO）** 是对齐调优的两种主要技术。

### RLHF
利用强化学习算法将LLMs与人类偏好对齐，并以人类标注作为训练循环中的监督。如InstructGPT所示，RLHF包含三个关键步骤：
1. **监督微调**：微调预训练模型，以呈现初步期望的输出行为。在RLHF设置中，微调后的模型称为策略模型。*此步骤可能会被跳过。*
2. **奖励建模（Reward Modeling）**
3. **强化学习（Reinforcement Learning）**

### DPO
DPO 使用简单的二分类损失从人类偏好标签中学习。与基于 PPO 的 RLHF 算法相比，DPO 不需要显式学习奖励模型，从而简化了整个流程为两个步骤：人类偏好数据收集和偏好学习。

# 评估

## 封闭集评估

**闭集问题**是指答案选项预先定义且限制在一个有限集合内的问题类型。评估通常在任务特定的数据集上进行。在这种情况下，响应可以通过基准指标自然地评判。

**评估设置**通常包括：
* 零样本（zero-shot） ：通常选择涵盖不同通用任务的广泛数据集，并将其划分为训练集（held-in）和测试集（held-out）。在前者上调整后，在后者上使用未见过的数据集甚至未见过的任务评估零样本性能。
* 微调（finetuning）：通常出现在领域特定任务的评估中。

上述评估方法通常局限于一小部分选定的任务或数据集，缺乏全面的定量比较。为此，一些研究努力开发专门为 MLLMs 设计的新基准。
* Fu 等人构建了一个综合评估基准 MME，包含 14 个感知和认知任务。MME 中的所有指令-回答对均由人工设计，以避免数据泄露。
* MMBench 是一个专门用于评估模型多维度能力的基准，使用 ChatGPT 将开放性回答与预定义选项匹配。
* Video-ChatGPT 和 Video-Bench 针对视频领域，提出了专门的基准和评估工具。

还有一些评估策略专注于评估模型的某个特定方面，例如 POPE 用于评估幻觉程度。

## 开放集评估
### 人工评估

人工评分需要人类对生成的回答进行评估。这种方法通常涉及手工设计的问题，旨在评估特定维度的能力。
* mPLUG-Owl 收集了一个与视觉相关的评估集，用于判断模型在自然图像理解、图表理解和流程图理解等方面的能力。
* GPT4Tools 构建了两个数据集，分别用于微调性能和零样本性能的评估，并从思维、行动、论证和整体表现等方面对回答进行评价。

### GPT评分

GPT 评分方法常用于评估多模态对话的性能。LLaVA 提出通过仅文本的 GPT-4 从不同方面（如帮助性和准确性）对回答进行评分。具体来说，从 COCO 验证集中随机抽取 30 张图像，每张图像关联一个简短问题、一个详细问题和一个复杂推理问题（通过 GPT-4 的自我指令生成）。模型生成的答案和 GPT-4 生成的答案都被发送给 GPT-4 进行比较。

将仅支持文本的 GPT-4 用作评估者的主要问题是，评估仅基于与图像相关的文本内容（如标题或边界框坐标），而无法直接访问图像本身。

随着 GPT 视觉接口的发布，一些研究开始利用更先进的 GPT-4V 模型来评估 MLLMs 的性能。Woodpecker使用 GPT-4V 根据图像判断模型回答的质量。由于 GPT-4V 可以直接访问图像，因此其评估结果预计比仅支持文本的 GPT-4 更加准确。

### 案例研究

另一种补充方法是通过案例研究比较 MLLMs 的不同能力。例如，一些研究评估了两种典型的高级商用模型：GPT-4V 和 Gemini。
* Yang 等人通过跨多个领域和任务构建一系列样本，对 GPT-4V 进行了深入的定性分析。这些任务涵盖了从基础技能（如生成标题和物体计数）到需要世界知识和推理的复杂任务（如笑话理解和作为具身代理的室内导航）。
* Wen 等人通过设计针对自动驾驶场景的样本，对 GPT-4V 进行了更为聚焦的评估。
* Fu 等人则通过将 Gemini-Pro 与 GPT-4V 进行对比，对其进行了全面评估。结果显示，尽管响应风格不同，GPT-4V 和 Gemini 在视觉推理能力上表现出相当的水平。

# 扩展多模态模型

* **粒度支持**：即对输入和输出粒度进行更精细支持的技术。
* **模态支持**：调整MLLM以支持更多多模态内容的输入，或生成更多模态的响应。
* **语言支持**：开发多语言模型，以覆盖更广泛的用户群体。
* **场景支持**：除了开发通用的通用助手外，一些研究还集中在需要考虑实际条件的更具体场景中，而另一些研究则将MLLM扩展到具有特定专业知识的下游任务中。

# 多模态幻觉

由MLLMs生成的响应与图像内容不一致的现象。

## 幻觉类型
* **存在幻觉**：最基本的形式，指的是模型错误地声称图像中存在某些物体。
* **属性幻觉**：指的是错误地描述某些物体的属性。它通常与存在幻觉相关，因为对属性的描述应基于图像中存在的物体。
* **关系幻觉**：一种更复杂的类型，同样基于物体的存在。它指的是对物体之间关系（如相对位置和互动）的错误描述。

## 评估方法
* **CHAIR**： 是一种早期用于评估开放式描述中幻觉水平的指标。该指标衡量的是在提到的所有物体中，包含幻觉物体的句子所占的比例。
* **POPE**： 是一种评估封闭式选择的方法。该方法通过构建多个带有二元选择的提示，每个提示都询问图像中是否存在特定物体。该方法还涵盖了更具挑战性的设置，以评估MLLMs的鲁棒性，并考虑了数据统计。最终评估使用了一种简单的关键词检测机制，即通过检测“是/否”关键词，将开放式回答转换为封闭式二元选择。
* **MME**：提供了更全面的评估，涵盖了存在性、数量、位置和颜色等方面。
* **HaELM**：不使用匹配机制来检测幻觉，提出使用纯文本LLM作为判断器，自动判断MLLM生成的描述是否与参考描述一致。
* **Woodpecker**：使用GPT-4V直接评估基于图像的模型响应，解决纯文本LLM评估只能访问有限的图像上下文并需要参考注释的问题。
* **FaithScore**：是一种更细粒度的指标，基于一种将描述性子句分解并分别评估每个子句的流程。
* **AMBER**：是一个无需LLM的基准，涵盖了判别任务和生成任务，并涉及三种幻觉类型。

## 缓解幻觉的方法

将目前已有方法大致分为三类：预校正、过程校正和后校正。

### 预校正
一种直观且直接的解决幻觉问题的方法是**收集专门的数据**（例如负面数据），并使用这些数据进行微调，从而生成幻觉较少的模型。
* **LRV-Instruction**：引入了一个视觉指令微调数据集。除了常见的正面指令外，该数据集还融入了在不同语义层次上精心设计的负面指令，以鼓励模型生成更符合图像内容的响应。
* **LLaVA-RLHF**：收集了人类偏好对，并通过强化学习技术对模型进行微调，从而使模型的回答更加贴近人类偏好，同时减少幻觉现象。

### 过程内校正
另一条研究路线是通过**改进架构设计或特征表示**来减少幻觉现象。这些工作试图探索幻觉产生的原因，并在生成过程中设计相应的解决方案以减轻其影响。
* **HallE-Switch**：对可能导致物体存在幻觉的因素进行了实证分析，并假设存在幻觉是因为物体未被视觉编码器正确锚定，而这些物体实际上是基于 LLM 的知识推断出来的。基于这一假设，该研究引入了一个连续控制因子及相应的训练方案，用于在推理过程中控制模型输出中的想象程度。
* **VCD**：指出物体幻觉主要由两个原因引起，即训练语料库中的统计偏差和 LLM 中嵌入的强大语言先验。作者注意到，当向图像中注入噪声时，MLLMs 更倾向于依赖语言先验而非图像内容生成响应，从而导致幻觉现象。为此，该研究设计了一种“放大-对比”解码方案，以抵消这种错误偏差。
* **HACL**：研究了视觉与语言的嵌入空间。基于观察结果，提出了一种对比学习方案，旨在将配对的跨模态表示拉得更近，同时将非幻觉文本表示与幻觉文本表示推开，从而减少幻觉现象的发生。

### 后校正
在输出生成后对幻觉进行纠正。
* **Woodpecker**：这是一个无需训练的通用幻觉修正框架。具体来说，该方法结合专家模型来补充图像的上下文信息，并设计了一条逐步修正幻觉的流水线。该方法具有可解释性，因为每一步的中间结果可以被检查，并且对象能够在图像中得到锚定。
* **LURE**：该方法训练了一个专门的修订器，用于屏蔽描述中不确定性较高的对象，并重新生成响应。

# 扩展技术

## 多模态Few-Shot学习（多模态上下文学习，Multimodal In-Context Learning，M-ICL）

ICL 具有两个显著特点：
* **与传统监督学习的区别**：不同于从大量数据中学习隐式模式的传统监督学习方法，ICL 的核心在于通过**类比**进行学习。LLMs 通过少量示例（以及可选的指令）进行学习，并将其推广到新问题上，从而以少样本的方式解决复杂且未见过的任务。
* **无需训练**：ICL 通常以无训练的方式实现，因此可以在推理阶段灵活集成到不同的框架中。

指令微调能够增强 ICL 能力。

ICL 被扩展到更多模态，形成了 多模态 Few-Shot 学习（Multimodal ICL, M-ICL）。

### 提升ICL能力

越来越多的研究专注于在各种场景下增强上下文学习（ICL）的性能。
* **MIMIC-IT**：通过构建包含多模态上下文格式的指令数据集，将上下文学习与指令微调相结合。在该数据集上进行指令微调后的模型在标题生成任务中表现出更强的少样本学习能力。
* **Emu**：扩展了 Flamingo的思想，在模型生成和对应的训练语料库中引入额外的模态。借助引入的视觉解码器（即 Stable Diffusion），模型能够从额外的视觉监督中学习，并支持更灵活的输出格式和上下文推理。具体而言，除了以纯文本形式回答问题外，模型还可以以图像形式给出响应。
* **Sheng 等人**：采用类似的思想，尝试将输出模态扩展为文本和图像两种形式。与使用专门的图像编码器不同，该研究采用统一的量化方案，并共享嵌入层。

此外，还有一些其他工作探索在特定设置下提升少样本学习性能的方法：
* **Link-context Learning**：专注于强化图像-标签对之间的因果联系，通过构建正负图像-描述对，提出了一种对比训练方案。
* **MMICL**：旨在增强模型处理多张相关图像的推理能力。为了加强图像与文本之间的联系，该研究提出了一种上下文方案，将交错的图像-文本数据转换为统一格式。
* **Jeong**：发现当插入少量不连贯的图像或文本作为噪声时，MLLMs 可能会被误导，从而给出与上下文不一致的回答。基于这一观察，该研究提出了一种预过滤方法，用于去除无关上下文，从而促进更连贯的响应。

### 应用
M-ICL主要应用于两种场景：
* **解决各种视觉推理任务**：通常涉及从少量特定任务的示例中学习，并将所学知识推广到一个新的但类似的提问。通过指令和示范提供的信息，LLMs 能够理解任务的目标以及输出的模板格式，最终生成预期的答案。
* **教会 LLMs 使用外部工具**：相比之下，工具使用的示例更为精细，通常包含一系列可按顺序执行的步骤以完成任务。因此，第二种场景与思维链密切相关。

## 多模态思维链（Multimodal Chain of Thought）

CoT 的核心思想是提示 LLMs 不仅输出最终答案，还输出得出该**答案的推理过程**，类似于人类的认知过程。

### 获取思维链的学习范式
获取 M-CoT 能力主要有三种方式：**微调、无训练的少样本/零样本学习**。这三种方式对样本量的需求依次递减。
* 微调方法通常涉及为 M-CoT 学习构建**特定的数据集**。
* 与微调相比，少样本/零样本学习在**计算效率**上更具优势。两者的主要区别在于，少样本学习通常需要手工设计一些上下文示例，以便模型能够更容易地逐步学习推理过程。相比之下，零样本学习不需要任何特定的 CoT 学习示例。在这种情况下，模型通过设计的指令提示，利用嵌入的知识和推理能力进行学习。

### 思维链配置
结构和长度是推理链的两个关键方面。
* 结构：
	* **单链推理**：被广泛使用。在逐步推理过程形成一个**单一的问题-理由-答案链**。
	* **树形链推理**：DDCoT 将一个问题分解为多个子问题，每个子问题由LLM自身或视觉专家解决以生成理由。然后，LLM聚合这些理由并进行推理以形成最终答案。
* 长度：
	* **自适应**：要求LLM自行决定何时停止推理链。
	* **预定义**：以预定义的长度停止推理链。

### 生成模式
* 基于填充的模式：要求根据上下文（前序和后序步骤）推断步骤以填补逻辑空白。
* 基于预测的模式：需要在给定条件（如指令和先前的推理历史）下扩展推理链。
这两种模式都要求生成的步骤必须一致且正确。

## LLM辅助的视觉推理

与传统的视觉推理模型相比，LLM辅助的视觉推理表现出以下几个显著优点：
* **强大的泛化能力**：得益于从大规模预训练中获得的丰富开放世界知识，这些系统能够以显著的**零样本或少样本**性能轻松推广到未见过的对象或概念。
* **新兴能力**：借助 LLMs 强大的推理能力，这些系统能够执行**复杂的任务**。例如，给定一张图像，MMREACT 可以解读其表面之下的深层含义，比如解释为什么某个表情包很有趣。
* **更好的交互性和可控性**：传统模型通常只允许有限的控制机制，并且往往需要昂贵的定制数据集。相比之下，基于 LLM 的系统可以通过**用户友好的接口**（如点击和自然语言查询）实现精细控制。

### 训练范式
* **免训练范式**：由于预训练的LLMs中存储了丰富的先验知识，一种直观且简单的方法是冻结预训练模型并直接提示LLMs以满足各种需求。根据设置，推理系统可以进一步分为：
	* **少样本模型**：需要一些手工制作的上下文样本来引导LLMs生成程序或一系列执行步骤。这些程序或执行步骤作为相应基础模型或外部工具/模块的指令。
	* **零样本模型**：更进一步，直接利用LLMs的语言/语义知识或推理能力。
* **微调范式**：采用进一步的微调来提高系统在工具使用方面的规划能力或增强其定位能力。

### LLM在其中的功能
将现有工作中，LLM在LLM辅助视觉推理系统中所扮演的角色分为三类：
* **LLM作为Controller**：LLM充当中央控制器，其职责包括：
	1. 将复杂任务分解为较简单的子任务/步骤：通常通过利用LLM的**CoT能力**来完成。
	2. 将这些任务分配给适当的工具/模块。
* **LLM作为决策者**： 复杂任务以多轮方式解决，通常以迭代方式进行。决策者通常履行以下职责：
	1. 总结当前上下文和历史信息，并决定当前步骤可用的信息是否足以回答问题或完成任务。
	2. 组织和总结答案，以用户友好的方式呈现。
* **LLM作为语义精炼器**： 主要利用其丰富的语言学和语义知识。具体来说，LLM通常被指示将信息整合为一致且流畅的自然语言句子，或根据不同的特定需求生成文本。

前两种角色与CoT相关。由于复杂任务需要分解为中间较简单的步骤，因此这些角色经常被使用。当LLM作为控制器时，系统通常在一轮内完成任务，而在决策者的情况下，多轮更为常见。

# 挑战与未来方向
多模态大语言模型（MLLMs）的发展仍处于初级阶段，因此存在许多改进空间，总结如下：
* 当前的MLLMs在**处理长上下文的多模态信息方面存在局限性**。这限制了具有更多多模态标记的高级模型的发展，例如长视频理解以及图像和文本交错的长文档理解。
* MLLMs**需要升级以遵循更复杂的指令**。例如，生成高质量问答对数据的主流方法仍然是提示闭源的GPT-4V，因为它具有先进的指令遵循能力，而其他模型通常无法实现。
* 在**M-ICL（多模态上下文学习）和M-CoT（多模态思维链）** 等技术方面仍有很大的改进空间。目前对这两种技术的研究仍处于初级阶段，MLLMs的相关能力较弱。因此，探索其底层机制和潜在改进方向具有广阔前景。
* 基于多模态大语言模型（MLLMs）**开发具身代理**是一个热门话题。开发能够与现实世界互动的此类代理具有重要意义。这些努力需要具备关键能力的模型，包括感知、推理、规划和执行。
* **安全问题**。与大型语言模型（LLMs）类似，MLLMs可能容易受到精心设计的攻击。换句话说，MLLMs可能被误导输出有偏见或不理想的响应。因此，提高模型的安全性将是一个重要课题。

# 结论
在本文中，我们对现有的MLLM文献进行了综述，并提供了其主要方向的广泛视角，包括基本框架和相关扩展。此外，我们强调了当前需要填补的研究空白，并指出了一些有前景的研究方向。我们希望本次综述能为读者提供MLLM当前进展的清晰图景，并激发更多研究工作。

