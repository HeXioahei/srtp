# 摘要
最近的视觉-语言(VL)研究已经显示出显著的进展，通过从具有转换器模型的海量图文对中学习类属表征。虽然现有的研究集中在利用大型预先训练的模型来实现高精度，但构建轻量级模型具有很大的实践价值，但探索较少。在本文中，我们提出了一种更小、更快的VL模型--MiniVLM，它可以像较大的VL模型一样在各种下游任务上具有良好的性能。MiniVLM由两个模块组成，一个是视觉特征提取模块，另一个是基于变换的视觉语言融合模块。受单级EfficientDet[52]网络的启发，我们设计了一种两级高效的特征提取算法(TEE)，与基准模型相比，视觉特征提取的代价降低了99%。在比较了不同的紧凑型BERT模型后，我们采用了MiniLm[59]结构来降低变压器模块的计算成本。此外，我们通过添加7M Open Images数据来改进MiniVLM预训练，这些数据是通过最先进的字幕模型进行伪标记的。我们还使用从强标签模型获得的高质量图像标签进行预训练，以增强跨通道对齐。大型模型可以离线使用，不会增加微调和推理的任何开销。通过以上设计选择，我们的MiniVLm将模型尺寸减少了73%，Flop减少了99%，同时在多个VL任务上保持了94−97%的准确率。我们希望MiniVLM有助于简化最先进的VL研究在边缘应用中的使用。