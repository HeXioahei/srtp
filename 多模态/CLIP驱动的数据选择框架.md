> A CLIP-Powered Framework for Robust and Generalizable Data Selection
> 
> 作者单位：南京大学
> 
> 论文链接：https://openreview.net/forum?id=9bMZ29SPVx
> 
> 代码链接：https://github.com/Jackbrocp/clip-powered-data-selection

## 1.introduction
近年来，大规模数据集对深度学习模型的进步至关重要，但在如此大的数据集上进行训练不可避免地会产生大量的存储和计算开销。同时，真实世界的数据集通常包含冗余和嘈杂的数据，对训练效率和模型性能产生负面影响。数据选择在从整个数据集中识别最具代表性的样本方面显示出前景，旨在通过降低训练成本来最大限度地减少性能差距。**现有工作通常依赖单模态信息为单个样本分配重要性分数，这可能会导致评估不准确**，尤其是在处理嘈杂或损坏的样本时。为了解决这一限制，我们提出了一种新型的 CLIP 驱动的数据选择框架，该框架利用多模态信息进行更稳健和可推广的样本选择。具体来说，我们的框架由三个关键模块组成——**数据集适配、样本评分和选择优化**——它们共同利用广泛的预训练多模态知识来全面评估样本影响并通过多目标优化优化选择结果。广泛的实验表明，我们的方法在各种基准数据集上始终优于现有的最先进的基线。值得注意的是，我们的方法有效地从数据集中去除了嘈杂或损坏的样本，使其能够以更少的数据实现更高的性能。这表明它不仅是一种加速训练的方法，还可以提高整体数据质量。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111839950.png)

图 1：多模态选择的好处。传统的单模态方法（上半部分）可能会难以处理嘈杂和损坏的数据，而我们的多模态方法（下半部分）可以识别具有多样性的类代表性样本，同时有效过滤掉噪声和损坏的数据。

## 2.motivation
现有的数据选择方法通常通过三个角度采用精心设计的标准：**重要性得分 Paul** 等人（2021 年）;Tan et al. （2024），**图像数据分布** Zheng et al. （2023）;Xia 等人 （2023） 和**基于优化的函数** Killamsetty 等人 （2021b）;杨等人（2023b）。尽管取得了可喜的结果，但这些方法仍表现出一定的局限性。一方面，仅依赖单模态图像信息可能会导致歧义，尤其是当存在嘈杂的样本时，这可能会导致对样本效果的评估不准确。例如，某些方法采用基于难度的标准来选择数据；然而，仅根据图像模态来区分真正困难的样本和嘈杂的样本是一个重大挑战。另一方面，现有方法通常选择得分最高或最低的样本，而组内高分和低分样本之间的相互作用可以显着影响整体表现，这被称为“**群体效应**”Koh 等人（2019）;杨等人（2023b）。因此，一种更有益的方法是利用多模态信息的力量并评估样本组的集体效应。

## 3.contribution
- 我们深入分析了以前仅依赖图像模态的工作的缺点，并提出了一种新的 CLIP 驱动的数据选择框架，该框架利用多模态特征进行稳健和可推广的数据选择
    
- 我们的框架包括**数据集适配**和**样本评分模块**，以促进多模态知识转移和全面的样本重要性评估。这种双模态设计有效地从数据集中去除了嘈杂和损坏的样本。
    
- 设计了**选择优化模块**，通过多目标优化，识别出具有预期选择率的最优子集，在保持高效率的同时有效解决群体效应。
    
- 实验结果表明，我们的方法在性能、跨架构泛化以及对噪声和损坏图像的鲁棒性方面优于以前的 SOTA 方法。同时，我们的方法在性能和选择效率方面实现了最佳权衡，为未来的研究建立了强大的数据选择基线。

## 4.Method
![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111846647.png)
图 2：我们提出的方法由数据集适配、抽样评分和选择优化模块组成。数据集自适应模块用于学习特定于数据集的知识。样本评分模块计算两个分数 Sand S 来评估样本重要性，并在此基础上进行选择优化，根据预期选择比率确定最佳子集。

我们提出的方法总结在图 2 中。该方法涉及使用预训练的视觉语言基础模型 CLIP 来构建多模态特征空间。不过**预训练数据集和目标数据集之间可能存在域偏移或差异** Liu et al. （2024a）;阿里贾尼等人（2024）。为了促进数据集适配并增强对特定于数据集的知识的学习，我们为这两种模式合并了**维度保留适配器**。接下来，得出两个分数以全面评估样本重要性，即**语义对齐分数 （SAS）**（表示为 S_A）和**样本多样性分数（SDS）**（表示为 S_D）。此外，我们不仅仅基于样本分数进行选择，而是设计了一种**多目标优化**来确定具有预期选择比率的最佳子集，从而有效地减轻了群体效应。我们将在后续部分中提供详细的方法。

#### 4.1.数据集适应
为了缓解预训练数据集和目标数据集之间的域偏移和差异，我们结合了维度保留适配器来对目标数据集进行适配。图像和文本适配器分别表示为 A_I 和 A_T。两个适配器都针对知识转移进行了微调，而预训练的 CLIP 权重被冻结。为了保持高效率，两个适配器都使用**简单的 MLP**。

具体来说，微调过程采用了 **InfoNCE 损失** Parulekar 等人 （2023）;Oord 等人（2018 年），它最大限度地提高了图像和文本表示之间的相互信息。文本表示使用提示描述类别信息：“[CLS] 的照片”，其中标记 [CLS] 代表相应的类别。损耗可确保适配器有效地对齐并捕获两种模式的相关特征。此外，它还增强了模型**区分正负对的能力**，从而提高了特定数据集深度表示的鲁棒性和准确性。

#### 4.2.样本得分
对于分类数据集，训练样本的学习过程与获取相应类别的知识有着内在的联系。更准确地表示其类别的训练样本通常在训练深度网络方面更有效。通过这种方式，语义对齐分数 （SAS） 旨在评估训练样本与其相应类别之间的语义相似性。具体来说，由于图像和文本特征驻留在同一嵌入空间内 Radford 等人（2021），因此 **SAS 是通过计算嵌入图像与相应文本深度描述之间的余弦相似度来推导出来的**。因此，第 i 个样本的 SAS 定义为：

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111858129.png)

对于选定的数据集，数据量的减少可能会限制所选数据的多样性，这对于训练数据集非常重要 Yang 等人 （2024a）。为了解决这个问题，我们引入了另一种多样性，全面评估训练数据的效果。**样本多样性分数 （SDS） 定义为每个样本与其同类的 k 个邻居样本之间的平均距离**：

![debccfb1eb79e8b6d2808eb4e99f7bd8.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111900548.png)

其中我们使用 KNN 算法获取每个样本的邻居样本，距离度量基于 lnorm，k 通常设置为每个类样本数的 10%。这样，SDS 可以理解为特征空间中训练样本的局部密度。**如果一个样本具有较多的邻居且距离较近（即较低的 SDS），则其训练效率可能更容易被其他邻居样本替代**。因此，**选择 SDS 较高的样品**通常更有利。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111903686.png)

图 3：SAS 和 SDS 有效性的说明。圆圈和十字分别表示正常样本和噪声样本。不同的颜色对应于选择结果。SDS（b）选择不同的样本，但可能包括噪声。SAS（c）可以避免嘈杂的样本，但可能会遗漏更广泛的类别信息。使用这两个分数 （d） 可以选择具有类别代表性的，同时保持高度多样性。

SAS 和 SDS 的影响如图 3 所示。SDS 有助于样本的多样性，但所选数据点可能包含噪声（图 3（b））。另一方面，SAS 可以选择语义上合适的样本，因为这些点基本上围绕样本中心（图 3（c））。然而，这些样品可能过于集中，因此缺乏多样性。当 SDS 和 SAS 一起使用时（图 3（d）），我们可以用更少的数据覆盖整个类别空间，并选择既具有语义代表性又多样化的样本，从而提高数据选择的有效性。

#### 4.3.选择优化
Killamsetty 等人（2021b）不依赖组合优化函数进行样本选择，而是通过 **SGD 多目标优化**来确定选择，从而提高了计算效率并加速了收敛。具体来说，我们引入了一个样本参数 d 来表示选择决策，其中元素 1 表示选择，而 0 表示其他元素。尽管由于缺乏梯度，二进制参数在神经网络中很难优化，但我们使用 sigmoid（·）函数将 d 的连续值推向近似二值化。优化后，d 被严格二值化以明确指示最终的样本选择。最初，d 使用所有 1 进行初始化。

为了指导优化过程，我们引入了三个损失项目。第一项 L_sa 旨在优先考虑具有高 SAS 的样本，因为这些样本更能代表其相应的类别，定义如下：

![b06b6d053995df01a6fcc24ce838fbbd.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111911036.png)

其中 N 是样本总数。对低 SAS 样本进行处罚，并鼓励选择语义对齐性更好的样本。此外，我们还引入了另一个损失项 L_sd，以鼓励选择具有更高 SDS 特征的更多样化的样品，其定义为：

![4ae66e7d406f89a9ae6036dc8050071e.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111913849.png)

为了减轻群体效应，我们根据特定的选择比率优化所选数据集，旨在确定最佳子集。我们引入选择损失项 L_s 来确保选择工艺遵循目标比例。然而，从连续实值参数优化中推导出精确的选择率是困难的。虽然严格二值化的值有助于显式样本选择，但通过梯度反向传播进行优化具有挑战性。为了解决这个问题，我们利用**直通式估计器（STE）** Bengio 等人（2013）来估计实际选择率并推导出梯度。STE 允许梯度在反向传播期间通过离散决策，有效地结合连续参数和二元参数的优势，以实现高效优化和准确的样品选择。这样，L_s 定义为：

![5ed02f256edbb94a757af0fd2f5b4eb7.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111914563.png)

其中 II 是一个指标函数，s 表示预期的选择比率。损失项将参数 d 引导至接近二进制值，确保 的计数与预期样本量一致。由于选择是自适应优化引导的，因此最终的选择比例可能会略有偏离目标。为了最小化这种偏差，我们用阈值θ来约束 Land，在我们的工作中，阈值θ设置为 5×10，确保实际选择率与预期值的差异小于±0.05%。我们还在附录 A 中提供了θ对实际选择比差距的理论分析。最后，将整体损失函数表述为：

![5b26a73f9b935a3491a5840c715bf269.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202509111922078.png)

其中α和β是根据损失项之间的数值差异进行调整的系数，可以方便地设置。附录 B 的算法 1 概述了完整的工作流程。

复杂性分析所提出的方法包括三个主要组成部分。1）数据集适配涉及对图像和文本适配器进行微调。由于适配器由简单的线性层组成，因此参数数量很少，并且前向传递和后向传递的计算效率都很高。2）在样本评分过程中，计算 SAS 和 SDS 的复杂度分别为 O（N）和 O（K ∗ f），其中 K 为类别数，f 为特征维度，典型为 512。KNN 算法的复杂度为 O（N∗ f），其中 N 是每个类的样本数。鉴于 K 和票价常数和 Nis 通常比 N 小得多，这个过程的总体复杂度约为 O（N ）。3）d 的选择优化不涉及深度模型，是一个数值优化过程。复杂度与参数数量成正比，即 O（|w|） = O（N ）。