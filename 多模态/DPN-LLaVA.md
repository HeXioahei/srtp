# 摘要
多模态大语言模型（MLLM）在各种视觉语言（VL）任务中表现出令人印象深刻的性能，但它们昂贵的计算仍然限制了现实世界的应用。为了解决这个问题，最近的努力旨在压缩视觉特征以节省MLLM的计算成本。然而，直接视觉压缩方法，例如高效投影仪，不可避免地破坏了MLLM中的视觉语义学，尤其是在困难的样本中。为了克服这一缺点，我们为高效MLLM提出了一种新颖的动态金字塔网络（DPN）。具体来说，DPN将MLLM制定为一种分层结构，其中视觉特征随着深度的增加而逐渐压缩。在这种情况下，即使具有高压缩比，细粒度的视觉信息仍然可以在浅层中被感知。 为了最大限度地发挥DPN的优势，我们进一步提出了一种创新的动态池化专家（DPE），它可以根据输入特征动态选择最佳视觉压缩率。通过这种设计，更硬的样本将被分配更大的计算，从而保留模型性能。为了验证我们的方法，我们在两个流行的MLLM和十个基准测试上进行了广泛的实验。实验结果表明，DPN可以在LLaVA上节省高达56%的平均FLOPs，同时进一步实现+0.74%的性能提升。此外，DPN的泛化能力也在现有的名为LLaVA-HR的高分辨率MLLM上得到验证。

