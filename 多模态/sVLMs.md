# sVLMs的架构分类
* 基于Transformer：
	* 特点：自注意力机制
	* 优点：强大的多模态理解和高校表示学习
* 基于Mamba：
	* 特点：状态空间模型（SSM）
	* 优点：先行可扩展性和计算效率
* 混合：
	* 特点：结合Transformer、CNN和其他轻量级机制
	* 优点：平衡任务性能和计算需求

# 基于Transformer的模型代表

## TinyGPT-V

* **高效架构**：集成紧凑的 Phi-2 语言模型和预训练视觉编码器
* **新型训练方法**：专注于小型预训练骨干网络
* **资源高效训练和推理**：克服大型 MLLMs 的封闭性
* **关键技术**：LoRA (Low-Rank Adaptation)、Layer Normalization

## MiniGPT-4

* **架构特点** 
	- **创新方法**：通过冻结视觉编码器与先进 LLM 对齐
	- **技术挑战**：复制 GPT-4 的多模态能力，同时保持透明度
	- **架构组成**：预训练 ViT 和 Q-Former，线性投影层，Vicuna LLM
	- **两阶段训练**：大规模图像-文本对预训练 + 精细调整
- **性能评估**
	- **优势**：详细图像描述生成、网站创建、梗图解读、创意任务
	- **局限性**：图像描述幻觉、空间信息理解困难

## TinyViT

* **架构特点**：
	* **轻量化视觉 Transformer (ViT)**：为计算能力有限的设备设计
	* **知识蒸馏 (Knowledge Distillation)**：从大型模型学习，提升性能
	* **分层结构**：逐步下采样和局部注意力，平衡效率与精度
* **应用场景**：
	- 图像分类
	- 目标检测
	- 语义分割
* **局限性**：大型模型尺寸和计算成本，实时性不足

## FastViT

* **架构**
	* **混合视觉 Transformer**：兼顾速度和精度
	* **RepMixer 块**：结构化重参数化，消除跳跃连接，提高效率
	* **训练时过参数化**：增强精度，但增加计算开销
* **优势**
	- 优于 CMT, EfficientNet, ConvNeXt 等模型
	- 图像分类、目标检测、语义分割
* **局限性**
	- 训练时间增加
	- 硬件特定优化限制适应性

## LLaVA-Mini

* **架构**：
	* 视觉编码器
	* 模态预融合模块：视觉信息压缩，减少 FLOPs
	* 查询压缩：进一步压缩视觉标记数量
	* LLM：降低计算成本，保持视觉理解能力
* **优势**：高分辨率图像和视频任务，优于先前模型
* **局限性**：视觉细节丢失，依赖查询压缩和模态预融合

## Moondream2

* **架构**：
	* 模态预融合
	* 视觉标记压缩
	* 查询压缩
* **优势**
	- 高效处理图像和视频任务
	- 边缘设备适用
- **局限性**
	- 生成不准确陈述
	- 难以理解细微指令
	- 潜在偏见
	- 依赖大规模预训练
