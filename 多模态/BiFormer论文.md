# BiFormer：具有双级路由注意力的视觉 Transformer

朱磊 ¹ 王新疆 ² 柯章瀚 ¹ 张伟 ² 刘润森 ¹†¹ 香港城市大学 ² 商汤科技研究院电子邮箱：{lzhu68-c,zhanghake2-c}@[my.cityu.edu.hk](https://my.cityu.edu.hk/), {wangxinjiang,wayne.zhang}@[sensetime.com](https://sensetime.com/), Rynson.Lau@cityu.edu.hk

## 摘要

作为视觉 Transformer（Vision Transformer）的核心构建模块，注意力机制是捕捉数据长程依赖关系的强大工具。但这种能力的实现需要付出代价：由于需计算所有空间位置间令牌（token）的两两交互，注意力机制会产生巨大的计算负担与沉重的内存占用。已有一系列研究尝试通过在注意力中引入手工设计且与内容无关的稀疏性来缓解这一问题，例如==将注意力操作限制在局部窗口、轴向条带或扩张窗口内==[^1]。与这些方法不同，本文提出一种基于==双级路由（bi-level routing）==的新型动态稀疏注意力机制，能够以==内容感知==的方式更灵活地分配计算资源。具体而言，对于每个查询（query），首先在粗粒度区域层面过滤掉无关的键值对（key-value pairs），随后在剩余候选区域（即路由区域）的并集上执行细粒度的令牌间注意力操作。本文为所提==双级路由注意力（Bi-level Routing Attention, BRA）==提供了一种简单且高效的实现方式：利用稀疏性节省计算量与内存的同时，仅涉及 GPU 友好的稠密矩阵乘法。以双级路由注意力为核心构建模块，本文进一步提出一种通用视觉 Transformer，命名为 ==BiFormer==。由于 BiFormer 能以查询自适应的方式关注一小部分相关令牌，不受其他无关令牌的干扰，因此兼具优异性能与高计算效率，在==密集预测任务==中表现尤为突出。在图像分类、目标检测、语义分割等多个计算机视觉任务上的实验结果，均验证了本文设计的有效性。代码已开源至：[https://github.com/rayleizhu/BiFormer](https://github.com/rayleizhu/BiFormer)。

## 1. 引言

==Transformer== 具备诸多适合构建强大数据驱动模型的特性：首先，它能够捕捉数据中的长程依赖关系 [29,42]；其次，它==几乎无归纳偏置==，使得模型能更灵活地适配海量数据 [15]；最后，它具有==高并行性==，这对大型模型的训练与推理十分有利 [13,33,36,42]。因此，Transformer 不仅彻底改变了自然语言处理领域，在计算机视觉领域也展现出极具前景的发展潜力。

过去两年间，计算机视觉领域见证了视觉 Transformer 的爆发式增长 [1,14,15,29,44,46]。在这些研究中，一个热门方向是改进其核心构建模块 —— 注意力机制。与本质上属于局部算子的卷积不同，注意力机制的关键特性是==全局感受野==，这一特性赋予视觉 Transformer 捕捉长程依赖的能力 [42]。然而，该特性也带来了代价：由于注意力需计算所有空间位置间令牌的亲和度（affinity），其==计算复杂度极高==，且内存占用沉重。

为缓解这一问题，一个可行方向是为视觉 Transformer 引入==稀疏注意力== [6]，使每个查询仅关注一小部分键值对而非全部。基于这一思路，研究者们探索了多种手工设计的稀疏模式，例如将注意力限制在局部窗口 [29]、扩张窗口 [41,46] 或轴向条带 [46] 内。另一方面，也有研究尝试让稀疏模式适应数据 [5,48]，但这些方法虽通过不同策略合并或选择键 / 值令牌，所选令牌却与查询无关（即所有查询共享同一组令牌）。然而，根据预训练视觉 Transformer（ViT）[15] 与基于 Transformer 的端到端目标检测模型（DETR）[1] 的可视化结果，不同语义区域的查询实际上会关注截然不同的键值对。因此，强制所有查询关注同一组令牌的做法可能并非最优。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202510112026473.png)
图 1. 原始注意力及其稀疏变体。(a) 原始注意力在全局范围内运作，导致计算复杂度高且内存占用大。(b)-(d) 一些研究尝试通过引入具有不同手工设计模式的稀疏注意力来降低复杂度，例如局部窗口 [29, 46]、轴向条带 [14]、扩张窗口 [41, 46]。(e) 可变形注意力 [48] 通过变换规则网格实现图像自适应稀疏。(f) 我们通过双层路由注意力实现动态的、查询感知的稀疏性，首先搜索 top-k（此例中 k=3）相关区域，然后关注它们的并集。

本文旨在设计一种具有动态、查询感知稀疏性的注意力机制，==核心目标是让每个查询仅关注一小部分语义相关性最强的键值对==。首要问题是如何定位这些需关注的键值对：例如，若像文献 [17] 那样以逐查询方式选择键值对，仍需计算所有查询与键之间的两两亲和度，因此计算复杂度与普通注意力相同；另一种思路是基于每个查询的局部上下文预测注意力偏移量 [10,48]，虽可避免两两亲和度计算，但难以建模长程依赖关系 [48]。

为高效地全局定位有价值的待关注键值对，本文提出一种 ==“区域到区域” 的路由方法==。核心思想是：先在粗粒度区域层面过滤掉最无关的键值对，而非直接在细粒度令牌层面操作。具体实现为：==首先构建区域级亲和度图，随后对其剪枝，仅保留每个节点的前 k 个连接==。如此一来，每个区域只需关注前 k 个 “路由区域”。确定待关注区域后，下一步是执行令牌间注意力操作 —— 由于此时键值对在空间上可能分散，该步骤的高效实现具有挑战性。对于这种情况，虽然稀疏矩阵乘法可适用，但在现代 GPU 上效率低下（GPU 依赖合并内存操作，即一次访问数十个连续字节的块 [31]）。为此，本文提出一种通过==聚集键 / 值令牌==实现的简单解决方案，仅涉及硬件友好的稠密矩阵乘法。由于该方法包含==区域级路由步骤==与==令牌级注意力步骤==，故将其命名为 ==“双级路由注意力（BRA）”==。

以双级路由注意力为核心构建模块，本文提出 BiFormer—— 一种通用视觉 Transformer 骨干网络，可应用于分类、目标检测、语义分割等多种任务。由于双级路由注意力使 BiFormer 能以内容感知的方式，为每个查询关注一小部分最相关的键值对令牌，因此模型实现了更优的 “计算 - 性能” 权衡。例如，BiFormer-T 在仅 46 亿浮点运算次数（FLOPs）的计算量下，在 ImageNet-1K 分类任务上实现了 83.8% 的 Top-1 准确率 —— 据我们所知，在未使用外部数据训练或蒸馏 [23,40] 的情况下，这是相同计算预算下的最佳性能。在实例分割、语义分割等下游任务中，该模型也持续展现出性能提升。

综上，本文的贡献如下：

1. ==为普通注意力引入一种新型双级路由机制，实现了查询自适应的内容感知稀疏模式；==
2. ==以双级路由注意力为基本构建模块，提出通用视觉 Transformer——BiFormer；==
3. ==在图像分类、目标检测、语义分割等多种计算机视觉任务上的实验表明，在相似模型规模下，BiFormer 的性能显著优于基准模型。==

## 2. 相关工作

### 2.1 视觉 Transformer

Transformer 是一类神经网络，采用通道维度的多层感知机（MLP）块进行逐位置嵌入（通道混合），并通过注意力块 [42] 进行跨位置关系建模（空间混合）。Transformer 最初为自然语言处理领域提出 [13,42]，随后由 DETR [1]、ViT [15] 等开创性工作引入计算机视觉领域。与卷积神经网络（CNN）相比，二者最大的区别在于：Transformer 以注意力机制替代卷积，实现全局上下文建模。然而，由于普通注意力需计算所有空间位置间的特征亲和度，其计算负担与内存占用极高，在高分辨率输入场景下问题尤为突出。因此，探索更高效的注意力机制成为重要研究方向。

### 2.2 高效注意力机制

已有大量研究通过稀疏连接模式 [6]、低秩近似 [43] 或循环操作 [11]，试图降低普通注意力的计算与内存复杂度瓶颈，文献 [39] 对这些注意力变体进行了全面综述。在视觉 Transformer 领域，得益于 Swin Transformer [29] 的巨大成功，稀疏注意力近年来备受关注。Swin Transformer 将注意力限制在非重叠局部窗口内，并引入移位窗口操作实现相邻窗口间的通信。为在合理计算预算下实现更大甚至类全局感受野，后续研究提出了多种手工设计的稀疏模式，如扩张窗口 [41,46] 或十字形窗口 [14]。

也有研究尝试让稀疏模式适应数据，例如 DAT [48]、TCFormer [53] 与 DPT [5]。这些方法虽通过不同合并或选择策略减少键 / 值令牌数量，但图像中所有查询共享同一组键 / 值令牌。与之不同，本文探索的是 “查询感知” 的键 / 值令牌选择。启发本文这一思路的关键观察是：根据预训练 ViT [15] 与 DETR [1] 的可视化结果，不同查询的关注区域可能存在显著差异。

本文通过 “粗到细” 的方式实现查询自适应稀疏性，这与四叉树注意力 [38] 有一定相似性。但二者存在本质区别：双级路由注意力的目标是定位少量最相关的键值对，而四叉树注意力构建令牌金字塔，并从不同粒度的所有层级聚合信息；此外，四叉树需深度递归以覆盖整个特征图，这会损害并行性，而双级路由注意力可通过聚集键 / 值令牌、后续执行稠密矩阵乘法实现更高效的计算。因此，四叉树 Transformer 的速度远慢于本文提出的 BiFormer。

## 3. 本文方法：BiFormer

本节详细阐述本文提出的方法。3.1 节首先简要概述注意力机制；3.2 节介绍新型双级路由注意力（BRA）机制，该机制可实现动态、查询自适应的稀疏性；3.3 节将证明，通过合理选择区域划分大小，双级路由注意力的复杂度可达到 $O ((HW)^{4/3})$；3.4 节以双级路由注意力为核心构建模块，提出一种新的分层视觉 Transformer——BiFormer。

### 3.1 预备知识：注意力机制

给定查询 $Q∈ℝ^{(Nq×C)}$、键 K∈ℝ^(Nkv×C) 和值 V∈ℝ^(Nkv×C)（其中 Nq 为查询数量，Nkv 为键 / 值数量，C 为通道数），注意力函数将每个查询转换为值的加权和，权重由查询与对应键的归一化点积计算得到。其矩阵形式可简洁定义为：\(Attention (Q, K, V)=softmax\left(\frac{Q K^{T}}{\sqrt{C}}\right) V. \tag{1}\)其中，标量因子√C 的引入是为了避免权重过度集中与梯度消失 [42]。

在 Transformer 中，实际使用的核心构建模块是多头自注意力（Multi-Head Self-Attention, MHSA）。“自注意力” 意味着查询 Q、键 K、值 V 均由同一输入 X∈ℝ^(N×C) 通过线性投影得到（对于视觉 Transformer，X 是空间展平后的特征图，即 N=H×W，H 和 W 分别为特征图的高度与宽度）；“多头” 则表示将输出沿通道维度划分为 h 个 “头”（head），每个头使用独立的投影权重组。其形式化定义为：\(\begin{aligned} & MHSA(X)=Concat\left( head_{0}, head_{1}, ..., head_{h}\right) W^{o}, \\ & head_{i}=Attention\left(X W_{i}^{q}, X W_{i}^{k}, X W_{i}^{v}\right), \end{aligned}\)其中，head_i∈ℝ^(N×(C/h)) 是第 i 个注意力头的输出；W_i^q、W_i^k、W_i^v∈ℝ^(C×(C/h)) 是对应输入的投影权重；额外的线性变换（权重矩阵 W^o∈ℝ^(C×C)）用于融合所有头的输出。

多头自注意力的复杂度为 O (N²)，这是因为存在 N 个查询，且每个查询需关注 N 个键值对。如此高的复杂度导致其在输入空间分辨率提升时，可扩展性极差。

### 3.2 双级路由注意力（BRA）

为缓解多头自注意力的可扩展性问题，已有研究 [14,29,41,46,48] 提出多种稀疏注意力机制，使每个查询仅关注少量键值对而非全部。然而，这些现有方法要么采用手工设计的静态模式，要么让所有查询共享同一组采样键值对（如图 1 所示）。本文探索一种动态、查询感知的稀疏注意力机制，核心思路是：先在粗粒度区域层面过滤掉大部分无关键值对，仅保留少量路由区域；随后在这些路由区域的并集上执行细粒度令牌间注意力操作。为简化符号，本节将以单头自注意力、单输入为例进行讨论（实际应用中采用的是多头自注意力与批量输入）。双级路由注意力的完整算法以 PyTorch 风格 [32] 伪代码形式总结于算法 1，下文将详细解释其步骤。

#### 算法 1 双级路由注意力（BRA）的 PyTorch 风格伪代码

python

运行

```python
# 输入：特征图 (H, W, C)，假设 H == W（高度等于宽度）
# 输出：特征图 (H, W, C)
# S：区域数量的平方根（即划分为S×S个区域）
# k：待关注的区域数量
# 对输入进行分块：(H, W, C) → (S², HW/S², C)
x = patchify(input, patch_size=H//S)
# 对查询、键、值进行线性投影
query, key, value = linear_qkv(x).chunk(3, dim=-1)
# 计算区域级查询与键 (S², C)
query_r, key_r = query.mean(dim=1), key.mean(dim=1)
# 构建区域图的邻接矩阵 (S², S²)
A_r = mm(query_r, key_r.transpose(-1, -2))
# 计算路由区域的索引矩阵 (S², k)
I_r = topk(A_r, k).index
# 聚集键值对
key_g = gather(key, I_r)  # (S², kHW/S², C)
value_g = gather(value, I_r)  # (S², kHW/S², C)
# 执行令牌间注意力操作
A = bmm(query, key_g.transpose(-2, -1))
A = softmax(A, dim=-1)
output = bmm(A, value_g) + dwconv(value)
# 恢复为原始形状 (H, W, C)
output = unpatchify(output, patch_size=H//S)
```

注：bmm 表示批量矩阵乘法；mm 表示矩阵乘法；dwconv 表示深度可分离卷积。

#### 3.2.1 区域划分与输入投影

给定二维输入特征图 X∈ℝ^(H×W×C)，首先将其划分为 S×S 个非重叠区域，每个区域包含 (HW)/S² 个特征向量。该步骤通过将 X 重塑为 X^r∈ℝ^(S²×(HW/S²)×C) 实现。随后，通过线性投影得到查询、键、值张量 Q、K、V∈ℝ^(S²×(HW/S²)×C)，公式如下：\(Q=X^{r}W^{q}, K=X^{r}W^{k}, V=X^{r}W^{v}, \tag{3}\)其中，W^q、W^k、W^v∈ℝ^(C×C) 分别为查询、键、值的投影权重。

#### 3.2.2 基于有向图的区域到区域路由

通过构建有向图，可确定 “每个区域需关注哪些其他区域” 的关系。具体而言：首先对 Q 和 K 执行区域内平均操作，得到区域级查询与键 Q^r、K^r∈ℝ^(S²×C)；随后，通过 Q^r 与 K^r 的转置进行矩阵乘法，得到区域到区域亲和度图的邻接矩阵 A^r∈ℝ^(S²×S²)，公式如下：\(A^{r}=Q^{r}\left(K^{r}\right)^{T} . \tag{4}\)

邻接矩阵 A^r 中的元素用于衡量两个区域的语义相关性。接下来的核心步骤是对亲和度图进行剪枝：为每个区域保留相关性最强的前 k 个连接。通过逐行执行 top-k 操作，得到路由索引矩阵 I^r∈ℕ^(S²×k)，公式如下：\(I^{r}=topkIndex\left(A^{r}\right) . \tag{5}\)

其中，I^r 的第 i 行包含第 i 个区域最相关的 k 个区域的索引。

#### 3.2.3 令牌间注意力

有了区域到区域的路由索引矩阵 I^r 后，即可执行细粒度令牌间注意力操作：对于区域 i 中的每个查询令牌，它将关注由 I^r (i,1)、I^r (i,2)、…、I^r (i,k) 索引的 k 个路由区域所包含的所有键值对。然而，由于这些路由区域可能分散在整个特征图中，而现代 GPU 依赖合并内存操作（一次加载数十个连续字节的块），该步骤的高效实现具有挑战性。为此，本文首先对键和值张量进行聚集操作，公式如下：\(K^{g}=gather(K,I^{r}), V^{g}=gather(V,I^{r}), \tag{6}\)其中，K^g、V^g∈ℝ^(S²×(kHW/S²)×C) 是聚集后的键与值张量。随后，在聚集后的键值对上执行注意力操作：\(O=Attention\left( Q, K^{g}, V^{g}\right)+LCE(V). \tag{7}\)

本文引入文献 [37] 中的局部上下文增强项 LCE (V)，其中 LCE (・) 由深度可分离卷积实现，卷积核大小设为 5。

### 3.3 双级路由注意力的复杂度分析

双级路由注意力与普通注意力类似，可直接建模长程依赖关系，但本节将证明：通过合理选择区域划分因子 S，双级路由注意力的复杂度可降至 O ((HW)^(4/3))，远低于普通注意力的 O ((HW)²) 与类全局轴向注意力 [14,22] 的 O ((HW)^(3/2))。

双级路由注意力的计算量由三部分组成：线性投影、区域到区域路由、令牌间注意力。总计算量公式如下：\(\begin{aligned} FLOPs &=FLOPs_{proj }+ FLOPs _{routing}+FLOPs _{attn} \\ &=3 HW C^{2}+2\left(S^{2}\right)^{2} C+2 HW k \frac{HW}{S^{2}} C \\ &=3 HW C^{2}+C\left(2 S^{4}+\frac{k(HW)^{2}}{S^{2}}+\frac{k(HW)^{2}}{S^{2}}\right) \\ &\geq 3 HW C^{2}+3 C\left(2 S^{4} \cdot \frac{k(HW)^{2}}{S^{2}} \cdot \frac{k(HW)^{2}}{S^{2}}\right)^{\frac{1}{3}} \\ &=3 HW C^{2}+3 C k^{\frac{2}{3}}(2 HW)^{\frac{4}{3}}, \end{aligned}\)

其中，C 为令牌嵌入维度（即特征图的通道数），k 为待关注的区域数量（“top-k” 中的 “k”）。上述推导应用了算术 - 几何均值不等式，式（8）中等号成立的条件为 2S⁴ = [k (HW)²]/S²，由此可解得：\(S=\left(\frac{k}{2}(HW)^{2}\right)^{\frac{1}{6}} . \tag{9}\)

这意味着，若根据式（9）随输入分辨率调整区域划分因子 S，双级路由注意力的复杂度可达到 O ((HW)^(4/3))。

### 3.4 BiFormer 的架构设计

以双级路由注意力为基本构建模块，本文提出通用视觉 Transformer——BiFormer。如图 3 所示，BiFormer 借鉴了近期主流视觉 Transformer [14,29,41] 的四阶段金字塔结构：具体而言，在第 1 阶段采用重叠分块嵌入（overlapped patch embedding），第 2 至第 4 阶段采用分块合并模块 [25,37]（用于降低输入空间分辨率、提升通道数），随后每个阶段包含 N_i 个连续的 BiFormer 块以实现特征变换。

在每个 BiFormer 块中，借鉴近期研究 [7,25,41] 的设计：首先通过 3×3 深度可分离卷积隐式编码相对位置信息，随后依次应用双级路由注意力模块与 2 层 MLP 模块（扩张比为 e），分别实现跨位置关系建模与逐位置嵌入。

本文通过调整网络宽度（即基础通道数 C）与深度（即每个阶段包含的 BiFormer 块数量 N_i，i=1,2,3,4），实例化了 3 种不同规模的 BiFormer 模型，其他配置保持一致。每个注意力头的通道数设为 32，MLP 扩张比 e=3；对于双级路由注意力，4 个阶段的 top-k 值分别设为 1、4、16、S²³，且针对分类 / 语义分割 / 目标检测任务，由于输入分辨率不同，区域划分因子 S 分别设为 7/8/16。

表 1 不同模型变体的网络宽度与深度（FLOPs 基于 224×224 输入计算）

|模型|通道数|块数量|参数（M）|浮点运算次数（G）|
|---|---|---|---|---|
|BiFormer-T|64|[2, 2, 8, 2]|13|2.2|
|BiFormer-S|64|[4, 4, 18, 4]|26|4.5|
|BiFormer-B|96|[4, 4, 18, 4]|57|9.8|

表 2 ImageNet-1K 上不同骨干网络的性能对比（所有模型均在 224×224 分辨率图像上训练与评估；“*” 表示模型采用令牌标记 [23] 训练；方法按计算量分组）

|模型|浮点运算次数（G）|参数（M）|Top-1 准确率（%）|
|---|---|---|---|
|ResNet-18 [19]|1.8|11.7|69.8|
|RegNetY-1.6G [34]|1.6|11.2|78.0|
|PVTv2-b1 [45]|2.1|13.1|78.7|
|Shunted-T [37]|2.1|11.5|79.8|
|QuadTree-B-b1 [38]|2.3|13.6|80.0|
|BiFormer-T|2.2|13.1|81.4|
|Swin-T [29]|4.5|29|81.3|
|CSWin-T [14]|4.5|23|82.7|
|DAT-T [48]|4.6|29|82.0|
|CrossFormer-S [46]|5.3|31|82.5|
|RegionViT-S [2]|5.3|31|82.6|
|QuadTree-B-b2 [38]|4.5|24|82.7|
|MaxViT-T [41]|5.6|31|83.6|
|ScalableViT-S [50]|4.2|32|83.1|
|Uniformer-S* [25]|4.2|24|83.4|
|Wave-ViT-S* [51]|4.7|23|83.9|
|BiFormer-S|4.5|26|83.8|
|BiFormer-S*|4.5|26|84.3|
|Swin-B [29]|15.4|88|83.5|
|CSWin-B [14]|15.0|78|84.2|
|CrossFormer-L [46]|16.1|92|84.0|
|ScalableViT-B [50]|8.6|81|84.1|
|Uniformer-B* [25]|8.3|50|85.1|
|Wave-ViT-B* [51]|7.2|34|84.8|
|BiFormer-B|9.8|57|84.3|
|BiFormer-B*|9.8|58|85.4|

（图 3 左：BiFormer 的整体架构，配置参考表 1；右：BiFormer 块的详细结构）输入 → 第 1 阶段：重叠分块嵌入 → 第 2 阶段：分块合并 + BiFormer 块 → 第 3 阶段：分块合并 + BiFormer 块 → 第 4 阶段：分块合并 + BiFormer 块BiFormer 块：LayerNorm（LN）→ 3×3 深度可分离卷积（DWConv）→ 双级路由注意力 → LayerNorm → MLP → LayerNorm

## 4. 实验

本文在多个主流计算机视觉任务上验证 BiFormer 的有效性，包括图像分类（4.1 节）、目标检测与实例分割（4.2 节）、语义分割（4.3 节）。具体而言：在 ImageNet-1K [12] 上从零开始训练以完成图像分类任务；在 COCO [28] 上对预训练骨干网络进行微调，以完成目标检测与实例分割任务；在 ADE20K [55] 上对预训练骨干网络进行微调，以完成语义分割任务。此外，4.4 节通过消融实验验证双级路由注意力及 BiFormer 其他架构设计的有效性；4.5 节通过可视化注意力图，验证双级路由注意力确实实现了查询自适应的稀疏模式。

### 4.1 ImageNet-1K 图像分类

#### 4.1.1 实验设置

在 ImageNet-1K [12] 数据集上进行图像分类实验，为保证公平对比，采用与 DeiT [40] 一致的实验设置：每个模型训练 300 轮，输入图像分辨率为 224×224；优化器采用 AdamW，权重衰减为 0.05；学习率采用余弦衰减调度，初始学习率为 0.001，前 5 轮采用线性热身 [16]；批大小设为 1024。为避免过拟合，采用多种正则化技术：RandAugment [9]（参数 rand-m9-mstd0.5inc1）、MixUp [54]（概率 0.8）、CutMix [52]（概率 1.0）、随机擦除（Random Erasing，概率 0.25），以及递增随机深度 [21]（BiFormer-T/S/B 的概率分别为 0.1/0.15/0.4）。为与采用令牌标记 [23] 训练的模型（如 Uniformer [25]、WaveViT [51]）公平对比，本文还提供了采用 WaveViT 相同训练方案的 BiFormer 版本。

#### 4.1.2 实验结果

将本文方法与多个相关方法及近期主流模型进行对比，定量结果如表 2 所示（模型按计算量分组）。在所有 3 个分组中，BiFormer 均持续优于其他对比模型：

- 在计算量最小的分组（≈2G FLOPs）中，BiFormer-T 的 Top-1 准确率达 81.4%，比性能最接近的 QuadTree-b1 [38] 高 1.4 个百分点；
- 在计算量中等的分组（≈4G FLOPs）中，BiFormer-S 的 Top-1 准确率达 83.8%—— 据我们所知，在未使用额外训练数据或训练技巧的情况下，这是该计算预算下的最佳结果；此外，采用令牌标记 [23] 蒸馏技术后，BiFormer-S 的准确率可进一步提升至 84.3%，表明该架构具有巨大潜力；
- 在计算量较大的分组（≈10G FLOPs）中，BiFormer-B 的性能甚至优于计算量高达≈16G FLOPs 的现有模型（如 Swin-B [29]、CSWin-B [14]、CrossFormer-L [46]）。

### 4.2 目标检测与实例分割

#### 4.2.1 实验设置

在 COCO 2017 [28] 数据集上评估模型的目标检测与实例分割性能。为保证公平对比，所有实验均基于 MMDetection [3] 工具库实现：目标检测采用 RetinaNet [27] 框架，实例分割采用 Mask R-CNN [18] 框架。在 COCO 上训练前，骨干网络使用 ImageNet-1K 预训练权重初始化，其他层随机初始化。模型采用 MMDetection 提供的标准 1× 调度（12 轮）训练，但优化器改用 AdamW [30]（而非 SGD）；初始学习率设为 1e-4，批大小为 16；RetinaNet 与 Mask R-CNN 的权重衰减分别设为 1e-4 与 5e-2。训练过程中，输入图像的短边固定为 800 像素，长边不超过 1333 像素。

#### 4.2.2 实验结果

实验结果如表 3 所示。对于 RetinaNet 目标检测，报告的指标包括平均精度均值（mAP）、不同交并比（IoU）阈值（50%、75%）下的平均精度（AP），以及不同目标尺寸（小、中、大，S/M/L）下的平均精度。结果显示：虽然 BiFormer 的整体性能与 WaveViT、QuadTree-B 等性能最接近的现有模型相当，但其在中小目标上的性能（AP_M、AP_S）显著优于这些模型 —— 这可能是因为双级路由注意力通过稀疏采样而非下采样节省计算量，从而保留了对中小目标至关重要的细粒度细节。

对于 Mask R-CNN 实例分割，报告的指标包括边界框平均精度（AP^b）与掩码平均精度（AP^m）（均包含不同 IoU 阈值（50%、75%）下的结果）。如表 3 所示，BiFormer 在所有指标上均展现出明显优势。

表 3 COCO 2017 数据集上目标检测（左组）与实例分割（右组）性能对比

|骨干网络|RetinaNet 1× 调度||||||Mask R-CNN 1× 调度||||||
|---|---|---|---|---|---|---|---|---|---|---|---|---|
||mAP|AP₅₀|AP₇₅|AP_S|AP_M|AP_L|mAP^b|AP^b₅₀|AP^b₇₅|mAP^m|AP^m₅₀|AP^m₇₅|
|Swin-T [29]|41.5|62.1|44.2|25.1|44.9|55.5|42.2|64.6|46.2|39.1|61.6|42.0|
|DAT-T [48]|42.8|64.4|45.2|28.0|45.8|57.8|44.4|67.6|48.5|40.4|64.2|43.1|
|CSWin-T [14]|-|-|-|-|-|-|46.7|68.6|51.3|42.2|65.6|45.4|
|CrossFormer-S [46]|44.4|55.3|38.6|19.3|40.0|48.8|45.4|68.0|49.7|41.4|64.8|44.6|
|QuadTree-B2 [38]|46.2|67.2|49.5|29.0|50.1|61.8|-|-|-|-|-|-|
|WaveViT-S* [51]|45.8|67.0|49.4|29.2|50.0|60.8|46.6|68.7|51.2|42.4|65.5|45.8|
|BiFormer-S|45.9|66.9|49.4|30.2|49.6|61.7|47.8|69.8|52.3|43.2|66.8|46.5|
|Swin-S [29]|44.5|65.7|47.5|27.4|48.0|59.9|44.8|66.6|48.9|40.9|63.4|44.2|
|DAT-S [48]|45.7|67.7|48.5|30.5|49.3|61.3|47.1|69.9|51.5|42.5|66.7|45.4|
|CSWin-S [14]|-|-|-|-|-|-|47.9|70.1|52.6|43.2|67.1|46.2|
|CrossFormer-B [46]|46.2|67.8|49.5|30.1|49.9|61.8|47.2|69.9|51.8|42.7|66.6|46.2|
|QuadTree-B3 [38]|47.3|68.2|50.6|30.4|51.3|62.9|-|-|-|-|-|-|
|Wave-ViT-B* [51]|47.2|68.2|50.9|29.7|51.4|62.3|47.6|69.1|52.4|43.0|66.4|46.0|
|BiFormer-B|47.1|68.5|50.4|31.3|50.8|62.6|48.6|70.5|53.8|43.7|67.6|47.1|

### 4.3 ADE20K 语义分割

#### 4.3.1 实验设置

遵循现有研究，在 ADE20K [55] 数据集上基于 MMSegmentation [8] 工具库进行语义分割实验，对比采用 Semantic FPN [24] 与 UperNet [49] 两种框架的性能。两种框架中，骨干网络均使用 ImageNet-1K 预训练权重初始化，其他层随机初始化；优化器采用 AdamW，批大小设为 32。为保证公平对比：Semantic FPN 实验采用与 PVT [44] 一致的设置，训练 80k 步；UperNet 实验采用与 Swin Transformer [29] 一致的设置，训练 160k 轮。

#### 4.3.2 实验结果

两种框架的实验结果如表 4 所示。结果显示：在 Semantic FPN 框架下，BiFormer-S/B 的均值交并比（mIoU）分别达 48.9%/49.9%，比 CSWin-T/S 高 0.7 个百分点；在 UperNet 框架下，BiFormer 也展现出类似的性能提升。

表 4 ADE20K 数据集上两种分割头（Semantic FPN 与 UperNet）的语义分割性能对比

|骨干网络|S-FPN mIoU（%）|UperNet||
|---|---|---|---|
| | |mIoU（%）|MS mIoU（%）|
|Swin-T [29]|41.5|44.5|45.8|
|DAT-T [48]|42.6|45.5|46.4|
|CSWin-T [14]|48.2|49.3|50.7|
|CrossFormer-S [46]|46.0|47.6|48.4|
|Shunted-S [37]|48.2|48.9|49.9|
|WaveViT-S* [51]|-|-|49.6|
|BiFormer-S|48.9|49.8|50.8|
|Swin-S [29]|-|47.6|49.5|
|DAT-S [48]|46.1|48.3|49.8|
|CSWin-S [14]|49.2|50.4|51.5|
|CrossFormer-B [46]|47.7|49.7|50.6|
|Uniformer-B [25]|48.0|50.0|50.8|
|WaveViT-B* [51]|-|-|51.5|
|BiFormer-B|49.9|51.0|51.7|

| 骨干网络 | S-FPN mIoU（%） |     |     |
| ---- | ------------- | --- | --- |
|      |               |     |     |


### 4.4 消融实验

#### 4.4.1 双级路由注意力的有效性

将双级路由注意力与多种现有稀疏注意力机制进行对比。为保证公平对比，借鉴文献 [14] 的做法，将宏观架构设计与 Swin-T [29] 对齐：具体而言，四阶段分别包含 2、2、6、2 个块，采用非重叠分块嵌入，初始分块嵌入维度 C=96，MLP 扩张比 e=4。实验结果如表 5 所示，无论是图像分类还是语义分割任务，双级路由注意力的性能均显著优于现有稀疏注意力机制。

表 5 不同注意力机制的消融实验（所有模型均采用 Swin-T [29] 的架构设计）

| 稀疏注意力机制     | ImageNet-1K Top-1 准确率（%） | ADE20K mIoU（%） |
| ----------- | ------------------------ | -------------- |
| 滑动窗口 [35]   | 81.4                     | -              |
| 移位窗口 [29]   | 81.3                     | 41.5           |
| 空间分离 [7]    | 81.5                     | 42.9           |
| 顺序轴向 [20]   | 81.5                     | 39.8           |
| 十字交叉 [22]   | 81.7                     | 43.0           |
| 十字形窗口 [14]  | 82.2                     | 43.4           |
| 可变形 [48]    | 82.0                     | 42.6           |
| 块 - 网格 [41] | 81.8                     | 42.8           |
| 双级路由（本文）    | 82.7                     | 44.8           |

#### 4.4.2 其他架构设计选择的影响

以 Swin-T 的结构为基准，表 6 总结了其他架构修改对 BiFormer-S 性能的提升作用（最终使模型在 ImageNet-1K 上达到当前最优性能）。这些修改包括：（1）将非重叠分块嵌入 [29] 替换为重叠分块嵌入 [14,37,45]；（2）采用更深层结构（即每个阶段堆叠更多块，同时将基础通道数从 96 降至 64、MLP 扩张比从 4 降至 3，以保持相近计算量）；（3）在 BiFormer 块开头添加卷积位置编码 [7,25]；（4）采用令牌标记 [23,25,51] 训练技术。结果显示：单纯采用更深层结构即可显著提升性能，而这一因素在现有研究中往往未被讨论。

表 6 从 Swin-T [29] 结构到 BiFormer-S 的消融路径（修改按顺序叠加）

|架构设计修改|参数（M）|浮点运算次数（G）|ImageNet-1K Top-1 准确率（%）|
|---|---|---|---|
|基准（Swin-T 结构）|29|4.6|82.7|
|+ 重叠分块嵌入|31|4.9|82.8（+0.1）|
|+ 更深层结构|25|4.5|83.5（+0.7）|
|+ 卷积位置编码|26|4.5|83.8（+0.3）|
|+ 令牌标记|29|4.9|84.3（+0.5）|

### 4.5 注意力图可视化

为进一步理解双级路由注意力的工作机制，本文可视化了路由区域与查询位置对应的注意力响应。可视化使用的是第 3 阶段（计算量最大的主要阶段）最后一个 BiFormer 块提取的路由索引与注意力分数，图 4 展示了两个场景的可视化结果。两种场景中均可清晰观察到：语义相关区域被成功定位。例如，在第一个街景场景中，若查询位置位于建筑物或树木上，对应的路由区域会覆盖相同或相似实体；在第二个室内场景中，当查询位置位于鼠标上时，路由区域包含主机、键盘和显示器的部分区域 —— 尽管这些区域并不相邻，这表明双级路由注意力能够捕捉长程的跨物体关系。

## 5. 局限性与未来工作

与采用简单静态模式的稀疏注意力相比，本文方法需额外执行 “定位待关注区域” 的步骤（构建并剪枝区域级图、从路由区域聚集键值对）。尽管该步骤在粗粒度区域层面执行，计算量较小，但不可避免地会增加 GPU 内核启动与内存事务的开销。因此，由于内核启动开销与内存瓶颈，BiFormer 在 GPU 上的吞吐量低于部分计算量相近的现有模型。不过，这一问题可通过工程优化缓解（如 GPU 内核融合）。未来工作中，我们将探索硬件感知的高效稀疏注意力与视觉 Transformer。

## 6. 结论

本文提出双级路由注意力，以动态、查询感知的方式实现计算资源的高效分配。该注意力机制的核心思想是：在粗粒度区域层面过滤掉最无关的键值对，具体通过构建并剪枝区域级有向图实现，随后在路由区域的并集上执行细粒度令牌间注意力操作。本文通过分析证明，双级路由注意力在合理选择区域划分大小的情况下，复杂度可达到 O ((HW)^(4/3))。以双级路由注意力为核心构建模块，本文提出的视觉 Transformer（BiFormer）在图像分类、目标检测、实例分割、语义分割 4 个主流视觉任务上均展现出优异性能。

## 附录

### A. 区域表示的讨论

本文提出的双级路由注意力中，通过平均池化获取区域级表示（Q^r 与 K^r），用于区域到区域的路由。此处对该选择的合理性进行说明：

实际上，区域到区域路由的目标是为后续令牌间注意力定位最相关的令牌，因此需最大化两个区域间令牌的平均两两亲和度。而这等价于最大化两个区域的 “平均令牌” 间的亲和度，证明如下：\(\frac{1}{|\Omega| \cdot\left|\Omega'\right|} \sum_{i \in \Omega} \sum_{j \in \Omega'} Q_{i} K_{j}=\frac{\sum_{i \in \Omega} Q_{i}}{|\Omega|} \cdot \frac{\sum_{j \in \Omega'} K_{j}}{\left|\Omega'\right|}, \tag{10}\)其中，Ω 与 Ω' 分别表示两个区域的令牌索引集合。

### B. 吞吐量对比

为验证双级路由注意力的计算效率，本文对比了采用不同注意力机制的模型吞吐量。具体而言：将 Swin-T [29] 中的移位窗口注意力模块替换为四叉树注意力 [38] 模块，得到 QuadTree-STL；替换为本文双级路由注意力模块，得到 BiFormer-STL。随后使用广泛采用的 timm [47] 脚本，在 32GB Tesla V100 GPU 上测试训练与推理吞吐量（批大小 128，图像分辨率 224×224）。

如图 5 所示，Swin-T 因结构简单，吞吐量最高；采用双级路由注意力后，BiFormer-STL 的训练与推理吞吐量较 Swin-T 分别下降约 30% 与 40%，这是由路由过程（定位待关注区域、聚集键值对）带来的额外 GPU 内核启动与内存事务开销导致的。尽管如此，BiFormer-STL 的速度仍比 QuadTree-STL 快 3~6 倍 —— 原因在于：一方面，四叉树注意力的递归特性损害了并行性；另一方面，四叉树注意力依赖稀疏矩阵乘法（在 GPU 上效率低下），而双级路由注意力通过聚集键值对、后续执行 GPU 友好的稠密矩阵乘法实现，效率更高。

需注意的是，路由过程带来的内存事务与内核启动开销可通过工程优化（如 GPU 内核融合）降低，这将作为未来工作的一部分。

（图 5 32GB Tesla V100 GPU 上的吞吐量对比；后缀 “STL” 表示 “Swin-T 结构”，即仅替换 Swin-T [29] 骨干网络的注意力模块；结果包含 FP32 精度与自动混合精度（AMP）两种模式）横轴：模型（Swin-T（4.5G FLOPs）、BiFormer-STL（4.6G FLOPs）、QuadTree-STL（4.8G FLOPs））纵轴：吞吐量（图像 / 秒）数据：

- FP32 训练：Swin-T 733.3、BiFormer-STL 542.3、QuadTree-STL 133.2
- FP32 推理：Swin-T （未标注具体值，图中略）、BiFormer-STL （未标注具体值，图中略）、QuadTree-STL 27.5
- AMP 训练：Swin-T （未标注具体值，图中略）、BiFormer-STL 321.4、QuadTree-STL （未标注具体值，图中略）
- AMP 推理：Swin-T （未标注具体值，图中略）、BiFormer-STL （未标注具体值，图中略）、QuadTree-STL （未标注具体值，图中略）

### C. top-k 与区域划分因子 S 的选择

本文中 S 与 k 的选择主要考虑工程实现问题：（1）为避免填充（填充会减慢训练速度并可能降低性能），S 需选为训练图像尺寸的约数。例如，图像分类任务中分辨率为 224=7×32，因此选择 S=7（确保每个阶段特征图尺寸均可被 S 整除），这与 Swin Transformer [29] 选择窗口大小为 7 的思路一致；（2）在密集预测任务中，选择更大的 S 以平衡区域级路由与令牌级注意力的复杂度，从而降低整体复杂度 —— 虽未严格遵循式（9）的缩放规则，但该式为选择提供了参考；（3）随着后续阶段区域尺寸减小，逐步增大 k 以保证待关注令牌数量合理。

S 与 k 的组合可灵活调整，表 7 基于 BiFormer-STL（同本文前述设置）展示了 ImageNet-1K 上的消融结果。关键发现是：增加待关注令牌数量甚至可能降低准确率，这表明显式的稀疏约束可作为一种正则化手段，避免模型受到背景信息的干扰。

表 7 top-k 与区域划分因子 S 的消融实验

|S|k|待关注令牌数量|准确率（%）|吞吐量（图像 / 秒，FP32）|
|---|---|---|---|---|
|7|1,4,16,49|64,64,64,49|82.7|522.3|
|7|1,2,8,32|64,32,32,32|82.4|563.2|
|7|2,8,32,49|128,128,128,49|82.6|419.9|
|8,4,2,1|2,2,2,1|98,98,98,49|82.3|606.2|

### D. 基于双级路由注意力适配预训练普通 ViT

近期，为利用掩码图像建模的大规模预训练优势，一种新的研究方向是将普通 ViT [15] 适配于密集预测任务 [4,26]。本文探索利用所提双级路由注意力适配预训练普通 ViT，以用于语义分割任务。

具体而言：将 DeiT-B [40] 中的全部或部分全连接多头自注意力（MHSA）模块替换为双级路由注意力模块，并在 ADE20K 数据集上训练语义分割模型前，直接加载 ImageNet 预训练权重（双级路由注意力模块的线性投影权重由原始 MHSA 的权重初始化）。将该适配方法与文献 [26] 的方法对比 —— 后者采用局部窗口注意力（窗口大小 w=14），并结合多个全局注意力或卷积传播块。本文设置窗口大小 w=4（由于特征图分辨率为 32×32，这等价于区域划分大小 S=8），待关注区域数量 k=12，因此每个查询关注 4²×12=192 个键值对，与局部窗口注意力（每个查询关注 14×14=196 个键值对）的关注数量相近。

表 8 展示了实验结果：在无传播块的情况下，采用双级路由注意力的架构比采用局部窗口注意力的架构，mIoU 显著高 2.4 个百分点；进一步添加 4 个全局传播块后，两种架构的性能均有提升，但采用双级路由注意力的架构仍保持 0.2 个百分点的优势。

表 8 基于双级路由注意力适配预训练 ViT [15]，用于 ADE20K 语义分割（解码器采用 Simple Feature Pyramid [26]，后续接 UperNet [49] 头）

|注意力函数|mIoU（%）|
|---|---|
|局部窗口注意力（w=14）|43.55|
|双级路由注意力（w=4，k=12）|45.92|
|局部窗口注意力 + 4 个卷积传播块|44.68|
|局部窗口注意力 + 4 个全局传播块|46.64|
|双级路由注意力 + 4 个全局传播块|46.84|

### E. 更多注意力图可视化结果

为进一步展示双级路由注意力的工作机制，图 6 提供了更多可视化结果。每个场景中，均展示了输入图像上的 2~3 个查询位置（左图）、对应的路由区域（中图）以及最终注意力热力图（右图）。


# 脚注

[^1]: 这句话描述的是 **注意力（attention）机制** 在计算时所采用的 **空间约束方式**，即只让每个位置关注（或“看见”）其邻近的、特定形状的区域，而不是整个序列或特征图。常见的几种约束方式如下：
	
	| 约束方式 | 含义 | 典型应用 |
	|----------|------|----------|
	| **局部窗口（local window）** | 对每个查询位置，只在一个固定大小的窗口（如 3×3、5×5 等）内计算注意力权重。窗口在序列或特征图上滑动，超出窗口的元素被视为不可见或权重为 0。 | Vision Transformer 中的 **Swin‑Transformer**、卷积‑类注意力等。 |
	| **轴向条带（axial stripe）** | 将二维特征图的注意力拆分为 **行** 与 **列** 两个单独的“一维”注意力。即先在水平方向（行）上计算注意力，再在垂直方向（列）上计算，或反之。这样每个位置只需要关注同一行或同一列的所有位置，计算复杂度从 O(N²) 降到 O(N·√N)。 | **Axial‑Attention**、**Axial‑DeepLab** 等模型。 |
	| **扩张窗口（dilated window）** | 在局部窗口的基础上加入 **膨胀（dilation）** 参数，使得窗口内部的采样点呈稀疏分布，能够在保持感受野大小的同时捕获更大尺度的上下文。类似于 **空洞卷积** 的思路。 | **Dilated‑Attention**、一些改进的 **Swin‑Transformer** 变体。 |
	
	### 为什么要使用这些限制？
	
	1. **降低计算成本**  
	   完全全局注意力的复杂度是 O(L²)（L 为序列长度或特征图像素数），在大规模图像或长序列上非常耗时。局部或轴向约束把复杂度降到 **线性或准线性**，更易于实际部署。
	
	2. **增强局部建模能力**  
	   视觉任务中，局部纹理和边缘信息往往更重要。局部窗口让模型更专注于相邻像素的细节。
	
	3. **扩大感受野**  
	   通过 **轴向** 或 **扩张** 的方式，模型仍能在不显著增加计算的前提下捕获跨越更大范围的上下文信息。
	
	### 小结
	
	“将注意力操作限制在局部窗口、轴向条带或扩张窗口内”指的就是 **在注意力计算时只让每个位置关注特定形状的子区域**（如固定大小的局部块、同一行/列、或带有膨胀的稀疏块），从而在保持或提升表达能力的同时，显著降低计算复杂度，特别适用于 **大规模图像、视频或长文本** 等高维数据的处理。
