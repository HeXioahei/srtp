# 摘要

**问题一**：像素级解译是遥感图像应用的关键环节，但目前普遍存在需要大量**人工标注**的局限性。
**解决方案一**：将开放词汇语义分割（OVSS）引入遥感领域。

**问题二**：遥感图像对低分辨率特征较为敏感，预测掩码中会出现目标形状失真和边界拟合不佳的问题。
**解决方案二**：一种简单通用的**上采样器SimFeatUp**，以==无训练的方式==恢复深度特征中丢失的空间信息。此外，基于对CLIP中局部patch令牌对`[CLS]`令牌的异常响应观察，我们提出通过**直接的减法运算来缓解patch令牌中的全局偏差**。

# 1.引言

遥感图像涉及到更多的空间分辨率、时间维度和物体视角，所以为其他数据模型（如自然图像）设计的解决方案对于遥感图像可能不是最佳的。

像素级感知即分割的应用比实例级感知更为频繁，而对像素级标注的需求加剧了获取大规模标签的难度。

从经验上看，我们认为这些问题在很大程度上可以归因于**过低的特征分辨率**：在当前基于CLIP的OVSS范例中，来自CLIP的特征映射被下采样到原始图像的1/16 （vitb /16）。因此，在本文中，我们提出了一种简单而通用的**特征上采样器SimFeatUp**，其训练目标是在少量未标记的图像上重建内容不变的高分辨率（HR）特征，并且可以在训练后对任意遥感图像特征进行上采样。由于SimFeatUp的这一特性，它可以作为一个通用的外部单元用于无需培训的OVSS框架。此外，CLIP在图像级别进行训练，它使用`[CLS]`令牌作为整个图像的表示，并将全局属性附加到本地令牌上。然而，在OVSS中，这种**全局属性会使局部特征对patch级推理产生偏差**。我们发现，**对局部patch特征和全局特征进行简单的相减运算可以有效地减小全局偏置**。大量的定量和定性实验表明，我们的方法比以前的工作有更好的分割质量。

**贡献**：
* 我们提出了SimFeatUp，一种用于无训练OVSS的通用特征上采样器，它可以鲁棒地对低分辨率（LR）特征上采样，并保持与图像内容的语义一致性。
* 我们提出了一种非常简单直接的方法来缓解CLIP的全局偏差问题，即执行局部和全局令牌的减法操作。
* 我们最后提出的模型，名为SegEarth-OV，在17个遥感数据集上实现了最先进的性能，涵盖语义分割、建筑提取、道路提取和洪水检测任务。

# 2.相关工作

* **视觉语言模型**：CLIP
* **监督语义分割**：feature up构建了一个模型无关的上采样方案，该方案使用多视图一致性损失，与nerf有很深的相似之处。然而，它只是用标签来探索这种情况。受FeatUp的启发并在其基础上构建，本工作中提出的SimFeatUp能够在没有任何标签的情况下显著改善OVSS。
* **开放词汇语义分割**：我们将目前基于clip的OVSS方法分为两组：需要培训的和不需要培训的。
	* 前者允许以监督或弱监督的方式在一些基类上训练模型。
		* 一些研究尝试训练一个可以自然地进行密集预测的定位感知CLIP。
		* 而另一些研究则选择CLIP预训练参数的一个子集或将有限数量的可训练参数引入冻结的CLIP，即对CLIP进行微调以适应基类的密集预测。
	* 无需训练的OVSS方法强调利用CLIP固有的定位能力，对特征或结构进行有限的手术。
		* MaskCLIP率先在CLIP图像编码器的注意力池层去除查询和关键投影。随后的研究充分探索了自我注意（即qq， k-k或v-v自我注意），这些修改在一定程度上减轻了CLIP的噪声激活和空间不变感知。
		* 另一个流是两阶段方法，它首先生成与类别无关的掩码建议，然后对掩码进行分类。
		* 此外，还可以引入其他一些基础模型（如SAM、Stable Diffusion）来增强CLIP的定位能力。

# 3.预备

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202507071543618.png)

(a)是SimFeatUp的培训过程。CLIP是冻结的，只有SimFeatUp在推理中有用。
(b)为SegEarth-OV的推理过程。来自CLIP的LR特征映射由SimFeatUp上采样，然后减去`[CLS]`令牌以减轻全局偏差。

## 3.1.CLIP
## 3.2.FeatUp
feature up 旨在训练一个与模型无关的上采样器。通过可学习上采样器σ↑对冰冻骨干网的LR特征`O[1: hw+1]`进行上采样操作，然后使用可学习下采样器σ↓重建LR特征。它的关键见解可以用以下损失函数简单概括：
$$ L_{rec} = ∥O[1 : hw + 1] − σ↓(σ↑(O[1 : hw + 1]))∥_2^2 $$

FeatUp实例化σ↑作为堆叠参数化 JBU（Joint Bilateral Upsampling）操作符。通过加权LR特征的相邻元素来估计上采样的HR特征元素。对于权值的生成，JBU考虑两个因素，即制导特征中相邻元素与中心元素之间的相似度和距离，对应于 $k_{range}$ 和 $k_{spatail}$ 。为简洁起见，我们省略了多视图一致性约束。
# 4.方法
## 4.1.SimFeatUp
feature up 缺乏对无训练设置的一些考虑，导致它不是OVSS任务的最佳选择，特别是在遥感环境中。
* **图像内容保留**：如第3.2节所述，FeatUp的目标是最小化原始LR特征和上下采样后的LR特征（即`σ↓(σ↑(O[1: hw 1]))`）。由于σ↑和σ↓都是可学习的，在这种弱约束下，上下采样过程变成了一个黑盒，中间的HR特征在内容上不能保证完整和与原始图像一致。为了解决这个问题，我们引入了一个额外的图像重建损失来约束HR特征：
	$$L_{img} = ∥I − CRN(σ↑(O[1 : hw + 1])))∥^2$$
	
	其中I表示输入图像。CRN表示内容保留网，接收HR特征作为输入，重建原始图像。具体来说，CRN由两个具有激活的2D卷积层和一个Tanh激活层组成，其中Tanh层被设计为约束输出为`[- 1,1]`，参见VAEs[24]。最后，训练SimFeatUp的损失由Lrec和Limg组成，权重为γ，即：
	$$L = L_{rec} + γL_{img}$$

* **要上采样哪个特征？**：feature up将CLIP的最终输出，即Eq.(2)中的0 [1:hw 1]作为上采样器的输入。这在基于训练的设置中可以很好地工作，例如，线性探针[1]。然而，在没有训练的OVSS中，如第2节所述，香草的自我关注会导致较差的表现。因此，目前的OVSS方法将其调制为自关注，这一规律也适用于遥感图像。在此前提下，式中的SA。