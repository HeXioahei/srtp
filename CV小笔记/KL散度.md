KL 散度（Kullback‑Leibler Divergence）是衡量两个概率分布 **P** 与 **Q** 之间差异的非对称度量。对离散情形，定义为  

$$
D_{\text{KL}}(P\|Q)=\sum_{x} P(x)\,\log\frac{P(x)}{Q(x)}
$$

对连续情形，则使用积分形式  

$$
D_{\text{KL}}(P\|Q)=\int p(x)\,\log\frac{p(x)}{q(x)}\,dx
$$

其中 $p(x)$ 与 $q(x)$ 分别是 **P** 与 **Q** 的概率密度（或质量）函数。KL 散度的主要性质：

1. **非负性**：$D_{\text{KL}}(P\|Q)\ge 0$，且仅当 $P=Q$（几乎处处相等）时等于 0（Gibbs 不等式）。  
2. **非对称**：一般情况下 $D_{\text{KL}}(P\|Q)\neq D_{\text{KL}}(Q\|P)$。  
3. **信息解释**：它表示如果用分布 **Q** 来近似真实分布 **P**，每个样本在编码时多出的额外比特数（信息损失）。  

在机器学习中，KL 散度常用于：

- **变分推断**：最小化近似后验与真实后验的 KL 散度。  
- **生成模型**（如 VAE、GAN）中的目标函数。  
- **强化学习** 中的策略更新（如 PPO 中的 KL‑penalty）。  
- **分布匹配**、**异常检测** 等场景。

**先验（Prior）**  
在进行概率推断或贝叶斯统计时，先验是指在观察到任何数据之前，对未知参数 θ 的概率分布的主观或经验性假设，用记号 p(θ) 表示。先验反映了研究者对参数可能取值的先验知识、经验或信念。

**后验（Posterior）**  
后验是结合先验信息与观测数据 X 后，对参数 θ 的更新后的概率分布，用记号 p(θ | X) 表示。依据贝叶斯公式：

$$
p(\theta \mid X)=\frac{p(X \mid \theta)\,p(\theta)}{p(X)}
$$

其中 p(X | θ) 是似然函数， p(X) 是归一化常数（证据）。后验分布综合了先验信念和数据提供的证据，提供了对参数的最新不确定性描述。