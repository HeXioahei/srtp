- **backbone等概念**
	 [(8 封私信 / 6 条消息) 深度学习网络中backbone是什么意思? - 知乎](https://www.zhihu.com/question/399611596)

- **Dense feature**
	密集特征（Dense Feature）是指在数据中大部分值为非零的浮点数型特征。这类特征通常以连续数值形式存在，例如温度、价格、图像像素值等，每个样本都会包含这些特征且其取值较为密集。与稀疏特征（如类别ID、文本词频等）不同，密集特征不需要通过独热编码（One-Hot Encoding）或嵌入（Embedding）等复杂处理，可以直接输入模型的全连接层（Dense Layer）进行学习。

- **train from scrath**
	from scrath 在英文中的意思就是“从零开始、从头开始、白手起家”，引申过来就是不使用预训练文件而直接进行训练.

- **Depthwise卷积与Pointwise卷积**
	[Depthwise卷积与Pointwise卷积 - 知乎](https://zhuanlan.zhihu.com/p/80041030)

- **种子指令**
	**种子指令（Seed Instructions）** 是指在人工智能（AI）模型训练或生成任务中，用于启动或引导模型行为的一组初始输入或提示。它们通常是简短、明确的指令或示例，帮助模型理解任务要求并生成符合预期的输出。

- **端到端的训练方式**
	**端到端（End-to-End）训练方式**是一种模型训练方法，整个过程从输入到输出由单一模型完成，无需分阶段或手动设计中间步骤。用这种方式训练复杂的大模型成本会很高。

- **SFT**
	Supervised Fine-tuning（监督微调）

- **指令微调**
	**[指令微调](https://zhida.zhihu.com/search?content_id=247610605&content_type=Article&match_order=1&q=%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83&zhida_source=entity)（Instruction Fine-Tuning）** 是大语言模型训练过程中的一个关键步骤，旨在通过在有监督的任务数据集上进行训练，使模型能够更好地理解人类指令并执行特定任务。这个过程在基础模型的基础上进一步优化模型的性能，使其输出更符合用户的预期，特别是在执行指令性任务时（如回答问题、写作、生成代码等）。

- **在线镜像下降**
	[A Modern Introduction to Online Learning 6 - 在线镜像下降 (I) - 知乎](https://zhuanlan.zhihu.com/p/685632557)

- **奖励模型**
	[ORM和PRM奖励模型（Reward Model，打分模型）知识点总结 - 知乎](https://zhuanlan.zhihu.com/p/20157090301#:~:text=%E5%9C%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%AD%EF%BC%8C%E5%B8%B8%E9%87%87%E7%94%A8%20RLHF%20%EF%BC%88Reinforcement%20Learning,from%20Human%20Feedback%EF%BC%89%E5%8D%B3%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%98%AF%E4%B8%80%E7%A7%8D%E5%B0%86%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E8%9E%8D%E5%85%A5%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E7%9A%84%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%EF%BC%8C%E8%AF%A5%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%80%E9%83%A8%E4%BB%BD%E5%B0%B1%E6%98%AF%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%E3%80%82%20%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%E4%B9%9F%E5%8F%AB%20%E6%89%93%E5%88%86%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%98%AF%E4%B8%80%E7%A7%8D%E9%80%9A%E8%BF%87%E9%87%8F%E5%8C%96%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0%E5%B9%B6%E6%89%93%E5%88%86%EF%BC%8C%E4%BB%A5%E5%BC%95%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E6%88%96%E8%BE%93%E5%87%BA%E7%BB%99%E7%94%A8%E6%88%B7%E7%BB%93%E6%9E%9C%E5%89%8D%E5%81%9A%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0%EF%BC%8C%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81%E9%87%8D%E6%96%B0%E7%BB%99%E7%94%A8%E6%88%B7%E9%A2%84%E6%B5%8B%E3%80%82)

- **长度惩罚（Length Penalty）**
	[大模型推理-Length Penalty - 知乎](https://zhuanlan.zhihu.com/p/716596412)

- **解耦**
	“解耦”指把原本紧密关联、相互依赖的两个或多个系统、模块、功能等分离开来，使它们能够独立工作、单独演化或单独替换。通过解耦，可以降低相互之间的耦合度，提升系统的可维护性、可扩展性和灵活性。常见的解耦方式包括使用接口/抽象层、事件/消息机制、依赖注入等技术手段。

- **模型容量**
	**模型容量**指的是一个机器学习模型能够表达和学习的函数复杂度或信息量，通常由以下因素决定：
	
	1. **参数数量**：模型的可训练权重和偏置的总数。参数越多，模型的表达空间越大。  
	2. **网络深度与宽度**：层数（深度）和每层的神经元/通道数（宽度）直接影响参数规模和特征抽象能力。  
	3. **结构复杂度**：如注意力头数、分支数、残差连接等设计也会提升模型的表示能力。  
	
	容量大意味着模型可以拟合更复杂的模式，但也更容易出现**过拟合**，需要更多数据或正则化手段来约束。容量小的模型更易训练、推理快，但可能欠拟合，难以捕捉数据中的细节。简言之，模型容量就是模型“记忆”和“学习”能力的量化衡量。





