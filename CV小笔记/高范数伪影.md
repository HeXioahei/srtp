**高范数伪影**（high‑norm artifact）是指在视觉 Transformer（ViT）等基于块（patch）嵌入的模型特征图中出现的异常 token，这类 token 的特征向量范数显著高于大多数其它 token。  

- **表现形式**：在特征图的范数分布上形成双峰或长尾，少数 token 的范数往往超过 150（约占 2% 左右），而普通 token 的范数大多在 0‑100 之间[[1]]。  
- **出现位置**：主要出现在模型的中间层，且集中在图像的低信息、背景区域（如大面积的天空、墙面等），这些区域本应只携带少量局部信息，却被高范数 token 占据[[2]]。  
- **本质原因**：高范数 token 其实是模型在训练过程中形成的“寄存器”式标记，它们倾向于保存全局信息，但牺牲了局部细节，导致特征图出现不自然的高能量点，即伪影。  
- **影响**：伪影会破坏特征图的平滑性，降低密集预测（如目标检测、语义分割）等下游任务的性能，并削弱模型的可解释性。  
- **解决思路**：在输入序列中加入专门的 **register tokens**（寄存器标记），让模型学习将这些高范数信息存放在可控的额外 token 中，从而消除原始特征图中的高范数伪影，显著提升模型在密集预测任务上的表现[[3]][[4]]。  

简而言之，高范数伪影是视觉 Transformer 中出现的、范数异常大的特征 token，常出现在低信息背景区域，属于模型内部的“寄存器”现象，需要通过添加专用寄存器 token 等方法加以抑制。